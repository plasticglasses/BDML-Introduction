{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ordered-recorder",
   "metadata": {},
   "source": [
    "# CW1 - Object Recognition using CNN\n",
    "To apply machine learning alorithms to clasify the testing images into object categories. Then use a model to perform classification and report quantitative results.\n",
    "\n",
    "Due: Monday 19th April"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "norwegian-karma",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "leading-turning",
   "metadata": {},
   "source": [
    "The aim is to evaluate the use of CNN's in image recognition and the affect of adding multiple layers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alpha-negotiation",
   "metadata": {},
   "source": [
    "# Imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "modified-demographic",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import skimage.feature\n",
    "import tensorflow as tf\n",
    "from sklearn.utils import shuffle\n",
    "from numpy import load\n",
    "from numpy import asarray\n",
    "from numpy import save"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "moving-democracy",
   "metadata": {},
   "source": [
    "# Load Data\n",
    "There are 100 different categories of objects\n",
    "each has 500 images for training and 100 images for testing.\n",
    "Split the data into train and test sections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "recovered-longer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images Shape: (32, 32, 3, 50000)\n",
      "Train Labels Fine Shape: (50000,)\n",
      "Train Labels Coarse Shape: (50000,)\n"
     ]
    }
   ],
   "source": [
    "images = np.load('trnImage.npy')\n",
    "label_fine = np.load('trnLabel_fine.npy')\n",
    "label_coarse = np.load('trnLabel_coarse.npy')\n",
    "\n",
    "#image_index = 1 # pick a specific image\n",
    "#image = images[:, :, :, image_index]\n",
    "\n",
    "test_images = np.load('tstImage.npy')\n",
    "test_label_fine = np.load('tstLabel_fine.npy')\n",
    "test_label_coarse = np.load('tstLabel_coarse.npy')\n",
    "\n",
    "print(f'Images Shape: {images.shape}')\n",
    "print(f'Train Labels Fine Shape: {label_fine.shape}')\n",
    "print(f'Train Labels Coarse Shape: {label_coarse.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "increasing-wright",
   "metadata": {},
   "source": [
    "# Shuffle data to ensure not ordered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "martial-orlando",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = shuffle(images, random_state=0)\n",
    "label_fine, label_coarse = shuffle(label_fine, label_coarse, random_state=0) #make sure the samples are not ordered\n",
    "\n",
    "\n",
    "test_images = shuffle(test_images, random_state=0)\n",
    "test_label_fine, test_label_coarse = shuffle(test_label_fine, test_label_coarse, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "looking-chain",
   "metadata": {},
   "source": [
    "# CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "adjacent-cattle",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32, 32, 1)\n"
     ]
    }
   ],
   "source": [
    "images_reshaped = np.transpose(images, (3, 0, 1, 2))[:, :, :, -1]\n",
    "images_reshaped = np.expand_dims(images_reshaped, axis=3)\n",
    "\n",
    "print(images_reshaped.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "coated-angel",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 32, 32, 1)\n"
     ]
    }
   ],
   "source": [
    "test_images_reshaped = np.transpose(test_images, (3, 0, 1, 2))[:, :, :, -1]\n",
    "test_images_reshaped = np.expand_dims(test_images_reshaped, axis=3)\n",
    "\n",
    "print(test_images_reshaped.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rotary-constraint",
   "metadata": {},
   "source": [
    "# Normalise the data, for each image do a hog, add how to array, train images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "banner-psychiatry",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Invalid shape (50000, 32, 32) for image data",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-105d9c89723b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'hog_array_train.npy'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\lizks\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\numpy\\lib\\npyio.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[0;32m    415\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 416\u001b[1;33m             \u001b[0mfid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstack\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menter_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos_fspath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    417\u001b[0m             \u001b[0mown_fid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'hog_array_train.npy'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-105d9c89723b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhog_image\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m122\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m         \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m         \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msuptitle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'Extracted HOG features from image number: {image_index}\\nFine Class: {label_fine[image_index]}, Coarse Class: {label_coarse[image_index]}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\lizks\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\matplotlib\\pyplot.py\u001b[0m in \u001b[0;36mimshow\u001b[1;34m(X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, filternorm, filterrad, resample, url, data, **kwargs)\u001b[0m\n\u001b[0;32m   2728\u001b[0m         \u001b[0mfilternorm\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfilternorm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilterrad\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfilterrad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresample\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mresample\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2729\u001b[0m         \u001b[0murl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m\"data\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m}\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2730\u001b[1;33m         **kwargs)\n\u001b[0m\u001b[0;32m   2731\u001b[0m     \u001b[0msci\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m__ret\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2732\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0m__ret\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\lizks\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\matplotlib\\__init__.py\u001b[0m in \u001b[0;36minner\u001b[1;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1445\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0minner\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1446\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1447\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msanitize_sequence\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1448\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1449\u001b[0m         \u001b[0mbound\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnew_sig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\lizks\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\matplotlib\\axes\\_axes.py\u001b[0m in \u001b[0;36mimshow\u001b[1;34m(self, X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, filternorm, filterrad, resample, url, **kwargs)\u001b[0m\n\u001b[0;32m   5521\u001b[0m                               resample=resample, **kwargs)\n\u001b[0;32m   5522\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5523\u001b[1;33m         \u001b[0mim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5524\u001b[0m         \u001b[0mim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_alpha\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5525\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_clip_path\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\lizks\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\matplotlib\\image.py\u001b[0m in \u001b[0;36mset_data\u001b[1;34m(self, A)\u001b[0m\n\u001b[0;32m    710\u001b[0m                 or self._A.ndim == 3 and self._A.shape[-1] in [3, 4]):\n\u001b[0;32m    711\u001b[0m             raise TypeError(\"Invalid shape {} for image data\"\n\u001b[1;32m--> 712\u001b[1;33m                             .format(self._A.shape))\n\u001b[0m\u001b[0;32m    713\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    714\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_A\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Invalid shape (50000, 32, 32) for image data"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "train_images_normalised = []\n",
    "\n",
    "try:\n",
    "    data = load('hog_array_train.npy')\n",
    "    print(data)\n",
    "except FileNotFoundError: \n",
    "    for image_index in range(0, 100):\n",
    "        image = images_reshaped[:, :, :, image_index]\n",
    "\n",
    "        # Extract features from a single image\n",
    "        _, hog_image = skimage.feature.hog(image, pixels_per_cell=[2,2], cells_per_block=[3,3], visualize=True)\n",
    "\n",
    "        plt.figure()\n",
    "        plt.subplot(121)\n",
    "        plt.imshow(hog_image)\n",
    "        plt.subplot(122)\n",
    "        plt.imshow(image)\n",
    "        plt.suptitle(f'Extracted HOG features from image number: {image_index}\\nFine Class: {label_fine[image_index]}, Coarse Class: {label_coarse[image_index]}')\n",
    "        plt.show(block=False)\n",
    "\n",
    "        print(hog_image)\n",
    "        train_images_normalised.append(hog_image)\n",
    "        #test_images_normalised[image_index] = hog_image\n",
    "\n",
    "        print(train_images_normalised[image_index])\n",
    "\n",
    "        train_images_output = np.array(train_images_normalised)\n",
    "\n",
    "\n",
    "        # save numpy array as npy file\n",
    "\n",
    "\n",
    "    data = asarray(train_images_output)\n",
    "        # save to npy file\n",
    "    save('hog_array_train.npy', data)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "correct-tokyo",
   "metadata": {},
   "source": [
    "normalise test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "absolute-arrival",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_images_normalised = []\n",
    "\n",
    "\n",
    "try:\n",
    "    \n",
    "    data = load('hog_array_test.npy')\n",
    "\n",
    "    print(data)\n",
    "except: \n",
    "    for image_index in range(0, 100):\n",
    "        image = test_images_reshaped[:, :, :, image_index]\n",
    "\n",
    "        # Extract features from a single image\n",
    "        _, hog_image = skimage.feature.hog(image, pixels_per_cell=[2,2], cells_per_block=[3,3], visualize=True)\n",
    "\n",
    "        plt.figure()\n",
    "        plt.subplot(121)\n",
    "        plt.imshow(hog_image)\n",
    "        plt.subplot(122)\n",
    "        plt.imshow(image)\n",
    "        plt.suptitle(f'Extracted HOG features from image number: {image_index}\\nFine Class: {label_fine[image_index]}, Coarse Class: {label_coarse[image_index]}')\n",
    "        plt.show(block=False)\n",
    "\n",
    "        print(hog_image)\n",
    "        test_images_normalised.append(hog_image)\n",
    "        #test_images_normalised[image_index] = hog_image\n",
    "\n",
    "        print(test_images_normalised[image_index])\n",
    "\n",
    "        train_images_output = np.array(test_images_normalised)\n",
    "\n",
    "\n",
    "        # save numpy array as npy file\n",
    "\n",
    "\n",
    "    data = asarray(train_images_output)\n",
    "        # save to npy file\n",
    "    save('hog_array_test.npy', data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "certain-catholic",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_images_normalised)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chubby-study",
   "metadata": {},
   "source": [
    "Normalise the data, for each image do a hog, add how to array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stupid-oxford",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_images_normalised)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unauthorized-opportunity",
   "metadata": {},
   "source": [
    "### Create and train a Tensorflow Convolutional Neural Network on the training set using Conv2D and pooling Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interior-penetration",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, -1)))\n",
    "model.add(tf.keras.layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "excessive-guyana",
   "metadata": {},
   "source": [
    "Check the Data cardinality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "continued-gentleman",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_images_normalised.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spiritual-paris",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_images_normalised.shape)\n",
    "print(test_images_normalised.shape)\n",
    "\n",
    "#train_images_normalised = np.array(train_images_normalised).reshape(50000, -1, 32, 32)\n",
    "#test_images_normalised = np.array(test_images_normalised).reshape(10000, -1, 32, 32)\n",
    "\n",
    "#train_images_normalised = train_images_normalised[:, 0, :, :]\n",
    "test_images_normalised = test_images_normalised[:, 0, :, :]\n",
    "\n",
    "train_images_normalised = np.transpose(train_images_normalised, (1, 2, 0))\n",
    "test_images_normalised = np.transpose(test_images_normalised, (1, 2, 0))\n",
    "\n",
    "print(train_images_normalised.shape)\n",
    "print(test_images_normalised.shape)\n",
    "\n",
    "\n",
    "print(label_fine.shape)\n",
    "print(test_label_fine.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "useful-double",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check number of unique  labels in coarse dtaaset\n",
    "#number of labels\n",
    "\n",
    "output_num_fine = (np.unique(label_fine).shape[0])\n",
    "print(output_num_fine)\n",
    "\n",
    "output_num_coarse = (np.unique(label_coarse).shape[0])\n",
    "print(output_num_coarse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intensive-northeast",
   "metadata": {},
   "outputs": [],
   "source": [
    "xTrn, xTst, yTrn, yTst = train_test_split(train_images_normalised, label_coarse, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "waiting-ivory",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(tf.keras.layers.Flatten()) #dense layers can oinly have 1d so flattern araray to one dimension\n",
    "model.add(tf.keras.layers.Dense(64, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(output_num_coarse, activation='softmax'))\n",
    "\n",
    "model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(xTrn, yTrn, epochs=10, \n",
    "                    validation_data=(xTst, yTst))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aggressive-postage",
   "metadata": {},
   "source": [
    "### Plot models traing curves "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "conditional-senegal",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['accuracy'], label='accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label = 'val_accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([0.5, 1])\n",
    "plt.legend(loc='lower right')\n",
    "\n",
    "test_loss, test_acc = model.evaluate(images_normalised,  label_fine_normalised, verbose=2)\n",
    "\n",
    "print(test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "improving-alias",
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(test_images_normalised, test_label_fine_normalised, verbose=0)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "seven-wiring",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
