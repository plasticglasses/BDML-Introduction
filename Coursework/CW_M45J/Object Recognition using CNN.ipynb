{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ordered-recorder",
   "metadata": {},
   "source": [
    "# CW1 - Object Recognition using CNN\n",
    "To apply machine learning alorithms to clasify the testing images into object categories. Then use a model to perform classification and report quantitative results.\n",
    "\n",
    "Due: Monday 19th April"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "norwegian-karma",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "leading-turning",
   "metadata": {},
   "source": [
    "The aim is to evaluate the use of CNN's in image recognition and the affect of adding multiple layers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alpha-negotiation",
   "metadata": {},
   "source": [
    "# Imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "modified-demographic",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import load\n",
    "from numpy import asarray\n",
    "from numpy import save\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import skimage.feature\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "moving-democracy",
   "metadata": {},
   "source": [
    "# Load Data\n",
    "There are 100 different categories of objects\n",
    "each has 500 images for training and 100 images for testing.\n",
    "Split the data into train and test sections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "recovered-longer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images Shape: (32, 32, 3, 50000)\n",
      "Train Labels Fine Shape: (50000,)\n",
      "Train Labels Coarse Shape: (50000,)\n"
     ]
    }
   ],
   "source": [
    "images = np.load('trnImage.npy')\n",
    "label_fine = np.load('trnLabel_fine.npy')\n",
    "label_coarse = np.load('trnLabel_coarse.npy')\n",
    "\n",
    "#image_index = 1 # pick a specific image\n",
    "#image = images[:, :, :, image_index]\n",
    "\n",
    "test_images = np.load('tstImage.npy')\n",
    "test_label_fine = np.load('tstLabel_fine.npy')\n",
    "test_label_coarse = np.load('tstLabel_coarse.npy')\n",
    "\n",
    "print(f'Images Shape: {images.shape}')\n",
    "print(f'Train Labels Fine Shape: {label_fine.shape}')\n",
    "print(f'Train Labels Coarse Shape: {label_coarse.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "increasing-wright",
   "metadata": {},
   "source": [
    "# Shuffle data to ensure not ordered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "martial-orlando",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = shuffle(images, random_state=0)\n",
    "label_fine, label_coarse = shuffle(label_fine, label_coarse, random_state=0) #make sure the samples are not ordered\n",
    "\n",
    "\n",
    "test_images = shuffle(test_images, random_state=0)\n",
    "test_label_fine, test_label_coarse = shuffle(test_label_fine, test_label_coarse, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "looking-chain",
   "metadata": {},
   "source": [
    "# CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adjacent-cattle",
   "metadata": {},
   "outputs": [],
   "source": [
    "#images_reshaped = np.transpose(images, (3, 0, 1, 2))[:, :, :, -1]\n",
    "#images_reshaped = np.expand_dims(images_reshaped, axis=3)\n",
    "#\n",
    "#print(images_reshaped.shape)\n",
    "#print(images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coated-angel",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_images_reshaped = np.transpose(test_images, (3, 0, 1, 2))[:, :, :, -1]\n",
    "#test_images_reshaped = np.expand_dims(test_images_reshaped, axis=3)\n",
    "\n",
    "#print(test_images_reshaped.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rotary-constraint",
   "metadata": {},
   "source": [
    "# Normalise the data, for each image do a hog, add how to array, train images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "banner-psychiatry",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32, 32)\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    train_images_normalised = load('hog_array_train.npy')\n",
    "    print(train_images_normalised.shape)\n",
    "except FileNotFoundError: \n",
    "    \n",
    "    train_images_normalised = []\n",
    "    \n",
    "    for image_index in range(0, images.shape[3]):\n",
    "        print(image_index, images.shape[3])\n",
    "        image = images[:, :, :, image_index]\n",
    "\n",
    "        # Extract features from a single image\n",
    "        _, hog_image = skimage.feature.hog(image, pixels_per_cell=[2,2], cells_per_block=[3,3], visualize=True)\n",
    "        train_images_normalised.append(hog_image)\n",
    "        \n",
    "    train_images_output = np.array(train_images_normalised)\n",
    "    data = asarray(train_images_output)\n",
    "        # save to npy file\n",
    "    save('hog_array_train.npy', data)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "absolute-arrival",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 32, 32)\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    test_images_normalised = load('hog_array_test.npy')\n",
    "    print(test_images_normalised.shape)\n",
    "    \n",
    "except: \n",
    "    test_images_normalised = []\n",
    "    for image_index in range(0, test_images.shape[3]):\n",
    "        print(image_index, test_images.shape[3])\n",
    "        image = test_images[:, :, :, image_index]\n",
    "\n",
    "        # Extract features from a single image\n",
    "        _, hog_image = skimage.feature.hog(image, pixels_per_cell=[2,2], cells_per_block=[3,3], visualize=True)\n",
    "        test_images_normalised.append(hog_image)\n",
    "\n",
    "    train_images_output = np.array(test_images_normalised)\n",
    "    data = asarray(train_images_output)\n",
    "    save('hog_array_test.npy', data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unauthorized-opportunity",
   "metadata": {},
   "source": [
    "### Create and train a Tensorflow Convolutional Neural Network on the training set using Conv2D and pooling Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "choice-tender",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images_reshaped = train_images_normalised.reshape(50000, 32, 32, 1)\n",
    "test_images_reshaped = test_images_normalised.reshape(10000, 32, 32, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "interior-penetration",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_3 (Conv2D)            (None, 30, 30, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 15, 15, 32)        0         \n",
      "=================================================================\n",
      "Total params: 320\n",
      "Trainable params: 320\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 1)))\n",
    "model.add(tf.keras.layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "excessive-guyana",
   "metadata": {},
   "source": [
    "Check the Data cardinality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "useful-double",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "20\n",
      "(50000, 32, 32, 1)\n",
      "(50000,)\n"
     ]
    }
   ],
   "source": [
    "#check number of unique  labels in coarse dtaaset\n",
    "#number of labels\n",
    "\n",
    "output_num_fine = (np.unique(label_fine).shape[0])\n",
    "print(output_num_fine)\n",
    "\n",
    "output_num_coarse = (np.unique(label_coarse).shape[0])\n",
    "print(output_num_coarse)\n",
    "\n",
    "print(train_images_reshaped.shape)\n",
    "print(label_coarse.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "numerous-advance",
   "metadata": {},
   "source": [
    "# Split Training data into a train and test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "intensive-northeast",
   "metadata": {},
   "outputs": [],
   "source": [
    "xTrn_split, xTst_split, yTrn_split, yTst_split = train_test_split(train_images_reshaped, label_coarse, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ranking-charter",
   "metadata": {},
   "source": [
    "# Train and fit the model\n",
    "\n",
    "softmax - sed as the last activation function of a neural network to normalize the output of a network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "waiting-ivory",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "1250/1250 [==============================] - 10s 8ms/step - loss: 2.9964 - accuracy: 0.0491 - val_loss: 2.9964 - val_accuracy: 0.0483\n",
      "Epoch 2/200\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 2.9959 - accuracy: 0.0530 - val_loss: 2.9960 - val_accuracy: 0.0463\n",
      "Epoch 3/200\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 2.9958 - accuracy: 0.0509 - val_loss: 2.9961 - val_accuracy: 0.0463\n",
      "Epoch 4/200\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 2.9959 - accuracy: 0.0482 - val_loss: 2.9961 - val_accuracy: 0.0463\n",
      "Epoch 5/200\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 2.9960 - accuracy: 0.0504 - val_loss: 2.9963 - val_accuracy: 0.0473\n",
      "Epoch 6/200\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 2.9959 - accuracy: 0.0510 - val_loss: 2.9962 - val_accuracy: 0.0473\n",
      "Epoch 7/200\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 2.9959 - accuracy: 0.0509 - val_loss: 2.9963 - val_accuracy: 0.0477\n",
      "Epoch 8/200\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 2.9959 - accuracy: 0.0485 - val_loss: 2.9962 - val_accuracy: 0.0473\n",
      "Epoch 9/200\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 2.9959 - accuracy: 0.0492 - val_loss: 2.9961 - val_accuracy: 0.0477\n",
      "Epoch 10/200\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 2.9960 - accuracy: 0.0478 - val_loss: 2.9962 - val_accuracy: 0.0483\n",
      "Epoch 11/200\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 2.9959 - accuracy: 0.0488 - val_loss: 2.9962 - val_accuracy: 0.0463\n",
      "Epoch 12/200\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 2.9959 - accuracy: 0.0520 - val_loss: 2.9962 - val_accuracy: 0.0477\n",
      "Epoch 13/200\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 2.9958 - accuracy: 0.0510 - val_loss: 2.9962 - val_accuracy: 0.0463\n",
      "Epoch 14/200\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 2.9959 - accuracy: 0.0501 - val_loss: 2.9963 - val_accuracy: 0.0473\n",
      "Epoch 15/200\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 2.9959 - accuracy: 0.0506 - val_loss: 2.9963 - val_accuracy: 0.0463\n",
      "Epoch 16/200\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 2.9960 - accuracy: 0.0489 - val_loss: 2.9964 - val_accuracy: 0.0463\n",
      "Epoch 17/200\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 2.9959 - accuracy: 0.0497 - val_loss: 2.9962 - val_accuracy: 0.0463\n",
      "Epoch 18/200\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 2.9959 - accuracy: 0.0506 - val_loss: 2.9963 - val_accuracy: 0.0463\n",
      "Epoch 19/200\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 2.9958 - accuracy: 0.0498 - val_loss: 2.9960 - val_accuracy: 0.0463\n",
      "Epoch 20/200\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 2.9960 - accuracy: 0.0496 - val_loss: 2.9961 - val_accuracy: 0.0463\n",
      "Epoch 21/200\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 2.9959 - accuracy: 0.0520 - val_loss: 2.9962 - val_accuracy: 0.0463\n",
      "Epoch 22/200\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 2.9959 - accuracy: 0.0502 - val_loss: 2.9963 - val_accuracy: 0.0463\n",
      "Epoch 23/200\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 2.9959 - accuracy: 0.0516 - val_loss: 2.9964 - val_accuracy: 0.0463\n",
      "Epoch 24/200\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 2.9958 - accuracy: 0.0506 - val_loss: 2.9962 - val_accuracy: 0.0477\n",
      "Epoch 25/200\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 2.9960 - accuracy: 0.0507 - val_loss: 2.9963 - val_accuracy: 0.0488\n",
      "Epoch 26/200\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 2.9960 - accuracy: 0.0479 - val_loss: 2.9964 - val_accuracy: 0.0463\n",
      "Epoch 27/200\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 2.9957 - accuracy: 0.0524 - val_loss: 2.9960 - val_accuracy: 0.0477\n",
      "Epoch 28/200\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 2.9958 - accuracy: 0.0525 - val_loss: 2.9960 - val_accuracy: 0.0477\n",
      "Epoch 29/200\n",
      "1250/1250 [==============================] - 10s 8ms/step - loss: 2.9958 - accuracy: 0.0499 - val_loss: 2.9962 - val_accuracy: 0.0477\n",
      "Epoch 30/200\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 2.9960 - accuracy: 0.0493 - val_loss: 2.9962 - val_accuracy: 0.0477\n",
      "Epoch 31/200\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 2.9959 - accuracy: 0.0484 - val_loss: 2.9962 - val_accuracy: 0.0463\n",
      "Epoch 32/200\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 2.9960 - accuracy: 0.0475 - val_loss: 2.9962 - val_accuracy: 0.0463\n",
      "Epoch 33/200\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 2.9960 - accuracy: 0.0509 - val_loss: 2.9962 - val_accuracy: 0.0473\n",
      "Epoch 34/200\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 2.9959 - accuracy: 0.0503 - val_loss: 2.9962 - val_accuracy: 0.0473\n",
      "Epoch 35/200\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 2.9959 - accuracy: 0.0506 - val_loss: 2.9962 - val_accuracy: 0.0473\n",
      "Epoch 36/200\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 2.9958 - accuracy: 0.0483 - val_loss: 2.9961 - val_accuracy: 0.0488\n",
      "Epoch 37/200\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 2.9958 - accuracy: 0.0513 - val_loss: 2.9962 - val_accuracy: 0.0488\n",
      "Epoch 38/200\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 2.9960 - accuracy: 0.0474 - val_loss: 2.9962 - val_accuracy: 0.0477\n",
      "Epoch 39/200\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 2.9959 - accuracy: 0.0520 - val_loss: 2.9963 - val_accuracy: 0.0473\n",
      "Epoch 40/200\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 2.9959 - accuracy: 0.0494 - val_loss: 2.9963 - val_accuracy: 0.0483\n",
      "Epoch 41/200\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 2.9959 - accuracy: 0.0510 - val_loss: 2.9964 - val_accuracy: 0.0477\n",
      "Epoch 42/200\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 2.9959 - accuracy: 0.0496 - val_loss: 2.9963 - val_accuracy: 0.0463\n",
      "Epoch 43/200\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 2.9958 - accuracy: 0.0533 - val_loss: 2.9962 - val_accuracy: 0.0488\n",
      "Epoch 44/200\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 2.9959 - accuracy: 0.0522 - val_loss: 2.9962 - val_accuracy: 0.0463\n",
      "Epoch 45/200\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 2.9959 - accuracy: 0.0494 - val_loss: 2.9962 - val_accuracy: 0.0463\n",
      "Epoch 46/200\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 2.9959 - accuracy: 0.0496 - val_loss: 2.9962 - val_accuracy: 0.0477\n",
      "Epoch 47/200\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 2.9960 - accuracy: 0.0484 - val_loss: 2.9963 - val_accuracy: 0.0477\n",
      "Epoch 48/200\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 2.9958 - accuracy: 0.0527 - val_loss: 2.9961 - val_accuracy: 0.0473\n",
      "Epoch 49/200\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 2.9959 - accuracy: 0.0481 - val_loss: 2.9961 - val_accuracy: 0.0483\n",
      "Epoch 50/200\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 2.9958 - accuracy: 0.0510 - val_loss: 2.9962 - val_accuracy: 0.0463\n",
      "Epoch 51/200\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 2.9960 - accuracy: 0.0495 - val_loss: 2.9963 - val_accuracy: 0.0463\n",
      "Epoch 52/200\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 2.9959 - accuracy: 0.0522 - val_loss: 2.9962 - val_accuracy: 0.0473\n",
      "Epoch 53/200\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 2.9959 - accuracy: 0.0491 - val_loss: 2.9963 - val_accuracy: 0.0463\n",
      "Epoch 54/200\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 2.9959 - accuracy: 0.0511 - val_loss: 2.9964 - val_accuracy: 0.0463\n",
      "Epoch 55/200\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 2.9959 - accuracy: 0.0502 - val_loss: 2.9962 - val_accuracy: 0.0501\n",
      "Epoch 56/200\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 2.9959 - accuracy: 0.0486 - val_loss: 2.9963 - val_accuracy: 0.0473\n",
      "Epoch 57/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1250/1250 [==============================] - 9s 7ms/step - loss: 2.9959 - accuracy: 0.0489 - val_loss: 2.9964 - val_accuracy: 0.0463\n",
      "Epoch 58/200\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 2.9959 - accuracy: 0.0498 - val_loss: 2.9962 - val_accuracy: 0.0473\n",
      "Epoch 59/200\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 2.9959 - accuracy: 0.0489 - val_loss: 2.9963 - val_accuracy: 0.0463\n",
      "Epoch 60/200\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 2.9957 - accuracy: 0.0523 - val_loss: 2.9960 - val_accuracy: 0.0501\n",
      "Epoch 61/200\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 2.9959 - accuracy: 0.0509 - val_loss: 2.9961 - val_accuracy: 0.0477\n",
      "Epoch 62/200\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 2.9960 - accuracy: 0.0471 - val_loss: 2.9961 - val_accuracy: 0.0473\n",
      "Epoch 63/200\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 2.9959 - accuracy: 0.0515 - val_loss: 2.9961 - val_accuracy: 0.0501\n",
      "Epoch 64/200\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 2.9957 - accuracy: 0.0513 - val_loss: 2.9961 - val_accuracy: 0.0463\n",
      "Epoch 65/200\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 2.9960 - accuracy: 0.0487 - val_loss: 2.9962 - val_accuracy: 0.0489\n",
      "Epoch 66/200\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 2.9958 - accuracy: 0.0495 - val_loss: 2.9958 - val_accuracy: 0.0483\n",
      "Epoch 67/200\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 2.9959 - accuracy: 0.0494 - val_loss: 2.9961 - val_accuracy: 0.0489\n",
      "Epoch 68/200\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 2.9959 - accuracy: 0.0493 - val_loss: 2.9962 - val_accuracy: 0.0477\n",
      "Epoch 69/200\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 2.9959 - accuracy: 0.0499 - val_loss: 2.9963 - val_accuracy: 0.0473\n",
      "Epoch 70/200\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 2.9960 - accuracy: 0.0509 - val_loss: 2.9963 - val_accuracy: 0.0463\n",
      "Epoch 71/200\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 2.9958 - accuracy: 0.0472 - val_loss: 2.9961 - val_accuracy: 0.0473\n",
      "Epoch 72/200\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 2.9959 - accuracy: 0.0520 - val_loss: 2.9962 - val_accuracy: 0.0463\n",
      "Epoch 73/200\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 2.9958 - accuracy: 0.0496 - val_loss: 2.9960 - val_accuracy: 0.0502\n",
      "Epoch 74/200\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 2.9959 - accuracy: 0.0483 - val_loss: 2.9961 - val_accuracy: 0.0488\n",
      "Epoch 75/200\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 2.9959 - accuracy: 0.0511 - val_loss: 2.9960 - val_accuracy: 0.0473\n",
      "Epoch 76/200\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 2.9960 - accuracy: 0.0494 - val_loss: 2.9963 - val_accuracy: 0.0463\n",
      "Epoch 77/200\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 2.9959 - accuracy: 0.0510 - val_loss: 2.9962 - val_accuracy: 0.0473\n",
      "Epoch 78/200\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 2.9959 - accuracy: 0.0488 - val_loss: 2.9963 - val_accuracy: 0.0477\n",
      "Epoch 79/200\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 2.9958 - accuracy: 0.0507 - val_loss: 2.9961 - val_accuracy: 0.0473\n",
      "Epoch 80/200\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 2.9958 - accuracy: 0.0491 - val_loss: 2.9962 - val_accuracy: 0.0501\n",
      "Epoch 81/200\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 2.9959 - accuracy: 0.0489 - val_loss: 2.9961 - val_accuracy: 0.0463\n",
      "Epoch 82/200\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 2.9959 - accuracy: 0.0509 - val_loss: 2.9963 - val_accuracy: 0.0473\n",
      "Epoch 83/200\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 2.9960 - accuracy: 0.0477 - val_loss: 2.9962 - val_accuracy: 0.0473\n",
      "Epoch 84/200\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 2.9960 - accuracy: 0.0487 - val_loss: 2.9963 - val_accuracy: 0.0477\n",
      "Epoch 85/200\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 2.9959 - accuracy: 0.0496 - val_loss: 2.9962 - val_accuracy: 0.0502\n",
      "Epoch 86/200\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 2.9959 - accuracy: 0.0525 - val_loss: 2.9962 - val_accuracy: 0.0477\n",
      "Epoch 87/200\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 2.9960 - accuracy: 0.0463 - val_loss: 2.9961 - val_accuracy: 0.0477\n",
      "Epoch 88/200\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 2.9959 - accuracy: 0.0513 - val_loss: 2.9961 - val_accuracy: 0.0483\n",
      "Epoch 89/200\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 2.9959 - accuracy: 0.0479 - val_loss: 2.9961 - val_accuracy: 0.0483\n",
      "Epoch 90/200\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 2.9959 - accuracy: 0.0504 - val_loss: 2.9962 - val_accuracy: 0.0463\n",
      "Epoch 91/200\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 2.9959 - accuracy: 0.0477 - val_loss: 2.9961 - val_accuracy: 0.0501\n",
      "Epoch 92/200\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 2.9959 - accuracy: 0.0517 - val_loss: 2.9961 - val_accuracy: 0.0473\n",
      "Epoch 93/200\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 2.9958 - accuracy: 0.0499 - val_loss: 2.9963 - val_accuracy: 0.0463\n",
      "Epoch 94/200\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 2.9958 - accuracy: 0.0511 - val_loss: 2.9961 - val_accuracy: 0.0473\n",
      "Epoch 95/200\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 2.9958 - accuracy: 0.0503 - val_loss: 2.9960 - val_accuracy: 0.0477\n",
      "Epoch 96/200\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 2.9959 - accuracy: 0.0501 - val_loss: 2.9963 - val_accuracy: 0.0483\n",
      "Epoch 97/200\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 2.9959 - accuracy: 0.0495 - val_loss: 2.9961 - val_accuracy: 0.0502\n",
      "Epoch 98/200\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 2.9959 - accuracy: 0.0499 - val_loss: 2.9961 - val_accuracy: 0.0489\n",
      "Epoch 99/200\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 2.9960 - accuracy: 0.0494 - val_loss: 2.9962 - val_accuracy: 0.0463\n",
      "Epoch 100/200\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 2.9960 - accuracy: 0.0482 - val_loss: 2.9963 - val_accuracy: 0.0483\n",
      "Epoch 101/200\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 2.9960 - accuracy: 0.0499 - val_loss: 2.9963 - val_accuracy: 0.0463\n",
      "Epoch 102/200\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 2.9959 - accuracy: 0.0462 - val_loss: 2.9961 - val_accuracy: 0.0463\n",
      "Epoch 103/200\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 2.9959 - accuracy: 0.0495 - val_loss: 2.9963 - val_accuracy: 0.0463\n",
      "Epoch 104/200\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 2.9959 - accuracy: 0.0501 - val_loss: 2.9962 - val_accuracy: 0.0463\n",
      "Epoch 105/200\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 2.9958 - accuracy: 0.0509 - val_loss: 2.9961 - val_accuracy: 0.0477\n",
      "Epoch 106/200\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 2.9959 - accuracy: 0.0492 - val_loss: 2.9961 - val_accuracy: 0.0483\n",
      "Epoch 107/200\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 2.9959 - accuracy: 0.0469 - val_loss: 2.9960 - val_accuracy: 0.0501\n",
      "Epoch 108/200\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 2.9959 - accuracy: 0.0485 - val_loss: 2.9963 - val_accuracy: 0.0463\n",
      "Epoch 109/200\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 2.9960 - accuracy: 0.0467 - val_loss: 2.9962 - val_accuracy: 0.0473\n",
      "Epoch 110/200\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 2.9960 - accuracy: 0.0474 - val_loss: 2.9963 - val_accuracy: 0.0477\n",
      "Epoch 111/200\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 2.9959 - accuracy: 0.0474 - val_loss: 2.9963 - val_accuracy: 0.0473\n",
      "Epoch 112/200\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 2.9959 - accuracy: 0.0492 - val_loss: 2.9961 - val_accuracy: 0.0477\n",
      "Epoch 113/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1250/1250 [==============================] - 9s 7ms/step - loss: 2.9959 - accuracy: 0.0493 - val_loss: 2.9961 - val_accuracy: 0.0463\n",
      "Epoch 114/200\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 2.9958 - accuracy: 0.0502 - val_loss: 2.9962 - val_accuracy: 0.0502\n",
      "Epoch 115/200\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 2.9959 - accuracy: 0.0501 - val_loss: 2.9962 - val_accuracy: 0.0477\n",
      "Epoch 116/200\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 2.9959 - accuracy: 0.0498 - val_loss: 2.9963 - val_accuracy: 0.0502\n",
      "Epoch 117/200\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 2.9958 - accuracy: 0.0472 - val_loss: 2.9962 - val_accuracy: 0.0483\n",
      "Epoch 118/200\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 2.9960 - accuracy: 0.0496 - val_loss: 2.9962 - val_accuracy: 0.0477\n",
      "Epoch 119/200\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 2.9960 - accuracy: 0.0473 - val_loss: 2.9962 - val_accuracy: 0.0489\n",
      "Epoch 120/200\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 2.9959 - accuracy: 0.0495 - val_loss: 2.9961 - val_accuracy: 0.0473\n",
      "Epoch 121/200\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 2.9959 - accuracy: 0.0504 - val_loss: 2.9962 - val_accuracy: 0.0473\n",
      "Epoch 122/200\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 2.9959 - accuracy: 0.0499 - val_loss: 2.9962 - val_accuracy: 0.0483\n",
      "Epoch 123/200\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 2.9959 - accuracy: 0.0504 - val_loss: 2.9962 - val_accuracy: 0.0463\n",
      "Epoch 124/200\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 2.9959 - accuracy: 0.0503 - val_loss: 2.9963 - val_accuracy: 0.0483\n",
      "Epoch 125/200\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 2.9960 - accuracy: 0.0505 - val_loss: 2.9962 - val_accuracy: 0.0463\n",
      "Epoch 126/200\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 2.9959 - accuracy: 0.0518 - val_loss: 2.9963 - val_accuracy: 0.0473\n",
      "Epoch 127/200\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 2.9959 - accuracy: 0.0483 - val_loss: 2.9963 - val_accuracy: 0.0477\n",
      "Epoch 128/200\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 2.9958 - accuracy: 0.0488 - val_loss: 2.9961 - val_accuracy: 0.0477\n",
      "Epoch 129/200\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 2.9959 - accuracy: 0.0518 - val_loss: 2.9962 - val_accuracy: 0.0463\n",
      "Epoch 130/200\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 2.9960 - accuracy: 0.0496 - val_loss: 2.9962 - val_accuracy: 0.0463\n",
      "Epoch 131/200\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 2.9960 - accuracy: 0.0507 - val_loss: 2.9962 - val_accuracy: 0.0463\n",
      "Epoch 132/200\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 2.9959 - accuracy: 0.0503 - val_loss: 2.9963 - val_accuracy: 0.0463\n",
      "Epoch 133/200\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 2.9960 - accuracy: 0.0488 - val_loss: 2.9962 - val_accuracy: 0.0463\n",
      "Epoch 134/200\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 2.9960 - accuracy: 0.0483 - val_loss: 2.9962 - val_accuracy: 0.0494\n",
      "Epoch 135/200\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 2.9960 - accuracy: 0.0492 - val_loss: 2.9962 - val_accuracy: 0.0463\n",
      "Epoch 136/200\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 2.9959 - accuracy: 0.0505 - val_loss: 2.9962 - val_accuracy: 0.0463\n",
      "Epoch 137/200\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 2.9959 - accuracy: 0.0482 - val_loss: 2.9962 - val_accuracy: 0.0463\n",
      "Epoch 138/200\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 2.9959 - accuracy: 0.0518 - val_loss: 2.9961 - val_accuracy: 0.0477\n",
      "Epoch 139/200\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 2.9958 - accuracy: 0.0504 - val_loss: 2.9961 - val_accuracy: 0.0463\n",
      "Epoch 140/200\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 2.9960 - accuracy: 0.0468 - val_loss: 2.9964 - val_accuracy: 0.0463\n",
      "Epoch 141/200\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 2.9960 - accuracy: 0.0503 - val_loss: 2.9963 - val_accuracy: 0.0463\n",
      "Epoch 142/200\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 2.9958 - accuracy: 0.0509 - val_loss: 2.9961 - val_accuracy: 0.0473\n",
      "Epoch 143/200\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 2.9959 - accuracy: 0.0500 - val_loss: 2.9963 - val_accuracy: 0.0463\n",
      "Epoch 144/200\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 2.9959 - accuracy: 0.0501 - val_loss: 2.9964 - val_accuracy: 0.0463\n",
      "Epoch 145/200\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 2.9958 - accuracy: 0.0512 - val_loss: 2.9961 - val_accuracy: 0.0477\n",
      "Epoch 146/200\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 2.9958 - accuracy: 0.0498 - val_loss: 2.9961 - val_accuracy: 0.0463\n",
      "Epoch 147/200\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 2.9959 - accuracy: 0.0512 - val_loss: 2.9962 - val_accuracy: 0.0477\n",
      "Epoch 148/200\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 2.9960 - accuracy: 0.0493 - val_loss: 2.9963 - val_accuracy: 0.0463\n",
      "Epoch 149/200\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 2.9959 - accuracy: 0.0501 - val_loss: 2.9963 - val_accuracy: 0.0463\n",
      "Epoch 150/200\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 2.9958 - accuracy: 0.0534 - val_loss: 2.9961 - val_accuracy: 0.0477\n",
      "Epoch 151/200\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 2.9959 - accuracy: 0.0522 - val_loss: 2.9962 - val_accuracy: 0.0477\n",
      "Epoch 152/200\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 2.9960 - accuracy: 0.0495 - val_loss: 2.9964 - val_accuracy: 0.0463\n",
      "Epoch 153/200\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 2.9959 - accuracy: 0.0517 - val_loss: 2.9963 - val_accuracy: 0.0473\n",
      "Epoch 154/200\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 2.9959 - accuracy: 0.0507 - val_loss: 2.9962 - val_accuracy: 0.0489\n",
      "Epoch 155/200\n",
      "1250/1250 [==============================] - 10s 8ms/step - loss: 2.9959 - accuracy: 0.0497 - val_loss: 2.9960 - val_accuracy: 0.0489\n",
      "Epoch 156/200\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 2.9959 - accuracy: 0.0491 - val_loss: 2.9961 - val_accuracy: 0.0477\n",
      "Epoch 157/200\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 2.9960 - accuracy: 0.0511 - val_loss: 2.9962 - val_accuracy: 0.0463\n",
      "Epoch 158/200\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 2.9958 - accuracy: 0.0515 - val_loss: 2.9962 - val_accuracy: 0.0477\n",
      "Epoch 159/200\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 2.9959 - accuracy: 0.0478 - val_loss: 2.9962 - val_accuracy: 0.0483\n",
      "Epoch 160/200\n",
      "1250/1250 [==============================] - 10s 8ms/step - loss: 2.9960 - accuracy: 0.0515 - val_loss: 2.9962 - val_accuracy: 0.0473\n",
      "Epoch 161/200\n",
      "1250/1250 [==============================] - 10s 8ms/step - loss: 2.9958 - accuracy: 0.0499 - val_loss: 2.9961 - val_accuracy: 0.0473\n",
      "Epoch 162/200\n",
      "1250/1250 [==============================] - 10s 8ms/step - loss: 2.9959 - accuracy: 0.0526 - val_loss: 2.9961 - val_accuracy: 0.0477\n",
      "Epoch 163/200\n",
      "1250/1250 [==============================] - 10s 8ms/step - loss: 2.9959 - accuracy: 0.0499 - val_loss: 2.9962 - val_accuracy: 0.0463\n",
      "Epoch 164/200\n",
      "1250/1250 [==============================] - 10s 8ms/step - loss: 2.9958 - accuracy: 0.0501 - val_loss: 2.9961 - val_accuracy: 0.0463\n",
      "Epoch 165/200\n",
      "1250/1250 [==============================] - 10s 8ms/step - loss: 2.9960 - accuracy: 0.0489 - val_loss: 2.9962 - val_accuracy: 0.0477\n",
      "Epoch 166/200\n",
      "1250/1250 [==============================] - 10s 8ms/step - loss: 2.9960 - accuracy: 0.0481 - val_loss: 2.9963 - val_accuracy: 0.0473\n",
      "Epoch 167/200\n",
      " 548/1250 [============>.................] - ETA: 5s - loss: 2.9958 - accuracy: 0.0527"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-38-56a8b088fd80>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m history = model.fit(xTrn_split, yTrn_split, epochs=200, \n\u001b[1;32m----> 9\u001b[1;33m                     validation_data=(xTst_split, yTst_split))\n\u001b[0m",
      "\u001b[1;32mc:\\users\\lizks\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1098\u001b[0m                 _r=1):\n\u001b[0;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1100\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1101\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\lizks\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 828\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"xla\"\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\lizks\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    853\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    854\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 855\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    856\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    857\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\lizks\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[1;32m-> 2943\u001b[1;33m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[0;32m   2944\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2945\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\lizks\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1917\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1919\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\lizks\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 560\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    561\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32mc:\\users\\lizks\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[1;32m---> 60\u001b[1;33m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.add(tf.keras.layers.Flatten()) #dense layers can oinly have 1d so flattern araray to one dimension\n",
    "model.add(tf.keras.layers.Dense(64, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(output_num_coarse, activation='softmax'))\n",
    "\n",
    "model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(xTrn_split, yTrn_split, epochs=50, \n",
    "                    validation_data=(xTst_split, yTst_split))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "happy-reggae",
   "metadata": {},
   "source": [
    "###  Predict labels for the testing set and check accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "sudden-council",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.04957784 0.05003688 0.04984916 ... 0.04997031 0.04883806 0.0500895 ]\n",
      " [0.04957784 0.05003688 0.04984916 ... 0.04997031 0.04883806 0.0500895 ]\n",
      " [0.04957784 0.05003688 0.04984916 ... 0.04997031 0.04883806 0.0500895 ]\n",
      " ...\n",
      " [0.04957784 0.05003688 0.04984916 ... 0.04997031 0.04883806 0.0500895 ]\n",
      " [0.04957784 0.05003688 0.04984916 ... 0.04997031 0.04883806 0.0500895 ]\n",
      " [0.04957784 0.05003688 0.04984916 ... 0.04997031 0.04883806 0.0500895 ]]\n"
     ]
    }
   ],
   "source": [
    "print(model.predict(test_images_reshaped))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aggressive-postage",
   "metadata": {},
   "source": [
    "### Plot models traing curves "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "conditional-senegal",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "You must compile your model before training/testing. Use `model.compile(optimizer, loss)`.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-44-02db8ce51459>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'lower right'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mtest_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_acc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_images_reshaped\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[0mtest_label_coarse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_acc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\lizks\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict)\u001b[0m\n\u001b[0;32m   1340\u001b[0m     \u001b[0mbase_layer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras_api_gauge\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_cell\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'evaluate'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1341\u001b[0m     \u001b[0mversion_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdisallow_legacy_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Model'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'evaluate'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1342\u001b[1;33m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_assert_compile_was_called\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1343\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_call_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'evaluate'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1344\u001b[0m     \u001b[0m_disallow_inside_tf_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'evaluate'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\lizks\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_assert_compile_was_called\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   2590\u001b[0m     \u001b[1;31m# (i.e. whether the model is built and its inputs/outputs are set).\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2591\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_compiled\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2592\u001b[1;33m       raise RuntimeError('You must compile your model before '\n\u001b[0m\u001b[0;32m   2593\u001b[0m                          \u001b[1;34m'training/testing. '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2594\u001b[0m                          'Use `model.compile(optimizer, loss)`.')\n",
      "\u001b[1;31mRuntimeError\u001b[0m: You must compile your model before training/testing. Use `model.compile(optimizer, loss)`."
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['accuracy'], label='accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label = 'val_accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([0.5, 1])\n",
    "plt.legend(loc='lower right')\n",
    "\n",
    "test_loss, test_acc = model.evaluate(test_images_reshaped,  test_label_coarse, verbose=2)\n",
    "\n",
    "print(test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "improving-alias",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.9957950115203857, 0.05000000074505806]\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(test_images_reshaped, test_label_coarse, verbose=0)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "seven-wiring",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
