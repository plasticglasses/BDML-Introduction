{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "italian-prompt",
   "metadata": {},
   "source": [
    "# M45 Coursework\n",
    "Liz Simpson, \n",
    "951428,\n",
    "Due: Monday 19th April 2021\n",
    "## Using AlexNet and ResNet to evaluate their effectiveness on classifying objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "patient-employee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "#Train-validation-test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#Onehot Encoding the labels.\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "#Image Data Augmentation\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "#Alex Net Models\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout, Flatten, Conv2D, MaxPooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "\n",
    "#Graphs \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Evaluation \n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "#ResNet\n",
    "import h5py\n",
    "import copy\n",
    "from scipy.io import savemat,loadmat\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore',category=FutureWarning)\n",
    "import tensorflow as tf\n",
    "print('Tensorflow version = ',tensorflow.__version__)\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler, History\n",
    "from ResNetModel import resnet\n",
    "from Utils import cutout,LR_WarmRestart,GetDataGen,plot_history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fourth-actor",
   "metadata": {},
   "source": [
    "## Loading Data \n",
    "\n",
    "CIFAR-100 Dataset using fine labels that labels data into 100 classes and coarse dataset that categorises the data into 20 superclasses. All images are 32x32 w x h and have an RGB value. There are 50000 images in the train dataset and 10000 in the test dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "accessible-demographic",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images Shape: (32, 32, 3, 50000)\n",
      "Train Labels Coarse Shape: (50000,)\n"
     ]
    }
   ],
   "source": [
    "images = np.load('trnImage.npy')\n",
    "labels = np.load('trnLabel_coarse.npy')\n",
    "labels_fine = np.load('trnLabel_fine.npy')\n",
    "\n",
    "test_images = np.load('tstImage.npy')\n",
    "test_labels = np.load('tstLabel_coarse.npy')\n",
    "test_labels_fine = np.load('tstLabel_fine.npy')\n",
    "\n",
    "print(f'Images Shape: {images.shape}')\n",
    "print(f'Train Labels Coarse Shape: {labels.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "figured-medicaid",
   "metadata": {},
   "source": [
    "# \n",
    "# Alex Net Coarse\n",
    "### Build the AlexNet with 11 layers \n",
    "Layers include convolutional2D layers, Activation layers using the ReLu and Softmax functions, BatchNormalisation and Max Pooling layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "collective-colorado",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_5 (Conv2D)            (None, 8, 8, 96)          34944     \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 8, 8, 96)          384       \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 8, 8, 96)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 4, 4, 96)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 4, 4, 256)         614656    \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 4, 4, 256)         1024      \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 2, 2, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 2, 2, 384)         885120    \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 2, 2, 384)         1536      \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 2, 2, 384)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 2, 2, 384)         1327488   \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, 2, 2, 384)         1536      \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 2, 2, 384)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 2, 2, 256)         884992    \n",
      "_________________________________________________________________\n",
      "batch_normalization_13 (Batc (None, 2, 2, 256)         1024      \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 2, 2, 256)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 1, 1, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 4096)              1052672   \n",
      "_________________________________________________________________\n",
      "batch_normalization_14 (Batc (None, 4096)              16384     \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "batch_normalization_15 (Batc (None, 4096)              16384     \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1000)              4097000   \n",
      "_________________________________________________________________\n",
      "batch_normalization_16 (Batc (None, 1000)              4000      \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 20)                20020     \n",
      "_________________________________________________________________\n",
      "batch_normalization_17 (Batc (None, 20)                80        \n",
      "_________________________________________________________________\n",
      "activation_17 (Activation)   (None, 20)                0         \n",
      "=================================================================\n",
      "Total params: 25,740,556\n",
      "Trainable params: 25,719,380\n",
      "Non-trainable params: 21,176\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1000)\n",
    "\n",
    "#Instantiation\n",
    "AlexNet = Sequential()\n",
    "\n",
    "#1st Convolutional Layer\n",
    "AlexNet.add(Conv2D(filters=96, input_shape=(32,32,3), kernel_size=(11,11), strides=(4,4), padding='same'))\n",
    "AlexNet.add(BatchNormalization())\n",
    "AlexNet.add(Activation('relu'))\n",
    "AlexNet.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='same'))\n",
    "\n",
    "#2nd Convolutional Layer\n",
    "AlexNet.add(Conv2D(filters=256, kernel_size=(5, 5), strides=(1,1), padding='same'))\n",
    "AlexNet.add(BatchNormalization())\n",
    "AlexNet.add(Activation('relu'))\n",
    "AlexNet.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='same'))\n",
    "\n",
    "#3rd Convolutional Layer\n",
    "AlexNet.add(Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='same'))\n",
    "AlexNet.add(BatchNormalization())\n",
    "AlexNet.add(Activation('relu'))\n",
    "\n",
    "#4th Convolutional Layer\n",
    "AlexNet.add(Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='same'))\n",
    "AlexNet.add(BatchNormalization())\n",
    "AlexNet.add(Activation('relu'))\n",
    "\n",
    "#5th Convolutional Layer\n",
    "AlexNet.add(Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), padding='same'))\n",
    "AlexNet.add(BatchNormalization())\n",
    "AlexNet.add(Activation('relu'))\n",
    "AlexNet.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='same'))\n",
    "\n",
    "#Passing it to a Fully Connected layer\n",
    "AlexNet.add(Flatten())\n",
    "# 1st Fully Connected Layer\n",
    "AlexNet.add(Dense(4096, input_shape=(32,32,3,)))\n",
    "AlexNet.add(BatchNormalization())\n",
    "AlexNet.add(Activation('relu'))\n",
    "# Add Dropout to prevent overfitting\n",
    "AlexNet.add(Dropout(0.4))\n",
    "\n",
    "#2nd Fully Connected Layer\n",
    "AlexNet.add(Dense(4096))\n",
    "AlexNet.add(BatchNormalization())\n",
    "AlexNet.add(Activation('relu'))\n",
    "#Add Dropout\n",
    "AlexNet.add(Dropout(0.4))\n",
    "\n",
    "#3rd Fully Connected Layer\n",
    "AlexNet.add(Dense(1000))\n",
    "AlexNet.add(BatchNormalization())\n",
    "AlexNet.add(Activation('relu'))\n",
    "#Add Dropout\n",
    "AlexNet.add(Dropout(0.4))\n",
    "\n",
    "#Output Layer\n",
    "AlexNet.add(Dense(20))\n",
    "AlexNet.add(BatchNormalization())\n",
    "AlexNet.add(Activation('softmax'))\n",
    "\n",
    "#Model Summary\n",
    "AlexNet.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "coupled-accuracy",
   "metadata": {},
   "source": [
    "### Complie AlexNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "mental-underground",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the model\n",
    "AlexNet.compile(loss = keras.losses.categorical_crossentropy, optimizer= 'adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eleven-finnish",
   "metadata": {},
   "source": [
    "### Change input shapes on Coarse Dataset\n",
    "Training Data needs shape ((35000, 32, 32, 3)\n",
    "Training Labels need shape (35000, 100))\n",
    "\n",
    "Use imagedataGenerators to generate enough data for the model from existing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "timely-malawi",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((35000, 32, 32, 3), (35000, 100))\n",
      "((15000, 32, 32, 3), (15000, 100))\n",
      "((10000, 32, 32, 3), (10000, 20))\n"
     ]
    }
   ],
   "source": [
    "x_train = np.transpose(images, (3, 0, 1, 2))\n",
    "y_train = labels.reshape(50000, 1)\n",
    "\n",
    "x_test = np.transpose(test_images, (3, 0, 1, 2))\n",
    "y_test = test_labels\n",
    "\n",
    "#Train-validation-test split\n",
    "x_train,x_val,y_train,y_val=train_test_split(x_train,y_train,test_size=0.3)\n",
    "\n",
    "#Since we have 20 classes we should expect the shape[1] of y_train,y_val and y_test to change from 1 to 20\n",
    "y_train=to_categorical(y_train)\n",
    "y_val=to_categorical(y_val)\n",
    "y_test=to_categorical(y_test)\n",
    "\n",
    "#Verifying the dimension after one hot encoding\n",
    "print((x_train.shape,y_train.shape))\n",
    "print((x_val.shape,y_val.shape))\n",
    "print((x_test.shape,y_test.shape))\n",
    "\n",
    "#Image Data Augmentation\n",
    "train_generator = ImageDataGenerator(rotation_range=2, horizontal_flip=True,zoom_range=.1 )\n",
    "val_generator = ImageDataGenerator(rotation_range=2, horizontal_flip=True,zoom_range=.1)\n",
    "test_generator = ImageDataGenerator(rotation_range=2, horizontal_flip= True,zoom_range=.1)\n",
    "\n",
    "#Fitting the augmentation defined above to the data\n",
    "train_generator.fit(x_train)\n",
    "val_generator.fit(x_val)\n",
    "test_generator.fit(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "trained-workstation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images Shape: (50000, 32, 32, 3)\n",
      "Train Labels Coarse Shape: (10000, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "print(f'Images Shape: {train_images_reshaped.shape}')\n",
    "print(f'Train Labels Coarse Shape: {test_images_reshaped.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "catholic-document",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining the parameters\n",
    "batch_size= 100\n",
    "epochs=100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "religious-journey",
   "metadata": {},
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "criminal-situation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "350/350 [==============================] - 156s 442ms/step - loss: 2.6588 - accuracy: 0.1843 - val_loss: 3.0741 - val_accuracy: 0.1523\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 159s 455ms/step - loss: 2.3056 - accuracy: 0.2861 - val_loss: 3.1576 - val_accuracy: 0.1925\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 161s 461ms/step - loss: 2.1845 - accuracy: 0.3224 - val_loss: 2.4502 - val_accuracy: 0.2684\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 154s 441ms/step - loss: 2.0883 - accuracy: 0.3517 - val_loss: 2.7001 - val_accuracy: 0.2463\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 147s 420ms/step - loss: 2.0153 - accuracy: 0.3740 - val_loss: 2.2482 - val_accuracy: 0.3184\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 148s 422ms/step - loss: 1.9406 - accuracy: 0.3971 - val_loss: 3.1157 - val_accuracy: 0.2049\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 148s 423ms/step - loss: 1.8967 - accuracy: 0.4132 - val_loss: 2.1929 - val_accuracy: 0.3353\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 147s 420ms/step - loss: 1.8187 - accuracy: 0.4330 - val_loss: 2.1430 - val_accuracy: 0.3483\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 147s 421ms/step - loss: 1.7739 - accuracy: 0.4493 - val_loss: 2.2262 - val_accuracy: 0.3218\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 147s 420ms/step - loss: 1.7233 - accuracy: 0.4650 - val_loss: 2.3573 - val_accuracy: 0.3281\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 148s 423ms/step - loss: 1.6769 - accuracy: 0.4786 - val_loss: 2.3861 - val_accuracy: 0.3165\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 144s 412ms/step - loss: 1.6334 - accuracy: 0.4927 - val_loss: 2.2658 - val_accuracy: 0.3256\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 152s 434ms/step - loss: 1.5788 - accuracy: 0.5048 - val_loss: 2.1086 - val_accuracy: 0.3633\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 156s 446ms/step - loss: 1.5405 - accuracy: 0.5192 - val_loss: 2.0351 - val_accuracy: 0.3887\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 159s 454ms/step - loss: 1.4962 - accuracy: 0.5306 - val_loss: 1.8658 - val_accuracy: 0.4283\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 158s 450ms/step - loss: 1.4693 - accuracy: 0.5394 - val_loss: 1.9435 - val_accuracy: 0.4116\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 158s 451ms/step - loss: 1.4089 - accuracy: 0.5616 - val_loss: 1.9772 - val_accuracy: 0.4061\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 160s 456ms/step - loss: 1.3854 - accuracy: 0.5625 - val_loss: 2.0219 - val_accuracy: 0.4060\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 158s 453ms/step - loss: 1.3316 - accuracy: 0.5846 - val_loss: 2.2602 - val_accuracy: 0.3741\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 160s 457ms/step - loss: 1.2931 - accuracy: 0.5948 - val_loss: 2.1312 - val_accuracy: 0.3763\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 161s 459ms/step - loss: 1.2608 - accuracy: 0.6039 - val_loss: 2.2598 - val_accuracy: 0.3681\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 160s 456ms/step - loss: 1.2180 - accuracy: 0.6222 - val_loss: 2.1283 - val_accuracy: 0.3873\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 155s 444ms/step - loss: 1.1611 - accuracy: 0.6367 - val_loss: 2.2156 - val_accuracy: 0.3953\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 157s 447ms/step - loss: 1.1477 - accuracy: 0.6385 - val_loss: 2.2408 - val_accuracy: 0.3924\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 160s 456ms/step - loss: 1.1151 - accuracy: 0.6546 - val_loss: 2.0054 - val_accuracy: 0.4363\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 162s 463ms/step - loss: 1.0676 - accuracy: 0.6681 - val_loss: 1.9118 - val_accuracy: 0.4488\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 162s 462ms/step - loss: 1.0339 - accuracy: 0.6769 - val_loss: 1.9486 - val_accuracy: 0.4456\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 162s 462ms/step - loss: 1.0126 - accuracy: 0.6869 - val_loss: 2.3170 - val_accuracy: 0.3682\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 166s 473ms/step - loss: 0.9811 - accuracy: 0.6955 - val_loss: 2.0258 - val_accuracy: 0.4258\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 162s 464ms/step - loss: 0.9433 - accuracy: 0.7056 - val_loss: 2.4976 - val_accuracy: 0.3629\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 163s 467ms/step - loss: 0.9217 - accuracy: 0.7106 - val_loss: 2.2125 - val_accuracy: 0.4207\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 163s 465ms/step - loss: 0.8741 - accuracy: 0.7247 - val_loss: 2.1654 - val_accuracy: 0.4236\n",
      "Epoch 33/100\n",
      "350/350 [==============================] - 159s 455ms/step - loss: 0.8611 - accuracy: 0.7326 - val_loss: 2.2485 - val_accuracy: 0.4073\n",
      "Epoch 34/100\n",
      "350/350 [==============================] - 158s 451ms/step - loss: 0.8285 - accuracy: 0.7432 - val_loss: 2.3264 - val_accuracy: 0.3968\n",
      "Epoch 35/100\n",
      "350/350 [==============================] - 157s 447ms/step - loss: 0.8006 - accuracy: 0.7500 - val_loss: 2.1233 - val_accuracy: 0.4452\n",
      "Epoch 36/100\n",
      "350/350 [==============================] - 158s 451ms/step - loss: 0.7938 - accuracy: 0.7498 - val_loss: 2.1879 - val_accuracy: 0.4266\n",
      "Epoch 37/100\n",
      "350/350 [==============================] - 160s 457ms/step - loss: 0.7647 - accuracy: 0.7612 - val_loss: 2.2467 - val_accuracy: 0.4222\n",
      "Epoch 38/100\n",
      "350/350 [==============================] - 160s 456ms/step - loss: 0.7429 - accuracy: 0.7659 - val_loss: 2.3501 - val_accuracy: 0.3946\n",
      "Epoch 39/100\n",
      "350/350 [==============================] - 156s 445ms/step - loss: 0.7089 - accuracy: 0.7803 - val_loss: 2.2250 - val_accuracy: 0.4276\n",
      "Epoch 40/100\n",
      "350/350 [==============================] - 157s 448ms/step - loss: 0.6940 - accuracy: 0.7813 - val_loss: 2.3740 - val_accuracy: 0.4195\n",
      "Epoch 41/100\n",
      "350/350 [==============================] - 156s 447ms/step - loss: 0.6697 - accuracy: 0.7919 - val_loss: 2.2557 - val_accuracy: 0.4242\n",
      "Epoch 42/100\n",
      "350/350 [==============================] - 161s 461ms/step - loss: 0.6616 - accuracy: 0.7934 - val_loss: 2.2895 - val_accuracy: 0.4418\n",
      "Epoch 43/100\n",
      "350/350 [==============================] - 159s 453ms/step - loss: 0.6370 - accuracy: 0.8018 - val_loss: 2.1834 - val_accuracy: 0.4407\n",
      "Epoch 44/100\n",
      "350/350 [==============================] - 159s 454ms/step - loss: 0.6233 - accuracy: 0.8060 - val_loss: 2.3646 - val_accuracy: 0.4228\n",
      "Epoch 45/100\n",
      "350/350 [==============================] - 159s 453ms/step - loss: 0.5930 - accuracy: 0.8164 - val_loss: 2.3138 - val_accuracy: 0.4377\n",
      "Epoch 46/100\n",
      "350/350 [==============================] - 156s 446ms/step - loss: 0.5850 - accuracy: 0.8201 - val_loss: 2.3934 - val_accuracy: 0.4226\n",
      "Epoch 47/100\n",
      "350/350 [==============================] - 155s 441ms/step - loss: 0.5659 - accuracy: 0.8232 - val_loss: 2.2698 - val_accuracy: 0.4465\n",
      "Epoch 48/100\n",
      "350/350 [==============================] - 157s 447ms/step - loss: 0.5523 - accuracy: 0.8264 - val_loss: 2.3708 - val_accuracy: 0.4417\n",
      "Epoch 49/100\n",
      "350/350 [==============================] - 155s 444ms/step - loss: 0.5240 - accuracy: 0.8381 - val_loss: 2.4140 - val_accuracy: 0.4240\n",
      "Epoch 50/100\n",
      "350/350 [==============================] - 157s 450ms/step - loss: 0.5281 - accuracy: 0.8354 - val_loss: 2.1736 - val_accuracy: 0.4677\n",
      "Epoch 51/100\n",
      "350/350 [==============================] - 158s 452ms/step - loss: 0.5022 - accuracy: 0.8434 - val_loss: 2.3057 - val_accuracy: 0.4469\n",
      "Epoch 52/100\n",
      "350/350 [==============================] - 155s 443ms/step - loss: 0.4968 - accuracy: 0.8442 - val_loss: 2.5245 - val_accuracy: 0.4278\n",
      "Epoch 53/100\n",
      "350/350 [==============================] - 153s 438ms/step - loss: 0.4809 - accuracy: 0.8514 - val_loss: 2.3686 - val_accuracy: 0.4481\n",
      "Epoch 54/100\n",
      "350/350 [==============================] - 154s 440ms/step - loss: 0.4553 - accuracy: 0.8597 - val_loss: 2.3857 - val_accuracy: 0.4447\n",
      "Epoch 55/100\n",
      "350/350 [==============================] - 154s 439ms/step - loss: 0.4568 - accuracy: 0.8563 - val_loss: 2.2365 - val_accuracy: 0.4668\n",
      "Epoch 56/100\n",
      "350/350 [==============================] - 153s 436ms/step - loss: 0.4478 - accuracy: 0.8606 - val_loss: 2.3500 - val_accuracy: 0.4586\n",
      "Epoch 57/100\n",
      "350/350 [==============================] - 154s 439ms/step - loss: 0.4257 - accuracy: 0.8667 - val_loss: 2.6994 - val_accuracy: 0.4104\n",
      "Epoch 58/100\n",
      "350/350 [==============================] - 154s 440ms/step - loss: 0.4139 - accuracy: 0.8722 - val_loss: 2.3925 - val_accuracy: 0.4527\n",
      "Epoch 59/100\n",
      "350/350 [==============================] - 154s 439ms/step - loss: 0.3917 - accuracy: 0.8778 - val_loss: 2.6760 - val_accuracy: 0.4070\n",
      "Epoch 60/100\n",
      "350/350 [==============================] - 153s 438ms/step - loss: 0.4041 - accuracy: 0.8734 - val_loss: 2.3306 - val_accuracy: 0.4711\n",
      "Epoch 61/100\n",
      "350/350 [==============================] - 152s 433ms/step - loss: 0.3915 - accuracy: 0.8779 - val_loss: 2.4518 - val_accuracy: 0.4429\n",
      "Epoch 62/100\n",
      "350/350 [==============================] - 154s 441ms/step - loss: 0.3888 - accuracy: 0.8797 - val_loss: 2.6027 - val_accuracy: 0.4355\n",
      "Epoch 63/100\n",
      "350/350 [==============================] - 154s 441ms/step - loss: 0.3735 - accuracy: 0.8840 - val_loss: 2.5586 - val_accuracy: 0.4388\n",
      "Epoch 64/100\n",
      "350/350 [==============================] - 157s 449ms/step - loss: 0.3602 - accuracy: 0.8870 - val_loss: 2.4561 - val_accuracy: 0.4681\n",
      "Epoch 65/100\n",
      "350/350 [==============================] - 163s 464ms/step - loss: 0.3624 - accuracy: 0.8870 - val_loss: 2.5045 - val_accuracy: 0.4568\n",
      "Epoch 66/100\n",
      "350/350 [==============================] - 161s 459ms/step - loss: 0.3446 - accuracy: 0.8933 - val_loss: 2.4759 - val_accuracy: 0.4626\n",
      "Epoch 67/100\n",
      "350/350 [==============================] - 161s 459ms/step - loss: 0.3395 - accuracy: 0.8914 - val_loss: 2.4824 - val_accuracy: 0.4599\n",
      "Epoch 68/100\n",
      "350/350 [==============================] - 161s 460ms/step - loss: 0.3249 - accuracy: 0.8986 - val_loss: 2.4529 - val_accuracy: 0.4684\n",
      "Epoch 69/100\n",
      "350/350 [==============================] - 161s 459ms/step - loss: 0.3256 - accuracy: 0.8977 - val_loss: 2.8444 - val_accuracy: 0.4165\n",
      "Epoch 70/100\n",
      "350/350 [==============================] - 160s 456ms/step - loss: 0.3209 - accuracy: 0.8988 - val_loss: 2.5540 - val_accuracy: 0.4493\n",
      "Epoch 71/100\n",
      "350/350 [==============================] - 158s 452ms/step - loss: 0.3079 - accuracy: 0.9042 - val_loss: 2.5341 - val_accuracy: 0.4617\n",
      "Epoch 72/100\n",
      "350/350 [==============================] - 160s 458ms/step - loss: 0.2985 - accuracy: 0.9069 - val_loss: 2.5438 - val_accuracy: 0.4563\n",
      "Epoch 73/100\n",
      "350/350 [==============================] - 161s 459ms/step - loss: 0.2927 - accuracy: 0.9103 - val_loss: 2.5920 - val_accuracy: 0.4500\n",
      "Epoch 74/100\n",
      "350/350 [==============================] - 159s 454ms/step - loss: 0.2891 - accuracy: 0.9106 - val_loss: 2.5814 - val_accuracy: 0.4599\n",
      "Epoch 75/100\n",
      "350/350 [==============================] - 156s 445ms/step - loss: 0.2806 - accuracy: 0.9102 - val_loss: 2.5749 - val_accuracy: 0.4534\n",
      "Epoch 76/100\n",
      "350/350 [==============================] - 154s 439ms/step - loss: 0.2780 - accuracy: 0.9118 - val_loss: 2.5722 - val_accuracy: 0.4531\n",
      "Epoch 77/100\n",
      "350/350 [==============================] - 151s 433ms/step - loss: 0.2658 - accuracy: 0.9165 - val_loss: 2.5933 - val_accuracy: 0.4538\n",
      "Epoch 78/100\n",
      "350/350 [==============================] - 154s 439ms/step - loss: 0.2705 - accuracy: 0.9150 - val_loss: 2.4952 - val_accuracy: 0.4678\n",
      "Epoch 79/100\n",
      "350/350 [==============================] - 154s 441ms/step - loss: 0.2605 - accuracy: 0.9180 - val_loss: 2.5499 - val_accuracy: 0.4587\n",
      "Epoch 80/100\n",
      "350/350 [==============================] - 157s 448ms/step - loss: 0.2633 - accuracy: 0.9154 - val_loss: 2.6273 - val_accuracy: 0.4561\n",
      "Epoch 81/100\n",
      "350/350 [==============================] - 150s 430ms/step - loss: 0.2611 - accuracy: 0.9168 - val_loss: 2.5869 - val_accuracy: 0.4629\n",
      "Epoch 82/100\n",
      "350/350 [==============================] - 151s 432ms/step - loss: 0.2508 - accuracy: 0.9219 - val_loss: 2.5912 - val_accuracy: 0.4630\n",
      "Epoch 83/100\n",
      "350/350 [==============================] - 153s 436ms/step - loss: 0.2431 - accuracy: 0.9239 - val_loss: 2.6687 - val_accuracy: 0.4588\n",
      "Epoch 84/100\n",
      "350/350 [==============================] - 154s 439ms/step - loss: 0.2408 - accuracy: 0.9246 - val_loss: 2.5736 - val_accuracy: 0.4694\n",
      "Epoch 85/100\n",
      "350/350 [==============================] - 152s 436ms/step - loss: 0.2284 - accuracy: 0.9281 - val_loss: 2.6344 - val_accuracy: 0.4579\n",
      "Epoch 86/100\n",
      "350/350 [==============================] - 159s 454ms/step - loss: 0.2354 - accuracy: 0.9264 - val_loss: 2.5587 - val_accuracy: 0.4806\n",
      "Epoch 87/100\n",
      "350/350 [==============================] - 155s 443ms/step - loss: 0.2335 - accuracy: 0.9276 - val_loss: 2.7524 - val_accuracy: 0.4476\n",
      "Epoch 88/100\n",
      "350/350 [==============================] - 155s 442ms/step - loss: 0.2265 - accuracy: 0.9299 - val_loss: 2.6399 - val_accuracy: 0.4745\n",
      "Epoch 89/100\n",
      "350/350 [==============================] - 153s 437ms/step - loss: 0.2145 - accuracy: 0.9309 - val_loss: 2.6270 - val_accuracy: 0.4654\n",
      "Epoch 90/100\n",
      "350/350 [==============================] - 153s 436ms/step - loss: 0.2162 - accuracy: 0.9322 - val_loss: 2.9407 - val_accuracy: 0.4406\n",
      "Epoch 91/100\n",
      "350/350 [==============================] - 150s 429ms/step - loss: 0.2118 - accuracy: 0.9340 - val_loss: 2.6775 - val_accuracy: 0.4725\n",
      "Epoch 92/100\n",
      "350/350 [==============================] - 151s 430ms/step - loss: 0.2050 - accuracy: 0.9348 - val_loss: 2.8054 - val_accuracy: 0.4509\n",
      "Epoch 93/100\n",
      "350/350 [==============================] - 150s 428ms/step - loss: 0.2099 - accuracy: 0.9340 - val_loss: 2.7317 - val_accuracy: 0.4599\n",
      "Epoch 94/100\n",
      "350/350 [==============================] - 150s 428ms/step - loss: 0.1920 - accuracy: 0.9399 - val_loss: 2.6517 - val_accuracy: 0.4692\n",
      "Epoch 95/100\n",
      "350/350 [==============================] - 149s 424ms/step - loss: 0.2007 - accuracy: 0.9370 - val_loss: 2.8189 - val_accuracy: 0.4499\n",
      "Epoch 96/100\n",
      "350/350 [==============================] - 149s 426ms/step - loss: 0.2003 - accuracy: 0.9371 - val_loss: 2.7006 - val_accuracy: 0.4666\n",
      "Epoch 97/100\n",
      "350/350 [==============================] - 148s 424ms/step - loss: 0.1961 - accuracy: 0.9394 - val_loss: 2.7948 - val_accuracy: 0.4501\n",
      "Epoch 98/100\n",
      "350/350 [==============================] - 149s 426ms/step - loss: 0.1879 - accuracy: 0.9410 - val_loss: 2.7679 - val_accuracy: 0.4649\n",
      "Epoch 99/100\n",
      "350/350 [==============================] - 148s 424ms/step - loss: 0.1901 - accuracy: 0.9403 - val_loss: 2.7598 - val_accuracy: 0.4660\n",
      "Epoch 100/100\n",
      "350/350 [==============================] - 149s 425ms/step - loss: 0.1842 - accuracy: 0.9410 - val_loss: 2.7415 - val_accuracy: 0.4749\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x23a0a2bdd08>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Training the model\n",
    "AlexNet.fit(train_generator.flow(x_train, y_train, batch_size=batch_size), epochs = epochs, steps_per_epoch = x_train.shape[0]//batch_size, validation_data = val_generator.flow(x_val, y_val, batch_size=batch_size), validation_steps = len(x_val)//batch_size, verbose=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acknowledged-determination",
   "metadata": {},
   "source": [
    "# Save and Load Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "challenging-utilization",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: alexNet_coarse\\assets\n"
     ]
    }
   ],
   "source": [
    "AlexNet.save('alexNet_coarse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "alleged-complexity",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tensorflow.python.keras.engine.sequential.Sequential object at 0x0000023A0C727608>\n"
     ]
    }
   ],
   "source": [
    "history = keras.models.load_model('alexNet_coarse')\n",
    "print(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "massive-shore",
   "metadata": {},
   "source": [
    "# AlexNet Coarse Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "corporate-inspector",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.43103271e-03 2.69028940e-03 3.49790382e-04 ... 2.72551752e-05\n",
      "  2.52320140e-04 1.88424962e-03]\n",
      " [2.16222252e-03 4.38046787e-04 7.33196503e-04 ... 1.40379707e-03\n",
      "  7.08199479e-03 1.51955225e-02]\n",
      " [6.87568307e-01 5.32912761e-02 1.24701794e-04 ... 2.19036080e-03\n",
      "  7.20124692e-04 5.95821766e-04]\n",
      " ...\n",
      " [4.05122182e-06 4.74672015e-05 1.19327306e-04 ... 1.09232997e-03\n",
      "  4.17817546e-06 4.70710911e-05]\n",
      " [1.22256446e-04 2.36951033e-04 5.94038574e-05 ... 9.82776037e-05\n",
      "  1.53403322e-04 8.84392575e-05]\n",
      " [5.14362864e-06 2.89375748e-04 9.96861339e-01 ... 3.85577034e-04\n",
      "  6.31554358e-05 2.98790110e-05]]\n"
     ]
    }
   ],
   "source": [
    "print(AlexNet.predict(test_images_reshaped))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "outer-inside",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = AlexNetFineHistory.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "first-fifty",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n"
     ]
    }
   ],
   "source": [
    "print(np.unique(test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "trained-choice",
   "metadata": {},
   "source": [
    "# Alex Coarse Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "clinical-nightlife",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of multiclass and continuous-multioutput targets",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-61-b8aebcf08eb5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mpredictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mAlexNetFineHistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_images_reshaped\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mcm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_labels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_labels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mdisp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mConfusionMatrixDisplay\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfusion_matrix\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdisplay_labels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_labels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mdisp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\lizks\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\lizks\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36mconfusion_matrix\u001b[1;34m(y_true, y_pred, labels, sample_weight, normalize)\u001b[0m\n\u001b[0;32m    294\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    295\u001b[0m     \"\"\"\n\u001b[1;32m--> 296\u001b[1;33m     \u001b[0my_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    297\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"binary\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"multiclass\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    298\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"%s is not supported\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0my_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\lizks\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     91\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m         raise ValueError(\"Classification metrics can't handle a mix of {0} \"\n\u001b[1;32m---> 93\u001b[1;33m                          \"and {1} targets\".format(type_true, type_pred))\n\u001b[0m\u001b[0;32m     94\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m     \u001b[1;31m# We can't have more than one value on y_type => The set is no more needed\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Classification metrics can't handle a mix of multiclass and continuous-multioutput targets"
     ]
    }
   ],
   "source": [
    "predictions = AlexNetFineHistory.predict(test_images_reshaped)\n",
    "cm = confusion_matrix(np.array(test_labels), np.array(predictions), labels=np.unique(test_labels))\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=np.unique(test_labels))\n",
    "disp.plot() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "elementary-james",
   "metadata": {},
   "outputs": [],
   "source": [
    "if self.binary:\n",
    "  test_confusion = ConfusionMatrixDisplay(confusion_matrix(self.val_y.data.cpu().numpy(), np.array(predictions)),display_labels=['Benign','Attack'])\n",
    "else:\n",
    "  test_confusion = ConfusionMatrixDisplay(confusion_matrix(self.val_y.data.cpu().numpy(), \n",
    "                                                                 np.array(predictions)),\n",
    "                                                    display_labels=['Benign','MSSQL','UDP','LDAP','NetBIOS','Portmap'])\n",
    "        \n",
    "print(\"(Top) Training Confusion Matrix\")\n",
    "train_confusion.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "minor-pacific",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-51-f0b59a90c7d6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'val_accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'val_accuracy'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Epoch'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Accuracy'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mylim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "plt.plot(history.history['accuracy'], label='accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label = 'val_accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([0.5, 1])\n",
    "plt.legend(loc='lower right')\n",
    "\n",
    "test_loss, test_acc = AlexNet.evaluate(test_images_reshaped,  test_labels_coarse, verbose=2)\n",
    "\n",
    "print(test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "forced-encyclopedia",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    c:\\users\\lizks\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1233 test_function  *\n        return step_function(self, iterator)\n    c:\\users\\lizks\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1224 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    c:\\users\\lizks\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1259 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    c:\\users\\lizks\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2730 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    c:\\users\\lizks\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:3417 _call_for_each_replica\n        return fn(*args, **kwargs)\n    c:\\users\\lizks\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1217 run_step  **\n        outputs = model.test_step(data)\n    c:\\users\\lizks\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1186 test_step\n        y, y_pred, sample_weight, regularization_losses=self.losses)\n    c:\\users\\lizks\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\compile_utils.py:203 __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    c:\\users\\lizks\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\keras\\losses.py:152 __call__\n        losses = call_fn(y_true, y_pred)\n    c:\\users\\lizks\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\keras\\losses.py:256 call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    c:\\users\\lizks\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:201 wrapper\n        return target(*args, **kwargs)\n    c:\\users\\lizks\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\keras\\losses.py:1537 categorical_crossentropy\n        return K.categorical_crossentropy(y_true, y_pred, from_logits=from_logits)\n    c:\\users\\lizks\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:201 wrapper\n        return target(*args, **kwargs)\n    c:\\users\\lizks\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py:4833 categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n    c:\\users\\lizks\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_shape.py:1134 assert_is_compatible_with\n        raise ValueError(\"Shapes %s and %s are incompatible\" % (self, other))\n\n    ValueError: Shapes (None, 1) and (None, 20) are incompatible\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-59-359898dc3de7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mAlexNet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_images_reshaped\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mAlexNet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_images\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_labels_fine\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\lizks\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict)\u001b[0m\n\u001b[0;32m   1387\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'test'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstep_num\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_r\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1388\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_test_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1389\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1390\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1391\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\lizks\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 828\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"xla\"\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\lizks\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    860\u001b[0m       \u001b[1;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    861\u001b[0m       \u001b[1;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 862\u001b[1;33m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    863\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    864\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001b[1;32mc:\\users\\lizks\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2939\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2940\u001b[0m       (graph_function,\n\u001b[1;32m-> 2941\u001b[1;33m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0m\u001b[0;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m   2943\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n",
      "\u001b[1;32mc:\\users\\lizks\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   3356\u001b[0m               call_context_key in self._function_cache.missed):\n\u001b[0;32m   3357\u001b[0m             return self._define_function_with_shape_relaxation(\n\u001b[1;32m-> 3358\u001b[1;33m                 args, kwargs, flat_args, filtered_flat_args, cache_key_context)\n\u001b[0m\u001b[0;32m   3359\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3360\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\lizks\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_define_function_with_shape_relaxation\u001b[1;34m(self, args, kwargs, flat_args, filtered_flat_args, cache_key_context)\u001b[0m\n\u001b[0;32m   3278\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3279\u001b[0m     graph_function = self._create_graph_function(\n\u001b[1;32m-> 3280\u001b[1;33m         args, kwargs, override_flat_arg_shapes=relaxed_arg_shapes)\n\u001b[0m\u001b[0;32m   3281\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marg_relaxed\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mrank_only_cache_key\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3282\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\lizks\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[1;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m   3204\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3205\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3206\u001b[1;33m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[0;32m   3207\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3208\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\lizks\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m    988\u001b[0m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    989\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 990\u001b[1;33m       \u001b[0mfunc_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    991\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    992\u001b[0m       \u001b[1;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\lizks\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m    632\u001b[0m             \u001b[0mxla_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    633\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 634\u001b[1;33m           \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    635\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    636\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\lizks\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    975\u001b[0m           \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint:disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    976\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"ag_error_metadata\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 977\u001b[1;33m               \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    978\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    979\u001b[0m               \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    c:\\users\\lizks\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1233 test_function  *\n        return step_function(self, iterator)\n    c:\\users\\lizks\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1224 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    c:\\users\\lizks\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1259 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    c:\\users\\lizks\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2730 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    c:\\users\\lizks\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:3417 _call_for_each_replica\n        return fn(*args, **kwargs)\n    c:\\users\\lizks\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1217 run_step  **\n        outputs = model.test_step(data)\n    c:\\users\\lizks\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1186 test_step\n        y, y_pred, sample_weight, regularization_losses=self.losses)\n    c:\\users\\lizks\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\compile_utils.py:203 __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    c:\\users\\lizks\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\keras\\losses.py:152 __call__\n        losses = call_fn(y_true, y_pred)\n    c:\\users\\lizks\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\keras\\losses.py:256 call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    c:\\users\\lizks\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:201 wrapper\n        return target(*args, **kwargs)\n    c:\\users\\lizks\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\keras\\losses.py:1537 categorical_crossentropy\n        return K.categorical_crossentropy(y_true, y_pred, from_logits=from_logits)\n    c:\\users\\lizks\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:201 wrapper\n        return target(*args, **kwargs)\n    c:\\users\\lizks\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py:4833 categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n    c:\\users\\lizks\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_shape.py:1134 assert_is_compatible_with\n        raise ValueError(\"Shapes %s and %s are incompatible\" % (self, other))\n\n    ValueError: Shapes (None, 1) and (None, 20) are incompatible\n"
     ]
    }
   ],
   "source": [
    "score = AlexNet.evaluate(test_images_reshaped, test_labels, verbose=0)\n",
    "print(score)\n",
    "\n",
    "score = AlexNet.evaluate(test_images, test_labels_fine, verbose=0)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "engaging-postcard",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "worse-presence",
   "metadata": {},
   "source": [
    "# Alex Net Fine "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alpha-tutorial",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.transpose(images, (3, 0, 1, 2))\n",
    "test_images_reshaped = np.transpose(test_images, (3, 0, 1, 2))\n",
    "labels_reshaped = labels.reshape(50000, 1)\n",
    "\n",
    "labels_fine_reshaped = labels_fine.reshape(50000, 1)\n",
    "\n",
    "\n",
    "#y_train = labels_reshaped\n",
    "y_train = labels_fine_reshaped\n",
    "\n",
    "x_test = test_images_reshaped\n",
    "y_test = test_labels\n",
    "\n",
    "#Train-validation-test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_val,y_train,y_val=train_test_split(x_train,y_train,test_size=0.3)\n",
    "\n",
    "\n",
    "#Onehot Encoding the labels.\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "#Since we have 20 classes we should expect the shape[1] of y_train,y_val and y_test to change from 1 to 20\n",
    "y_train=to_categorical(y_train)\n",
    "y_val=to_categorical(y_val)\n",
    "y_test=to_categorical(y_test)\n",
    "\n",
    "#Verifying the dimension after one hot encoding\n",
    "print((x_train.shape,y_train.shape))\n",
    "print((x_val.shape,y_val.shape))\n",
    "print((x_test.shape,y_test.shape))\n",
    "\n",
    "#Image Data Augmentation\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_generator = ImageDataGenerator(rotation_range=2, horizontal_flip=True,zoom_range=.1 )\n",
    "val_generator = ImageDataGenerator(rotation_range=2, horizontal_flip=True,zoom_range=.1)\n",
    "test_generator = ImageDataGenerator(rotation_range=2, horizontal_flip= True,zoom_range=.1)\n",
    "\n",
    "#Fitting the augmentation defined above to the data\n",
    "train_generator.fit(x_train)\n",
    "val_generator.fit(x_val)\n",
    "test_generator.fit(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "reasonable-miller",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_15 (Conv2D)           (None, 8, 8, 96)          34944     \n",
      "_________________________________________________________________\n",
      "batch_normalization_27 (Batc (None, 8, 8, 96)          384       \n",
      "_________________________________________________________________\n",
      "activation_27 (Activation)   (None, 8, 8, 96)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 4, 4, 96)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_16 (Conv2D)           (None, 4, 4, 256)         614656    \n",
      "_________________________________________________________________\n",
      "batch_normalization_28 (Batc (None, 4, 4, 256)         1024      \n",
      "_________________________________________________________________\n",
      "activation_28 (Activation)   (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 2, 2, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 2, 2, 384)         885120    \n",
      "_________________________________________________________________\n",
      "batch_normalization_29 (Batc (None, 2, 2, 384)         1536      \n",
      "_________________________________________________________________\n",
      "activation_29 (Activation)   (None, 2, 2, 384)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_18 (Conv2D)           (None, 2, 2, 384)         1327488   \n",
      "_________________________________________________________________\n",
      "batch_normalization_30 (Batc (None, 2, 2, 384)         1536      \n",
      "_________________________________________________________________\n",
      "activation_30 (Activation)   (None, 2, 2, 384)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_19 (Conv2D)           (None, 2, 2, 256)         884992    \n",
      "_________________________________________________________________\n",
      "batch_normalization_31 (Batc (None, 2, 2, 256)         1024      \n",
      "_________________________________________________________________\n",
      "activation_31 (Activation)   (None, 2, 2, 256)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling (None, 1, 1, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 4096)              1052672   \n",
      "_________________________________________________________________\n",
      "batch_normalization_32 (Batc (None, 4096)              16384     \n",
      "_________________________________________________________________\n",
      "activation_32 (Activation)   (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "batch_normalization_33 (Batc (None, 4096)              16384     \n",
      "_________________________________________________________________\n",
      "activation_33 (Activation)   (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 1000)              4097000   \n",
      "_________________________________________________________________\n",
      "batch_normalization_34 (Batc (None, 1000)              4000      \n",
      "_________________________________________________________________\n",
      "activation_34 (Activation)   (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 100)               100100    \n",
      "_________________________________________________________________\n",
      "batch_normalization_35 (Batc (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "activation_35 (Activation)   (None, 100)               0         \n",
      "=================================================================\n",
      "Total params: 25,820,956\n",
      "Trainable params: 25,799,620\n",
      "Non-trainable params: 21,336\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Importing library\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout, Flatten, Conv2D, MaxPooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(1000)\n",
    "\n",
    "#Instantiation\n",
    "AlexNetFine = Sequential()\n",
    "\n",
    "#1st Convolutional Layer\n",
    "AlexNetFine.add(Conv2D(filters=96, input_shape=(32,32,3), kernel_size=(11,11), strides=(4,4), padding='same'))\n",
    "AlexNetFine.add(BatchNormalization())\n",
    "AlexNetFine.add(Activation('relu'))\n",
    "AlexNetFine.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='same'))\n",
    "\n",
    "#2nd Convolutional Layer\n",
    "AlexNetFine.add(Conv2D(filters=256, kernel_size=(5, 5), strides=(1,1), padding='same'))\n",
    "AlexNetFine.add(BatchNormalization())\n",
    "AlexNetFine.add(Activation('relu'))\n",
    "AlexNetFine.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='same'))\n",
    "\n",
    "#3rd Convolutional Layer\n",
    "AlexNetFine.add(Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='same'))\n",
    "AlexNetFine.add(BatchNormalization())\n",
    "AlexNetFine.add(Activation('relu'))\n",
    "\n",
    "#4th Convolutional Layer\n",
    "AlexNetFine.add(Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='same'))\n",
    "AlexNetFine.add(BatchNormalization())\n",
    "AlexNetFine.add(Activation('relu'))\n",
    "\n",
    "#5th Convolutional Layer\n",
    "AlexNetFine.add(Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), padding='same'))\n",
    "AlexNetFine.add(BatchNormalization())\n",
    "AlexNetFine.add(Activation('relu'))\n",
    "AlexNetFine.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='same'))\n",
    "\n",
    "#Passing it to a Fully Connected layer\n",
    "AlexNetFine.add(Flatten())\n",
    "# 1st Fully Connected Layer\n",
    "AlexNetFine.add(Dense(4096, input_shape=(32,32,3,)))\n",
    "AlexNetFine.add(BatchNormalization())\n",
    "AlexNetFine.add(Activation('relu'))\n",
    "# Add Dropout to prevent overfitting\n",
    "AlexNetFine.add(Dropout(0.4))\n",
    "\n",
    "#2nd Fully Connected Layer\n",
    "AlexNetFine.add(Dense(4096))\n",
    "AlexNetFine.add(BatchNormalization())\n",
    "AlexNetFine.add(Activation('relu'))\n",
    "#Add Dropout\n",
    "AlexNet.add(Dropout(0.4))\n",
    "\n",
    "#3rd Fully Connected Layer\n",
    "AlexNetFine.add(Dense(1000))\n",
    "AlexNetFine.add(BatchNormalization())\n",
    "AlexNetFine.add(Activation('relu'))\n",
    "#Add Dropout\n",
    "AlexNetFine.add(Dropout(0.4))\n",
    "\n",
    "#Output Layer\n",
    "AlexNetFine.add(Dense(100))\n",
    "AlexNetFine.add(BatchNormalization())\n",
    "AlexNetFine.add(Activation('softmax'))\n",
    "\n",
    "#Model Summary\n",
    "AlexNetFine.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "powered-anger",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the model\n",
    "AlexNetFine.compile(loss = keras.losses.categorical_crossentropy, optimizer= 'adam', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "turned-practitioner",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "350/350 [==============================] - 152s 432ms/step - loss: 4.2240 - accuracy: 0.0668 - val_loss: 4.0814 - val_accuracy: 0.0837\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 152s 434ms/step - loss: 3.6774 - accuracy: 0.1317 - val_loss: 3.8463 - val_accuracy: 0.1213\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 150s 429ms/step - loss: 3.4801 - accuracy: 0.1654 - val_loss: 3.9826 - val_accuracy: 0.1068\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 154s 440ms/step - loss: 3.3198 - accuracy: 0.1967 - val_loss: 4.0372 - val_accuracy: 0.1150\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 156s 446ms/step - loss: 3.1956 - accuracy: 0.2146 - val_loss: 3.9655 - val_accuracy: 0.1228\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 155s 442ms/step - loss: 3.1008 - accuracy: 0.2354 - val_loss: 3.9543 - val_accuracy: 0.1234\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 154s 439ms/step - loss: 3.0194 - accuracy: 0.2490 - val_loss: 3.8983 - val_accuracy: 0.1403\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 154s 439ms/step - loss: 2.9353 - accuracy: 0.2671 - val_loss: 3.3514 - val_accuracy: 0.1943\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 152s 434ms/step - loss: 2.8587 - accuracy: 0.2766 - val_loss: 3.8833 - val_accuracy: 0.1564\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 153s 438ms/step - loss: 2.7843 - accuracy: 0.2936 - val_loss: 3.2141 - val_accuracy: 0.2217\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 153s 438ms/step - loss: 2.7344 - accuracy: 0.3044 - val_loss: 3.1015 - val_accuracy: 0.2472\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 153s 436ms/step - loss: 2.6784 - accuracy: 0.3120 - val_loss: 3.2784 - val_accuracy: 0.2133\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 153s 436ms/step - loss: 2.6035 - accuracy: 0.3262 - val_loss: 3.0499 - val_accuracy: 0.2517\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 152s 434ms/step - loss: 2.5658 - accuracy: 0.3358 - val_loss: 3.0732 - val_accuracy: 0.2500\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 151s 432ms/step - loss: 2.5137 - accuracy: 0.3476 - val_loss: 3.3070 - val_accuracy: 0.2231\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 151s 432ms/step - loss: 2.4657 - accuracy: 0.3555 - val_loss: 3.1061 - val_accuracy: 0.2441\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 151s 431ms/step - loss: 2.3970 - accuracy: 0.3734 - val_loss: 3.1075 - val_accuracy: 0.2559\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 150s 428ms/step - loss: 2.3554 - accuracy: 0.3771 - val_loss: 3.4336 - val_accuracy: 0.2180\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 149s 426ms/step - loss: 2.3067 - accuracy: 0.3896 - val_loss: 2.9422 - val_accuracy: 0.2829\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 149s 424ms/step - loss: 2.2454 - accuracy: 0.4031 - val_loss: 2.8943 - val_accuracy: 0.2845\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 148s 424ms/step - loss: 2.1941 - accuracy: 0.4163 - val_loss: 3.1176 - val_accuracy: 0.2639\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 149s 425ms/step - loss: 2.1494 - accuracy: 0.4288 - val_loss: 2.9925 - val_accuracy: 0.2801\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 149s 424ms/step - loss: 2.1018 - accuracy: 0.4433 - val_loss: 2.9041 - val_accuracy: 0.2987\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 148s 422ms/step - loss: 2.0586 - accuracy: 0.4534 - val_loss: 3.0877 - val_accuracy: 0.2727\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 148s 423ms/step - loss: 1.9946 - accuracy: 0.4650 - val_loss: 3.0930 - val_accuracy: 0.2806\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 148s 423ms/step - loss: 1.9425 - accuracy: 0.4762 - val_loss: 2.8784 - val_accuracy: 0.3080\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 147s 421ms/step - loss: 1.9000 - accuracy: 0.4830 - val_loss: 2.9972 - val_accuracy: 0.2839\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 148s 423ms/step - loss: 1.8644 - accuracy: 0.4955 - val_loss: 3.0340 - val_accuracy: 0.2915\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 149s 426ms/step - loss: 1.8033 - accuracy: 0.5107 - val_loss: 3.1847 - val_accuracy: 0.2752\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 148s 422ms/step - loss: 1.7813 - accuracy: 0.5144 - val_loss: 3.3022 - val_accuracy: 0.2606\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 150s 428ms/step - loss: 1.7276 - accuracy: 0.5282 - val_loss: 2.8928 - val_accuracy: 0.3209\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 147s 421ms/step - loss: 1.6663 - accuracy: 0.5424 - val_loss: 3.1443 - val_accuracy: 0.2955\n",
      "Epoch 33/100\n",
      "350/350 [==============================] - 147s 421ms/step - loss: 1.6412 - accuracy: 0.5474 - val_loss: 3.3613 - val_accuracy: 0.2800\n",
      "Epoch 34/100\n",
      "350/350 [==============================] - 148s 423ms/step - loss: 1.6080 - accuracy: 0.5594 - val_loss: 3.2202 - val_accuracy: 0.2868\n",
      "Epoch 35/100\n",
      "350/350 [==============================] - 147s 421ms/step - loss: 1.5572 - accuracy: 0.5652 - val_loss: 3.1504 - val_accuracy: 0.2952\n",
      "Epoch 36/100\n",
      "350/350 [==============================] - 149s 427ms/step - loss: 1.5219 - accuracy: 0.5741 - val_loss: 2.9466 - val_accuracy: 0.3184\n",
      "Epoch 37/100\n",
      "350/350 [==============================] - 149s 427ms/step - loss: 1.5052 - accuracy: 0.5791 - val_loss: 3.1075 - val_accuracy: 0.3113\n",
      "Epoch 38/100\n",
      "350/350 [==============================] - 149s 427ms/step - loss: 1.4598 - accuracy: 0.5950 - val_loss: 3.1811 - val_accuracy: 0.3026\n",
      "Epoch 39/100\n",
      "350/350 [==============================] - 149s 426ms/step - loss: 1.4256 - accuracy: 0.6007 - val_loss: 3.0275 - val_accuracy: 0.3137\n",
      "Epoch 40/100\n",
      "350/350 [==============================] - 149s 427ms/step - loss: 1.3763 - accuracy: 0.6162 - val_loss: 3.1491 - val_accuracy: 0.3145\n",
      "Epoch 41/100\n",
      "350/350 [==============================] - 150s 428ms/step - loss: 1.3680 - accuracy: 0.6180 - val_loss: 3.1204 - val_accuracy: 0.3139\n",
      "Epoch 42/100\n",
      "350/350 [==============================] - 150s 427ms/step - loss: 1.3344 - accuracy: 0.6283 - val_loss: 3.3095 - val_accuracy: 0.3007\n",
      "Epoch 43/100\n",
      "350/350 [==============================] - 150s 430ms/step - loss: 1.2893 - accuracy: 0.6390 - val_loss: 3.2278 - val_accuracy: 0.3113\n",
      "Epoch 44/100\n",
      "350/350 [==============================] - 149s 426ms/step - loss: 1.2638 - accuracy: 0.6471 - val_loss: 3.3081 - val_accuracy: 0.3069\n",
      "Epoch 45/100\n",
      "350/350 [==============================] - 148s 422ms/step - loss: 1.2385 - accuracy: 0.6527 - val_loss: 3.1646 - val_accuracy: 0.3277\n",
      "Epoch 46/100\n",
      "350/350 [==============================] - 148s 422ms/step - loss: 1.1995 - accuracy: 0.6585 - val_loss: 3.1722 - val_accuracy: 0.3259\n",
      "Epoch 47/100\n",
      "350/350 [==============================] - 148s 422ms/step - loss: 1.1781 - accuracy: 0.6703 - val_loss: 3.2502 - val_accuracy: 0.3144\n",
      "Epoch 48/100\n",
      "350/350 [==============================] - 148s 422ms/step - loss: 1.1419 - accuracy: 0.6726 - val_loss: 3.2642 - val_accuracy: 0.3200\n",
      "Epoch 49/100\n",
      "350/350 [==============================] - 150s 429ms/step - loss: 1.1054 - accuracy: 0.6869 - val_loss: 3.1746 - val_accuracy: 0.3316\n",
      "Epoch 50/100\n",
      "350/350 [==============================] - 154s 441ms/step - loss: 1.0806 - accuracy: 0.6943 - val_loss: 3.3786 - val_accuracy: 0.3009\n",
      "Epoch 51/100\n",
      "350/350 [==============================] - 155s 444ms/step - loss: 1.0619 - accuracy: 0.6991 - val_loss: 3.3275 - val_accuracy: 0.3180\n",
      "Epoch 52/100\n",
      "350/350 [==============================] - 156s 444ms/step - loss: 1.0343 - accuracy: 0.7083 - val_loss: 3.3423 - val_accuracy: 0.3151\n",
      "Epoch 53/100\n",
      "350/350 [==============================] - 157s 449ms/step - loss: 1.0139 - accuracy: 0.7091 - val_loss: 3.3067 - val_accuracy: 0.3292\n",
      "Epoch 54/100\n",
      "350/350 [==============================] - 158s 451ms/step - loss: 0.9740 - accuracy: 0.7221 - val_loss: 3.2500 - val_accuracy: 0.3364\n",
      "Epoch 55/100\n",
      "350/350 [==============================] - 156s 446ms/step - loss: 0.9483 - accuracy: 0.7306 - val_loss: 3.3278 - val_accuracy: 0.3280\n",
      "Epoch 56/100\n",
      "350/350 [==============================] - 153s 438ms/step - loss: 0.9274 - accuracy: 0.7346 - val_loss: 3.5297 - val_accuracy: 0.3080\n",
      "Epoch 57/100\n",
      "350/350 [==============================] - 154s 441ms/step - loss: 0.9132 - accuracy: 0.7345 - val_loss: 3.3203 - val_accuracy: 0.3343\n",
      "Epoch 58/100\n",
      "350/350 [==============================] - 152s 434ms/step - loss: 0.8776 - accuracy: 0.7442 - val_loss: 3.6489 - val_accuracy: 0.2981\n",
      "Epoch 59/100\n",
      "350/350 [==============================] - 158s 450ms/step - loss: 0.8665 - accuracy: 0.7504 - val_loss: 3.6179 - val_accuracy: 0.3097\n",
      "Epoch 60/100\n",
      "350/350 [==============================] - 156s 447ms/step - loss: 0.8337 - accuracy: 0.7577 - val_loss: 3.5939 - val_accuracy: 0.3192\n",
      "Epoch 61/100\n",
      "350/350 [==============================] - 153s 436ms/step - loss: 0.8199 - accuracy: 0.7655 - val_loss: 3.5278 - val_accuracy: 0.3250\n",
      "Epoch 62/100\n",
      "350/350 [==============================] - 158s 451ms/step - loss: 0.7986 - accuracy: 0.7707 - val_loss: 3.4888 - val_accuracy: 0.3287\n",
      "Epoch 63/100\n",
      "350/350 [==============================] - 158s 452ms/step - loss: 0.7799 - accuracy: 0.7756 - val_loss: 3.5911 - val_accuracy: 0.3277\n",
      "Epoch 64/100\n",
      "350/350 [==============================] - 159s 455ms/step - loss: 0.7438 - accuracy: 0.7849 - val_loss: 3.5703 - val_accuracy: 0.3225\n",
      "Epoch 65/100\n",
      "350/350 [==============================] - 160s 457ms/step - loss: 0.7101 - accuracy: 0.7984 - val_loss: 3.5011 - val_accuracy: 0.3433\n",
      "Epoch 66/100\n",
      "350/350 [==============================] - 153s 438ms/step - loss: 0.7051 - accuracy: 0.7989 - val_loss: 3.7273 - val_accuracy: 0.3104\n",
      "Epoch 67/100\n",
      "350/350 [==============================] - 158s 450ms/step - loss: 0.6960 - accuracy: 0.7967 - val_loss: 3.7247 - val_accuracy: 0.3198\n",
      "Epoch 68/100\n",
      "350/350 [==============================] - 153s 437ms/step - loss: 0.6817 - accuracy: 0.8019 - val_loss: 3.6285 - val_accuracy: 0.3369\n",
      "Epoch 69/100\n",
      "350/350 [==============================] - 156s 445ms/step - loss: 0.6688 - accuracy: 0.8066 - val_loss: 3.5603 - val_accuracy: 0.3375\n",
      "Epoch 70/100\n",
      "350/350 [==============================] - 157s 449ms/step - loss: 0.6442 - accuracy: 0.8148 - val_loss: 3.6048 - val_accuracy: 0.3333\n",
      "Epoch 71/100\n",
      "350/350 [==============================] - 155s 442ms/step - loss: 0.6288 - accuracy: 0.8199 - val_loss: 3.7032 - val_accuracy: 0.3303\n",
      "Epoch 72/100\n",
      "350/350 [==============================] - 156s 446ms/step - loss: 0.5955 - accuracy: 0.8268 - val_loss: 3.6242 - val_accuracy: 0.3410\n",
      "Epoch 73/100\n",
      "350/350 [==============================] - 158s 451ms/step - loss: 0.5702 - accuracy: 0.8364 - val_loss: 3.6336 - val_accuracy: 0.3370\n",
      "Epoch 74/100\n",
      "350/350 [==============================] - 158s 452ms/step - loss: 0.5907 - accuracy: 0.8310 - val_loss: 3.7307 - val_accuracy: 0.3266\n",
      "Epoch 75/100\n",
      "350/350 [==============================] - 157s 449ms/step - loss: 0.5613 - accuracy: 0.8347 - val_loss: 3.7587 - val_accuracy: 0.3378\n",
      "Epoch 76/100\n",
      "350/350 [==============================] - 160s 457ms/step - loss: 0.5423 - accuracy: 0.8414 - val_loss: 3.6858 - val_accuracy: 0.3432\n",
      "Epoch 77/100\n",
      "350/350 [==============================] - 158s 452ms/step - loss: 0.5332 - accuracy: 0.8460 - val_loss: 3.8192 - val_accuracy: 0.3301\n",
      "Epoch 78/100\n",
      "350/350 [==============================] - 155s 442ms/step - loss: 0.5158 - accuracy: 0.8510 - val_loss: 3.8369 - val_accuracy: 0.3327\n",
      "Epoch 79/100\n",
      "350/350 [==============================] - 156s 445ms/step - loss: 0.5096 - accuracy: 0.8528 - val_loss: 3.6562 - val_accuracy: 0.3497\n",
      "Epoch 80/100\n",
      "350/350 [==============================] - 156s 445ms/step - loss: 0.4928 - accuracy: 0.8562 - val_loss: 3.7744 - val_accuracy: 0.3304\n",
      "Epoch 81/100\n",
      "350/350 [==============================] - 158s 452ms/step - loss: 0.4918 - accuracy: 0.8570 - val_loss: 3.7294 - val_accuracy: 0.3433\n",
      "Epoch 82/100\n",
      "350/350 [==============================] - 172s 491ms/step - loss: 0.4708 - accuracy: 0.8609 - val_loss: 4.0584 - val_accuracy: 0.3143\n",
      "Epoch 83/100\n",
      "350/350 [==============================] - 156s 445ms/step - loss: 0.4625 - accuracy: 0.8634 - val_loss: 3.7973 - val_accuracy: 0.3422\n",
      "Epoch 84/100\n",
      "350/350 [==============================] - 154s 440ms/step - loss: 0.4392 - accuracy: 0.8728 - val_loss: 3.8131 - val_accuracy: 0.3409\n",
      "Epoch 85/100\n",
      "350/350 [==============================] - 155s 444ms/step - loss: 0.4520 - accuracy: 0.8664 - val_loss: 3.7822 - val_accuracy: 0.3455\n",
      "Epoch 86/100\n",
      "350/350 [==============================] - 152s 434ms/step - loss: 0.4319 - accuracy: 0.8745 - val_loss: 3.8095 - val_accuracy: 0.3399\n",
      "Epoch 87/100\n",
      "350/350 [==============================] - 149s 427ms/step - loss: 0.4149 - accuracy: 0.8790 - val_loss: 3.8918 - val_accuracy: 0.3370\n",
      "Epoch 88/100\n",
      "350/350 [==============================] - 155s 442ms/step - loss: 0.4037 - accuracy: 0.8811 - val_loss: 3.9116 - val_accuracy: 0.3307\n",
      "Epoch 89/100\n",
      "350/350 [==============================] - 172s 490ms/step - loss: 0.3972 - accuracy: 0.8837 - val_loss: 3.9280 - val_accuracy: 0.3333\n",
      "Epoch 90/100\n",
      "350/350 [==============================] - 223s 637ms/step - loss: 0.3775 - accuracy: 0.8912 - val_loss: 4.0818 - val_accuracy: 0.3192\n",
      "Epoch 91/100\n",
      "350/350 [==============================] - 166s 475ms/step - loss: 0.3810 - accuracy: 0.8867 - val_loss: 3.8624 - val_accuracy: 0.3470\n",
      "Epoch 92/100\n",
      "350/350 [==============================] - 158s 452ms/step - loss: 0.3761 - accuracy: 0.8905 - val_loss: 3.9866 - val_accuracy: 0.3303\n",
      "Epoch 93/100\n",
      "350/350 [==============================] - 156s 445ms/step - loss: 0.3792 - accuracy: 0.8918 - val_loss: 3.9563 - val_accuracy: 0.3452\n",
      "Epoch 94/100\n",
      "350/350 [==============================] - 156s 447ms/step - loss: 0.3569 - accuracy: 0.8959 - val_loss: 4.0188 - val_accuracy: 0.3257\n",
      "Epoch 95/100\n",
      "350/350 [==============================] - 155s 443ms/step - loss: 0.3544 - accuracy: 0.8985 - val_loss: 3.9142 - val_accuracy: 0.3405\n",
      "Epoch 96/100\n",
      "350/350 [==============================] - 165s 472ms/step - loss: 0.3496 - accuracy: 0.8984 - val_loss: 3.9353 - val_accuracy: 0.3371\n",
      "Epoch 97/100\n",
      "350/350 [==============================] - 169s 481ms/step - loss: 0.3461 - accuracy: 0.8982 - val_loss: 4.1174 - val_accuracy: 0.3255\n",
      "Epoch 98/100\n",
      "350/350 [==============================] - 184s 526ms/step - loss: 0.3420 - accuracy: 0.9006 - val_loss: 4.0128 - val_accuracy: 0.3282\n",
      "Epoch 99/100\n",
      "350/350 [==============================] - 211s 602ms/step - loss: 0.3355 - accuracy: 0.9014 - val_loss: 3.9206 - val_accuracy: 0.3429\n",
      "Epoch 100/100\n",
      "350/350 [==============================] - 212s 607ms/step - loss: 0.3174 - accuracy: 0.9073 - val_loss: 3.9445 - val_accuracy: 0.3390\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x23a09085dc8>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AlexNetFine.fit(, epochs = epochs, steps_per_epoch = x_train.shape[0]//batch_size, validation_data = val_generator.flow(x_val, y_val, batch_size=batch_size), validation_steps = len(x_test)//batch_size, verbose=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "minor-caribbean",
   "metadata": {},
   "source": [
    "# Test and load Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "forced-arkansas",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: alexNet_fine\\assets\n"
     ]
    }
   ],
   "source": [
    "AlexNetFine.save('alexNet_fine')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "touched-housing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: resNet_coarse_fail\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save('resNet_coarse_fail')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "listed-harbor",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "vanilla-future",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_y' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-24f84c525a0f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'resNet_coarse_fail'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'train_y' is not defined"
     ]
    }
   ],
   "source": [
    "history = tf.keras.models.load_model('resNet_coarse_fail')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "biblical-stake",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 32, 32, 3) for input KerasTensor(type_spec=TensorSpec(shape=(None, 32, 32, 3), dtype=tf.float32, name='input_4'), name='input_4', description=\"created by layer 'input_4'\"), but it was called on an input with incompatible shape (None, 1).\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    c:\\users\\lizks\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1478 predict_function  *\n        return step_function(self, iterator)\n    c:\\users\\lizks\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1468 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    c:\\users\\lizks\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1259 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    c:\\users\\lizks\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2730 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    c:\\users\\lizks\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:3417 _call_for_each_replica\n        return fn(*args, **kwargs)\n    c:\\users\\lizks\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1461 run_step  **\n        outputs = model.predict_step(data)\n    c:\\users\\lizks\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1434 predict_step\n        return self(x, training=False)\n    c:\\users\\lizks\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py:1012 __call__\n        outputs = call_fn(inputs, *args, **kwargs)\n    c:\\users\\lizks\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\functional.py:425 call\n        inputs, training=training, mask=mask)\n    c:\\users\\lizks\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\functional.py:560 _run_internal_graph\n        outputs = node.layer(*args, **kwargs)\n    c:\\users\\lizks\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py:998 __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs, self.name)\n    c:\\users\\lizks\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\input_spec.py:223 assert_input_compatibility\n        str(tuple(shape)))\n\n    ValueError: Input 0 of layer conv1_pad is incompatible with the layer: expected ndim=4, found ndim=2. Full shape received: (None, 1)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-51f769375651>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\lizks\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1627\u001b[0m           \u001b[1;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1628\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_predict_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1629\u001b[1;33m             \u001b[0mtmp_batch_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1630\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1631\u001b[0m               \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\lizks\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 828\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"xla\"\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\lizks\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    869\u001b[0m       \u001b[1;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    870\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 871\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    872\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    873\u001b[0m       \u001b[1;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\lizks\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[1;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[0;32m    724\u001b[0m     self._concrete_stateful_fn = (\n\u001b[0;32m    725\u001b[0m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[1;32m--> 726\u001b[1;33m             *args, **kwds))\n\u001b[0m\u001b[0;32m    727\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    728\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0minvalid_creator_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0munused_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0munused_kwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\lizks\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2967\u001b[0m       \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2968\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2969\u001b[1;33m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2970\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2971\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\lizks\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   3359\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3360\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3361\u001b[1;33m           \u001b[0mgraph_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3362\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3363\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\lizks\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[1;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m   3204\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3205\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3206\u001b[1;33m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[0;32m   3207\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3208\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\lizks\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m    988\u001b[0m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    989\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 990\u001b[1;33m       \u001b[0mfunc_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    991\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    992\u001b[0m       \u001b[1;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\lizks\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m    632\u001b[0m             \u001b[0mxla_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    633\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 634\u001b[1;33m           \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    635\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    636\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\lizks\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    975\u001b[0m           \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint:disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    976\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"ag_error_metadata\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 977\u001b[1;33m               \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    978\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    979\u001b[0m               \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    c:\\users\\lizks\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1478 predict_function  *\n        return step_function(self, iterator)\n    c:\\users\\lizks\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1468 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    c:\\users\\lizks\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1259 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    c:\\users\\lizks\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2730 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    c:\\users\\lizks\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:3417 _call_for_each_replica\n        return fn(*args, **kwargs)\n    c:\\users\\lizks\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1461 run_step  **\n        outputs = model.predict_step(data)\n    c:\\users\\lizks\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1434 predict_step\n        return self(x, training=False)\n    c:\\users\\lizks\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py:1012 __call__\n        outputs = call_fn(inputs, *args, **kwargs)\n    c:\\users\\lizks\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\functional.py:425 call\n        inputs, training=training, mask=mask)\n    c:\\users\\lizks\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\functional.py:560 _run_internal_graph\n        outputs = node.layer(*args, **kwargs)\n    c:\\users\\lizks\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py:998 __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs, self.name)\n    c:\\users\\lizks\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\input_spec.py:223 assert_input_compatibility\n        str(tuple(shape)))\n\n    ValueError: Input 0 of layer conv1_pad is incompatible with the layer: expected ndim=4, found ndim=2. Full shape received: (None, 1)\n"
     ]
    }
   ],
   "source": [
    "print(history.predict(y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interim-dating",
   "metadata": {},
   "source": [
    "# \n",
    "# \n",
    "# ResNet50 Coarse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "important-realtor",
   "metadata": {},
   "outputs": [],
   "source": [
    "#params\n",
    "init_lr = 0.1\n",
    "epochs = 50\n",
    "batch_size = 50\n",
    "My_wd=5e-4/2\n",
    "resnet_width = 10\n",
    "resnet_depth = 20\n",
    "UseBinary=False\n",
    "UseCutout=True\n",
    "Loss = 'categorical_crossentropy'\n",
    "Optimizer = SGD(lr=init_lr,decay=0.0, momentum=0.9, nesterov=False)\n",
    "Metrics = ['accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "transsexual-bottle",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32, 32, 3)\n",
      "(50000, 1)\n",
      "(10000, 32, 32, 3)\n",
      "(10000, 1)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "x_train = np.load('trnImage.npy')\n",
    "y_train = np.load('trnLabel_coarse.npy')\n",
    "#labels_fine = np.load('trnLabel_fine.npy')\n",
    "\n",
    "x_test = np.load('tstImage.npy')\n",
    "y_test = np.load('tstLabel_coarse.npy')\n",
    "#test_labels_fine = np.load('tstLabel_fine.npy')\n",
    "\n",
    "x_train = np.transpose(x_train, (3, 0, 1, 2))\n",
    "x_test = np.transpose(x_test, (3, 0, 1, 2))\n",
    "y_train = y_train.reshape(50000, 1)\n",
    "y_test = y_test.reshape(10000, 1)\n",
    "\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)\n",
    "\n",
    "num_classes = np.unique(y_train).shape[0]\n",
    "K_train = x_train.shape[0]\n",
    "input_shape = x_train.shape[1:]\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "y_train = tf.keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "danish-immunology",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_7 (InputLayer)            [(None, 32, 32, 3)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_105 (BatchN (None, 32, 32, 3)    12          input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_100 (Conv2D)             (None, 32, 32, 160)  4320        batch_normalization_105[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_106 (BatchN (None, 32, 32, 160)  320         conv2d_100[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_100 (Activation)     (None, 32, 32, 160)  0           batch_normalization_106[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_101 (Conv2D)             (None, 32, 32, 160)  230400      activation_100[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_107 (BatchN (None, 32, 32, 160)  320         conv2d_101[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_101 (Activation)     (None, 32, 32, 160)  0           batch_normalization_107[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_102 (Conv2D)             (None, 32, 32, 160)  230400      activation_101[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_45 (Add)                    (None, 32, 32, 160)  0           conv2d_102[0][0]                 \n",
      "                                                                 conv2d_100[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_108 (BatchN (None, 32, 32, 160)  320         add_45[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_102 (Activation)     (None, 32, 32, 160)  0           batch_normalization_108[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_103 (Conv2D)             (None, 32, 32, 160)  230400      activation_102[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_109 (BatchN (None, 32, 32, 160)  320         conv2d_103[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_103 (Activation)     (None, 32, 32, 160)  0           batch_normalization_109[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_104 (Conv2D)             (None, 32, 32, 160)  230400      activation_103[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_46 (Add)                    (None, 32, 32, 160)  0           conv2d_104[0][0]                 \n",
      "                                                                 add_45[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_110 (BatchN (None, 32, 32, 160)  320         add_46[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_104 (Activation)     (None, 32, 32, 160)  0           batch_normalization_110[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_105 (Conv2D)             (None, 32, 32, 160)  230400      activation_104[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_111 (BatchN (None, 32, 32, 160)  320         conv2d_105[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_105 (Activation)     (None, 32, 32, 160)  0           batch_normalization_111[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_106 (Conv2D)             (None, 32, 32, 160)  230400      activation_105[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_47 (Add)                    (None, 32, 32, 160)  0           conv2d_106[0][0]                 \n",
      "                                                                 add_46[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_112 (BatchN (None, 32, 32, 160)  320         add_47[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_106 (Activation)     (None, 32, 32, 160)  0           batch_normalization_112[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_107 (Conv2D)             (None, 16, 16, 320)  460800      activation_106[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_113 (BatchN (None, 16, 16, 320)  640         conv2d_107[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_10 (AveragePo (None, 16, 16, 160)  0           add_47[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_107 (Activation)     (None, 16, 16, 320)  0           batch_normalization_113[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_10 (Lambda)              (None, 16, 16, 160)  0           average_pooling2d_10[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_108 (Conv2D)             (None, 16, 16, 320)  921600      activation_107[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_10 (Concatenate)    (None, 16, 16, 320)  0           average_pooling2d_10[0][0]       \n",
      "                                                                 lambda_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_48 (Add)                    (None, 16, 16, 320)  0           conv2d_108[0][0]                 \n",
      "                                                                 concatenate_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_114 (BatchN (None, 16, 16, 320)  640         add_48[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_108 (Activation)     (None, 16, 16, 320)  0           batch_normalization_114[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_109 (Conv2D)             (None, 16, 16, 320)  921600      activation_108[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_115 (BatchN (None, 16, 16, 320)  640         conv2d_109[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_109 (Activation)     (None, 16, 16, 320)  0           batch_normalization_115[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_110 (Conv2D)             (None, 16, 16, 320)  921600      activation_109[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_49 (Add)                    (None, 16, 16, 320)  0           conv2d_110[0][0]                 \n",
      "                                                                 add_48[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_116 (BatchN (None, 16, 16, 320)  640         add_49[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_110 (Activation)     (None, 16, 16, 320)  0           batch_normalization_116[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_111 (Conv2D)             (None, 16, 16, 320)  921600      activation_110[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_117 (BatchN (None, 16, 16, 320)  640         conv2d_111[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_111 (Activation)     (None, 16, 16, 320)  0           batch_normalization_117[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_112 (Conv2D)             (None, 16, 16, 320)  921600      activation_111[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_50 (Add)                    (None, 16, 16, 320)  0           conv2d_112[0][0]                 \n",
      "                                                                 add_49[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_118 (BatchN (None, 16, 16, 320)  640         add_50[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_112 (Activation)     (None, 16, 16, 320)  0           batch_normalization_118[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_113 (Conv2D)             (None, 8, 8, 640)    1843200     activation_112[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_119 (BatchN (None, 8, 8, 640)    1280        conv2d_113[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_11 (AveragePo (None, 8, 8, 320)    0           add_50[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_113 (Activation)     (None, 8, 8, 640)    0           batch_normalization_119[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_11 (Lambda)              (None, 8, 8, 320)    0           average_pooling2d_11[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_114 (Conv2D)             (None, 8, 8, 640)    3686400     activation_113[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_11 (Concatenate)    (None, 8, 8, 640)    0           average_pooling2d_11[0][0]       \n",
      "                                                                 lambda_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_51 (Add)                    (None, 8, 8, 640)    0           conv2d_114[0][0]                 \n",
      "                                                                 concatenate_11[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_120 (BatchN (None, 8, 8, 640)    1280        add_51[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_114 (Activation)     (None, 8, 8, 640)    0           batch_normalization_120[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_115 (Conv2D)             (None, 8, 8, 640)    3686400     activation_114[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_121 (BatchN (None, 8, 8, 640)    1280        conv2d_115[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_115 (Activation)     (None, 8, 8, 640)    0           batch_normalization_121[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_116 (Conv2D)             (None, 8, 8, 640)    3686400     activation_115[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_52 (Add)                    (None, 8, 8, 640)    0           conv2d_116[0][0]                 \n",
      "                                                                 add_51[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_122 (BatchN (None, 8, 8, 640)    1280        add_52[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_116 (Activation)     (None, 8, 8, 640)    0           batch_normalization_122[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_117 (Conv2D)             (None, 8, 8, 640)    3686400     activation_116[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_123 (BatchN (None, 8, 8, 640)    1280        conv2d_117[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_117 (Activation)     (None, 8, 8, 640)    0           batch_normalization_123[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_118 (Conv2D)             (None, 8, 8, 640)    3686400     activation_117[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_53 (Add)                    (None, 8, 8, 640)    0           conv2d_118[0][0]                 \n",
      "                                                                 add_52[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_124 (BatchN (None, 8, 8, 640)    1280        add_53[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_118 (Activation)     (None, 8, 8, 640)    0           batch_normalization_124[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_119 (Conv2D)             (None, 8, 8, 20)     12800       activation_118[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_125 (BatchN (None, 8, 8, 20)     40          conv2d_119[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_5 (Glo (None, 20)           0           batch_normalization_125[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_119 (Activation)     (None, 20)           0           global_average_pooling2d_5[0][0] \n",
      "==================================================================================================\n",
      "Total params: 26,757,332\n",
      "Trainable params: 26,743,526\n",
      "Non-trainable params: 13,806\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#fdefine a datagen or generating training samples with flip and pad/crop augmentation, and if set to True, with cutout augmentation\n",
    "dataGenerator = GetDataGen(UseCutout)\n",
    "\n",
    "#define and compile the model\n",
    "ResnetCoarsemodel = resnet(UseBinary,input_shape=input_shape, depth=resnet_depth, num_classes=num_classes,wd=My_wd,width=resnet_width)\n",
    "ResnetCoarsemodel.compile(loss=Loss ,optimizer = Optimizer, metrics = Metrics)\n",
    "\n",
    "#print  the model\n",
    "ResnetCoarsemodel.summary()\n",
    "\n",
    "#define the learnng rate schedule\n",
    "steps_per_epoch = int(np.floor(K_train / batch_size))\n",
    "lr_scheduler = LR_WarmRestart(nbatch=steps_per_epoch,\n",
    "                              initial_lr=init_lr, min_lr=init_lr*1e-4,\n",
    "                              epochs_restart = [1.0,3.0, 7.0, 15.0, 31.0, 63.0,127.0,255.0]) \n",
    "\n",
    "#define callbacks\n",
    "history = History()\n",
    "callbacks = [lr_scheduler,history]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "parliamentary-jersey",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\n",
      " Start of Epoch Learning Rate = 0.096119\n",
      "150/150 [==============================] - 866s 6s/step - loss: 5.6113 - accuracy: 0.2129 - val_loss: 6.0751 - val_accuracy: 0.0500\n",
      "\n",
      " End of Epoch Learning Rate = 0.080978\n",
      "Epoch 2/50\n",
      "\n",
      " Start of Epoch Learning Rate = 0.080978\n",
      "150/150 [==============================] - 879s 6s/step - loss: 5.2187 - accuracy: 0.2373 - val_loss: 5.9592 - val_accuracy: 0.0500\n",
      "\n",
      " End of Epoch Learning Rate = 0.063602\n",
      "Epoch 3/50\n",
      "\n",
      " Start of Epoch Learning Rate = 0.063602\n",
      "150/150 [==============================] - 857s 6s/step - loss: 4.9095 - accuracy: 0.2749 - val_loss: 5.6069 - val_accuracy: 0.0500\n",
      "\n",
      " End of Epoch Learning Rate = 0.044156\n",
      "Epoch 4/50\n",
      "\n",
      " Start of Epoch Learning Rate = 0.044156\n",
      "150/150 [==============================] - 844s 6s/step - loss: 4.6987 - accuracy: 0.2965 - val_loss: 5.5715 - val_accuracy: 0.0500\n",
      "\n",
      " End of Epoch Learning Rate = 0.025600\n",
      "Epoch 5/50\n",
      "\n",
      " Start of Epoch Learning Rate = 0.025600\n",
      "150/150 [==============================] - 864s 6s/step - loss: 4.5275 - accuracy: 0.3387 - val_loss: 5.5666 - val_accuracy: 0.0500\n",
      "\n",
      " End of Epoch Learning Rate = 0.010760\n",
      "Epoch 6/50\n",
      "\n",
      " Start of Epoch Learning Rate = 0.010760\n",
      "150/150 [==============================] - 874s 6s/step - loss: 4.4381 - accuracy: 0.3529 - val_loss: 5.5911 - val_accuracy: 0.0500\n",
      "\n",
      " End of Epoch Learning Rate = 0.001895\n",
      "Epoch 7/50\n",
      "\n",
      " Start of Epoch Learning Rate = 0.100000\n",
      "150/150 [==============================] - 887s 6s/step - loss: 4.5503 - accuracy: 0.2643 - val_loss: 5.2215 - val_accuracy: 0.0500\n",
      "\n",
      " End of Epoch Learning Rate = 0.099914\n",
      "Epoch 8/50\n",
      "\n",
      " Start of Epoch Learning Rate = 0.099914\n",
      "150/150 [==============================] - 873s 6s/step - loss: 4.2081 - accuracy: 0.2895 - val_loss: 5.3155 - val_accuracy: 0.0500\n",
      "\n",
      " End of Epoch Learning Rate = 0.098384\n",
      "Epoch 9/50\n",
      "\n",
      " Start of Epoch Learning Rate = 0.098384\n",
      "150/150 [==============================] - 860s 6s/step - loss: 3.8965 - accuracy: 0.3180 - val_loss: 6.1424 - val_accuracy: 0.0500\n",
      "\n",
      " End of Epoch Learning Rate = 0.094994\n",
      "Epoch 10/50\n",
      "\n",
      " Start of Epoch Learning Rate = 0.094994\n",
      "150/150 [==============================] - 852s 6s/step - loss: 3.6735 - accuracy: 0.3347 - val_loss: 4.6631 - val_accuracy: 0.0500\n",
      "\n",
      " End of Epoch Learning Rate = 0.089875\n",
      "Epoch 11/50\n",
      "\n",
      " Start of Epoch Learning Rate = 0.089875\n",
      "150/150 [==============================] - 854s 6s/step - loss: 3.4490 - accuracy: 0.3612 - val_loss: 4.6700 - val_accuracy: 0.0500\n",
      "\n",
      " End of Epoch Learning Rate = 0.083225\n",
      "Epoch 12/50\n",
      "\n",
      " Start of Epoch Learning Rate = 0.083225\n",
      "150/150 [==============================] - 853s 6s/step - loss: 3.2713 - accuracy: 0.3747 - val_loss: 4.5206 - val_accuracy: 0.0500\n",
      "\n",
      " End of Epoch Learning Rate = 0.075297\n",
      "Epoch 13/50\n",
      "\n",
      " Start of Epoch Learning Rate = 0.075297\n",
      "150/150 [==============================] - 876s 6s/step - loss: 3.1161 - accuracy: 0.3895 - val_loss: 4.5828 - val_accuracy: 0.0500\n",
      "\n",
      " End of Epoch Learning Rate = 0.066398\n",
      "Epoch 14/50\n",
      "\n",
      " Start of Epoch Learning Rate = 0.066398\n",
      "150/150 [==============================] - 863s 6s/step - loss: 2.9653 - accuracy: 0.4173 - val_loss: 4.1842 - val_accuracy: 0.0500\n",
      "\n",
      " End of Epoch Learning Rate = 0.056869\n",
      "Epoch 15/50\n",
      "\n",
      " Start of Epoch Learning Rate = 0.056869\n",
      "150/150 [==============================] - 857s 6s/step - loss: 2.8785 - accuracy: 0.4244 - val_loss: 4.4028 - val_accuracy: 0.0500\n",
      "\n",
      " End of Epoch Learning Rate = 0.047076\n",
      "Epoch 16/50\n",
      "\n",
      " Start of Epoch Learning Rate = 0.047076\n",
      "150/150 [==============================] - 848s 6s/step - loss: 2.7612 - accuracy: 0.4525 - val_loss: 4.7887 - val_accuracy: 0.0500\n",
      "\n",
      " End of Epoch Learning Rate = 0.037395\n",
      "Epoch 17/50\n",
      "\n",
      " Start of Epoch Learning Rate = 0.037395\n",
      "150/150 [==============================] - 867s 6s/step - loss: 2.6669 - accuracy: 0.4713 - val_loss: 4.3179 - val_accuracy: 0.0500\n",
      "\n",
      " End of Epoch Learning Rate = 0.028199\n",
      "Epoch 18/50\n",
      "\n",
      " Start of Epoch Learning Rate = 0.028199\n",
      "150/150 [==============================] - 871s 6s/step - loss: 2.5574 - accuracy: 0.5035 - val_loss: 4.2454 - val_accuracy: 0.0500\n",
      "\n",
      " End of Epoch Learning Rate = 0.019841\n",
      "Epoch 19/50\n",
      "\n",
      " Start of Epoch Learning Rate = 0.019841\n",
      "150/150 [==============================] - 873s 6s/step - loss: 2.4890 - accuracy: 0.5152 - val_loss: 4.1921 - val_accuracy: 0.0500\n",
      "\n",
      " End of Epoch Learning Rate = 0.012642\n",
      "Epoch 20/50\n",
      "\n",
      " Start of Epoch Learning Rate = 0.012642\n",
      "150/150 [==============================] - 873s 6s/step - loss: 2.4402 - accuracy: 0.5317 - val_loss: 4.3542 - val_accuracy: 0.0500\n",
      "\n",
      " End of Epoch Learning Rate = 0.006880\n",
      "Epoch 21/50\n",
      "\n",
      " Start of Epoch Learning Rate = 0.006880\n",
      "150/150 [==============================] - 870s 6s/step - loss: 2.4001 - accuracy: 0.5445 - val_loss: 4.4895 - val_accuracy: 0.0500\n",
      "\n",
      " End of Epoch Learning Rate = 0.002774\n",
      "Epoch 22/50\n",
      "\n",
      " Start of Epoch Learning Rate = 0.002774\n",
      "150/150 [==============================] - 870s 6s/step - loss: 2.3564 - accuracy: 0.5549 - val_loss: 4.5463 - val_accuracy: 0.0500\n",
      "\n",
      " End of Epoch Learning Rate = 0.000483\n",
      "Epoch 23/50\n",
      "\n",
      " Start of Epoch Learning Rate = 0.100000\n",
      "150/150 [==============================] - 869s 6s/step - loss: 2.8040 - accuracy: 0.3917 - val_loss: 4.4896 - val_accuracy: 0.0500\n",
      "\n",
      " End of Epoch Learning Rate = 0.099979\n",
      "Epoch 24/50\n",
      "\n",
      " Start of Epoch Learning Rate = 0.099979\n",
      "150/150 [==============================] - 865s 6s/step - loss: 2.6936 - accuracy: 0.4133 - val_loss: 4.4095 - val_accuracy: 0.0500\n",
      "\n",
      " End of Epoch Learning Rate = 0.099594\n",
      "Epoch 25/50\n",
      "\n",
      " Start of Epoch Learning Rate = 0.099594\n",
      "150/150 [==============================] - 878s 6s/step - loss: 2.5776 - accuracy: 0.4349 - val_loss: 4.2036 - val_accuracy: 0.0500\n",
      "\n",
      " End of Epoch Learning Rate = 0.098732\n",
      "Epoch 26/50\n",
      "\n",
      " Start of Epoch Learning Rate = 0.098732\n",
      "150/150 [==============================] - 887s 6s/step - loss: 2.4821 - accuracy: 0.4533 - val_loss: 4.1199 - val_accuracy: 0.0500\n",
      "\n",
      " End of Epoch Learning Rate = 0.097401\n",
      "Epoch 27/50\n",
      "\n",
      " Start of Epoch Learning Rate = 0.097401\n",
      "150/150 [==============================] - 864s 6s/step - loss: 2.4569 - accuracy: 0.4459 - val_loss: 3.9938 - val_accuracy: 0.0500\n",
      "\n",
      " End of Epoch Learning Rate = 0.095614\n",
      "Epoch 28/50\n",
      "\n",
      " Start of Epoch Learning Rate = 0.095614\n",
      "150/150 [==============================] - 853s 6s/step - loss: 2.3972 - accuracy: 0.4583 - val_loss: 3.9220 - val_accuracy: 0.0500\n",
      "\n",
      " End of Epoch Learning Rate = 0.093387\n",
      "Epoch 29/50\n",
      "\n",
      " Start of Epoch Learning Rate = 0.093387\n",
      "150/150 [==============================] - 850s 6s/step - loss: 2.3109 - accuracy: 0.4769 - val_loss: 4.6139 - val_accuracy: 0.0500\n",
      "\n",
      " End of Epoch Learning Rate = 0.090742\n",
      "Epoch 30/50\n",
      "\n",
      " Start of Epoch Learning Rate = 0.090742\n",
      "150/150 [==============================] - 850s 6s/step - loss: 2.2865 - accuracy: 0.4816 - val_loss: 3.7593 - val_accuracy: 0.0500\n",
      "\n",
      " End of Epoch Learning Rate = 0.087705\n",
      "Epoch 31/50\n",
      "\n",
      " Start of Epoch Learning Rate = 0.087705\n",
      "150/150 [==============================] - 852s 6s/step - loss: 2.2319 - accuracy: 0.4913 - val_loss: 4.0722 - val_accuracy: 0.0500\n",
      "\n",
      " End of Epoch Learning Rate = 0.084305\n",
      "Epoch 32/50\n",
      "\n",
      " Start of Epoch Learning Rate = 0.084305\n",
      "150/150 [==============================] - 852s 6s/step - loss: 2.2158 - accuracy: 0.4889 - val_loss: 3.9961 - val_accuracy: 0.0500\n",
      "\n",
      " End of Epoch Learning Rate = 0.080575\n",
      "Epoch 33/50\n",
      "\n",
      " Start of Epoch Learning Rate = 0.080575\n",
      "150/150 [==============================] - 850s 6s/step - loss: 2.1344 - accuracy: 0.5219 - val_loss: 4.1958 - val_accuracy: 0.0500\n",
      "\n",
      " End of Epoch Learning Rate = 0.076550\n",
      "Epoch 34/50\n",
      "\n",
      " Start of Epoch Learning Rate = 0.076550\n",
      "150/150 [==============================] - 848s 6s/step - loss: 2.1280 - accuracy: 0.5117 - val_loss: 3.9741 - val_accuracy: 0.0500\n",
      "\n",
      " End of Epoch Learning Rate = 0.072270\n",
      "Epoch 35/50\n",
      "\n",
      " Start of Epoch Learning Rate = 0.072270\n",
      "150/150 [==============================] - 847s 6s/step - loss: 2.0760 - accuracy: 0.5303 - val_loss: 3.9400 - val_accuracy: 0.0500\n",
      "\n",
      " End of Epoch Learning Rate = 0.067775\n",
      "Epoch 36/50\n",
      "\n",
      " Start of Epoch Learning Rate = 0.067775\n",
      "150/150 [==============================] - 848s 6s/step - loss: 2.0437 - accuracy: 0.5359 - val_loss: 4.1603 - val_accuracy: 0.0500\n",
      "\n",
      " End of Epoch Learning Rate = 0.063109\n",
      "Epoch 37/50\n",
      "\n",
      " Start of Epoch Learning Rate = 0.063109\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150/150 [==============================] - 848s 6s/step - loss: 2.0117 - accuracy: 0.5420 - val_loss: 4.0534 - val_accuracy: 0.0500\n",
      "\n",
      " End of Epoch Learning Rate = 0.058317\n",
      "Epoch 38/50\n",
      "\n",
      " Start of Epoch Learning Rate = 0.058317\n",
      "150/150 [==============================] - 850s 6s/step - loss: 1.9601 - accuracy: 0.5561 - val_loss: 3.8614 - val_accuracy: 0.0500\n",
      "\n",
      " End of Epoch Learning Rate = 0.053445\n",
      "Epoch 39/50\n",
      "\n",
      " Start of Epoch Learning Rate = 0.053445\n",
      "150/150 [==============================] - 852s 6s/step - loss: 1.9337 - accuracy: 0.5568 - val_loss: 3.8406 - val_accuracy: 0.0552\n",
      "\n",
      " End of Epoch Learning Rate = 0.048540\n",
      "Epoch 40/50\n",
      "\n",
      " Start of Epoch Learning Rate = 0.048540\n",
      "150/150 [==============================] - 850s 6s/step - loss: 1.9200 - accuracy: 0.5665 - val_loss: 4.9649 - val_accuracy: 0.0500\n",
      "\n",
      " End of Epoch Learning Rate = 0.043648\n",
      "Epoch 41/50\n",
      "\n",
      " Start of Epoch Learning Rate = 0.043648\n",
      "150/150 [==============================] - 850s 6s/step - loss: 1.8681 - accuracy: 0.5765 - val_loss: 4.0347 - val_accuracy: 0.0500\n",
      "\n",
      " End of Epoch Learning Rate = 0.038818\n",
      "Epoch 42/50\n",
      "\n",
      " Start of Epoch Learning Rate = 0.038818\n",
      "150/150 [==============================] - 852s 6s/step - loss: 1.8390 - accuracy: 0.5884 - val_loss: 4.0886 - val_accuracy: 0.0500\n",
      "\n",
      " End of Epoch Learning Rate = 0.034096\n",
      "Epoch 43/50\n",
      "\n",
      " Start of Epoch Learning Rate = 0.034096\n",
      "150/150 [==============================] - 851s 6s/step - loss: 1.7950 - accuracy: 0.6005 - val_loss: 4.0836 - val_accuracy: 0.0500\n",
      "\n",
      " End of Epoch Learning Rate = 0.029527\n",
      "Epoch 44/50\n",
      "\n",
      " Start of Epoch Learning Rate = 0.029527\n",
      "150/150 [==============================] - 851s 6s/step - loss: 1.7483 - accuracy: 0.6187 - val_loss: 3.8006 - val_accuracy: 0.0500\n",
      "\n",
      " End of Epoch Learning Rate = 0.025155\n",
      "Epoch 45/50\n",
      "\n",
      " Start of Epoch Learning Rate = 0.025155\n",
      "150/150 [==============================] - 853s 6s/step - loss: 1.7393 - accuracy: 0.6144 - val_loss: 3.9372 - val_accuracy: 0.0500\n",
      "\n",
      " End of Epoch Learning Rate = 0.021023\n",
      "Epoch 46/50\n",
      "\n",
      " Start of Epoch Learning Rate = 0.021023\n",
      "150/150 [==============================] - 853s 6s/step - loss: 1.6907 - accuracy: 0.6325 - val_loss: 3.8172 - val_accuracy: 0.0500\n",
      "\n",
      " End of Epoch Learning Rate = 0.017169\n",
      "Epoch 47/50\n",
      "\n",
      " Start of Epoch Learning Rate = 0.017169\n",
      "150/150 [==============================] - 855s 6s/step - loss: 1.6365 - accuracy: 0.6524 - val_loss: 3.9321 - val_accuracy: 0.0500\n",
      "\n",
      " End of Epoch Learning Rate = 0.013632\n",
      "Epoch 48/50\n",
      "\n",
      " Start of Epoch Learning Rate = 0.013632\n",
      "150/150 [==============================] - 856s 6s/step - loss: 1.6352 - accuracy: 0.6533 - val_loss: 3.9815 - val_accuracy: 0.0500\n",
      "\n",
      " End of Epoch Learning Rate = 0.010445\n",
      "Epoch 49/50\n",
      "\n",
      " Start of Epoch Learning Rate = 0.010445\n",
      "150/150 [==============================] - 854s 6s/step - loss: 1.5879 - accuracy: 0.6675 - val_loss: 3.6896 - val_accuracy: 0.0500\n",
      "\n",
      " End of Epoch Learning Rate = 0.007639\n",
      "Epoch 50/50\n",
      "\n",
      " Start of Epoch Learning Rate = 0.007639\n",
      "150/150 [==============================] - 854s 6s/step - loss: 1.5603 - accuracy: 0.6760 - val_loss: 3.8660 - val_accuracy: 0.0500\n",
      "\n",
      " End of Epoch Learning Rate = 0.005242\n"
     ]
    }
   ],
   "source": [
    "ResnetCoarsemodelHistory = ResnetCoarsemodel.fit(dataGenerator.flow(x_train, y_train, batch_size=batch_size),\n",
    "                              validation_data=(x_test, y_test),\n",
    "                              epochs=epochs,\n",
    "                              verbose=1,\n",
    "                              callbacks=callbacks,\n",
    "                              steps_per_epoch=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "piano-little",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\n",
      " Start of Epoch Learning Rate = 0.100000\n",
      "50/50 [==============================] - 428s 9s/step - loss: 6.3011 - accuracy: 0.1311 - val_loss: 67.9212 - val_accuracy: 0.0500\n",
      "\n",
      " End of Epoch Learning Rate = 0.099406\n",
      "Epoch 2/50\n",
      "\n",
      " Start of Epoch Learning Rate = 0.099406\n",
      "50/50 [==============================] - 419s 8s/step - loss: 5.9632 - accuracy: 0.1897 - val_loss: 13.9176 - val_accuracy: 0.0500\n",
      "\n",
      " End of Epoch Learning Rate = 0.042324\n",
      "Epoch 3/50\n",
      "\n",
      " Start of Epoch Learning Rate = 0.100000\n",
      "50/50 [==============================] - 423s 9s/step - loss: 5.8605 - accuracy: 0.2087 - val_loss: 7.9850 - val_accuracy: 0.0500\n",
      "\n",
      " End of Epoch Learning Rate = 0.099851\n",
      "Epoch 4/50\n",
      "\n",
      " Start of Epoch Learning Rate = 0.099851\n",
      "50/50 [==============================] - 423s 9s/step - loss: 5.7155 - accuracy: 0.2053 - val_loss: 6.6349 - val_accuracy: 0.0500\n",
      "\n",
      " End of Epoch Learning Rate = 0.082528\n",
      "Epoch 5/50\n",
      "\n",
      " Start of Epoch Learning Rate = 0.082528\n",
      "50/50 [==============================] - 417s 8s/step - loss: 5.5239 - accuracy: 0.2069 - val_loss: 6.1467 - val_accuracy: 0.0500\n",
      "\n",
      " End of Epoch Learning Rate = 0.046153\n",
      "Epoch 6/50\n",
      "\n",
      " Start of Epoch Learning Rate = 0.046153\n",
      "50/50 [==============================] - 416s 8s/step - loss: 5.4409 - accuracy: 0.2262 - val_loss: 6.1959 - val_accuracy: 0.0500\n",
      "\n",
      " End of Epoch Learning Rate = 0.012035\n",
      "Epoch 7/50\n",
      "\n",
      " Start of Epoch Learning Rate = 0.100000\n",
      "50/50 [==============================] - 418s 8s/step - loss: 5.4128 - accuracy: 0.2253 - val_loss: 6.3985 - val_accuracy: 0.0500\n",
      "\n",
      " End of Epoch Learning Rate = 0.099963\n",
      "Epoch 8/50\n",
      "\n",
      " Start of Epoch Learning Rate = 0.099963\n",
      "50/50 [==============================] - 415s 8s/step - loss: 5.2590 - accuracy: 0.2244 - val_loss: 6.0060 - val_accuracy: 0.0500\n",
      "\n",
      " End of Epoch Learning Rate = 0.095422\n",
      "Epoch 9/50\n",
      "\n",
      " Start of Epoch Learning Rate = 0.095422\n",
      "50/50 [==============================] - 414s 8s/step - loss: 5.1305 - accuracy: 0.2336 - val_loss: 5.8656 - val_accuracy: 0.0500\n",
      "\n",
      " End of Epoch Learning Rate = 0.083968\n",
      "Epoch 10/50\n",
      "\n",
      " Start of Epoch Learning Rate = 0.083968\n",
      "50/50 [==============================] - 417s 8s/step - loss: 4.9474 - accuracy: 0.2626 - val_loss: 5.6950 - val_accuracy: 0.0500\n",
      "\n",
      " End of Epoch Learning Rate = 0.067342\n",
      "Epoch 11/50\n",
      "\n",
      " Start of Epoch Learning Rate = 0.067342\n",
      "50/50 [==============================] - 419s 8s/step - loss: 4.8760 - accuracy: 0.2443 - val_loss: 5.6992 - val_accuracy: 0.0500\n",
      "\n",
      " End of Epoch Learning Rate = 0.048078\n",
      "Epoch 12/50\n",
      "\n",
      " Start of Epoch Learning Rate = 0.048078\n",
      "50/50 [==============================] - 419s 8s/step - loss: 4.7807 - accuracy: 0.2616 - val_loss: 5.6479 - val_accuracy: 0.0500\n",
      "\n",
      " End of Epoch Learning Rate = 0.029106\n",
      "Epoch 13/50\n",
      "\n",
      " Start of Epoch Learning Rate = 0.029106\n",
      "50/50 [==============================] - 421s 8s/step - loss: 4.6658 - accuracy: 0.2957 - val_loss: 5.5075 - val_accuracy: 0.0500\n",
      "\n",
      " End of Epoch Learning Rate = 0.013317\n",
      "Epoch 14/50\n",
      "\n",
      " Start of Epoch Learning Rate = 0.013317\n",
      "50/50 [==============================] - 421s 8s/step - loss: 4.6367 - accuracy: 0.2786 - val_loss: 5.4976 - val_accuracy: 0.0500\n",
      "\n",
      " End of Epoch Learning Rate = 0.003112\n",
      "Epoch 15/50\n",
      "\n",
      " Start of Epoch Learning Rate = 0.100000\n",
      "50/50 [==============================] - 420s 8s/step - loss: 4.6781 - accuracy: 0.2809 - val_loss: 5.6800 - val_accuracy: 0.0500\n",
      "\n",
      " End of Epoch Learning Rate = 0.099991\n",
      "Epoch 16/50\n",
      "\n",
      " Start of Epoch Learning Rate = 0.099991\n",
      "50/50 [==============================] - 423s 9s/step - loss: 4.6426 - accuracy: 0.2573 - val_loss: 5.6213 - val_accuracy: 0.0500\n",
      "\n",
      " End of Epoch Learning Rate = 0.098842\n",
      "Epoch 17/50\n",
      "\n",
      " Start of Epoch Learning Rate = 0.098842\n",
      "50/50 [==============================] - 418s 8s/step - loss: 4.5529 - accuracy: 0.2746 - val_loss: 5.4003 - val_accuracy: 0.0500\n",
      "\n",
      " End of Epoch Learning Rate = 0.095817\n",
      "Epoch 18/50\n",
      "\n",
      " Start of Epoch Learning Rate = 0.095817\n",
      "50/50 [==============================] - 418s 8s/step - loss: 4.4239 - accuracy: 0.2815 - val_loss: 5.1174 - val_accuracy: 0.0500\n",
      "\n",
      " End of Epoch Learning Rate = 0.091031\n",
      "Epoch 19/50\n",
      "\n",
      " Start of Epoch Learning Rate = 0.091031\n",
      "50/50 [==============================] - 418s 8s/step - loss: 4.2634 - accuracy: 0.3037 - val_loss: 5.0015 - val_accuracy: 0.0500\n",
      "\n",
      " End of Epoch Learning Rate = 0.084669\n",
      "Epoch 20/50\n",
      "\n",
      " Start of Epoch Learning Rate = 0.084669\n",
      "50/50 [==============================] - 418s 8s/step - loss: 4.1819 - accuracy: 0.3142 - val_loss: 5.1370 - val_accuracy: 0.0500\n",
      "\n",
      " End of Epoch Learning Rate = 0.076974\n",
      "Epoch 21/50\n",
      "\n",
      " Start of Epoch Learning Rate = 0.076974\n",
      "50/50 [==============================] - 419s 8s/step - loss: 4.0891 - accuracy: 0.3101 - val_loss: 5.0165 - val_accuracy: 0.0500\n",
      "\n",
      " End of Epoch Learning Rate = 0.068243\n",
      "Epoch 22/50\n",
      "\n",
      " Start of Epoch Learning Rate = 0.068243\n",
      "50/50 [==============================] - 421s 8s/step - loss: 3.9997 - accuracy: 0.3154 - val_loss: 4.9811 - val_accuracy: 0.0500\n",
      "\n",
      " End of Epoch Learning Rate = 0.058811\n",
      "Epoch 23/50\n",
      "\n",
      " Start of Epoch Learning Rate = 0.058811\n",
      "50/50 [==============================] - 425s 9s/step - loss: 3.9094 - accuracy: 0.3364 - val_loss: 4.9228 - val_accuracy: 0.0500\n",
      "\n",
      " End of Epoch Learning Rate = 0.049041\n",
      "Epoch 24/50\n",
      "\n",
      " Start of Epoch Learning Rate = 0.049041\n",
      "50/50 [==============================] - 423s 9s/step - loss: 3.8602 - accuracy: 0.3341 - val_loss: 4.9487 - val_accuracy: 0.0500\n",
      "\n",
      " End of Epoch Learning Rate = 0.039308\n",
      "Epoch 25/50\n",
      "\n",
      " Start of Epoch Learning Rate = 0.039308\n",
      "50/50 [==============================] - 425s 9s/step - loss: 3.8144 - accuracy: 0.3421 - val_loss: 4.8676 - val_accuracy: 0.0500\n",
      "\n",
      " End of Epoch Learning Rate = 0.029986\n",
      "Epoch 26/50\n",
      "\n",
      " Start of Epoch Learning Rate = 0.029986\n",
      "50/50 [==============================] - 427s 9s/step - loss: 3.7950 - accuracy: 0.3359 - val_loss: 4.8772 - val_accuracy: 0.0500\n",
      "\n",
      " End of Epoch Learning Rate = 0.021433\n",
      "Epoch 27/50\n",
      "\n",
      " Start of Epoch Learning Rate = 0.021433\n",
      "50/50 [==============================] - 429s 9s/step - loss: 3.6912 - accuracy: 0.3812 - val_loss: 4.9151 - val_accuracy: 0.0500\n",
      "\n",
      " End of Epoch Learning Rate = 0.013978\n",
      "Epoch 28/50\n",
      "\n",
      " Start of Epoch Learning Rate = 0.013978\n",
      "50/50 [==============================] - 427s 9s/step - loss: 3.6186 - accuracy: 0.4047 - val_loss: 5.2307 - val_accuracy: 0.0500\n",
      "\n",
      " End of Epoch Learning Rate = 0.007908\n",
      "Epoch 29/50\n",
      "\n",
      " Start of Epoch Learning Rate = 0.007908\n",
      "50/50 [==============================] - 424s 9s/step - loss: 3.6290 - accuracy: 0.3868 - val_loss: 5.0755 - val_accuracy: 0.0500\n",
      "\n",
      " End of Epoch Learning Rate = 0.003455\n",
      "Epoch 30/50\n",
      "\n",
      " Start of Epoch Learning Rate = 0.003455\n",
      "50/50 [==============================] - 424s 9s/step - loss: 3.6209 - accuracy: 0.3941 - val_loss: 5.0554 - val_accuracy: 0.0500\n",
      "\n",
      " End of Epoch Learning Rate = 0.000792\n",
      "Epoch 31/50\n",
      "\n",
      " Start of Epoch Learning Rate = 0.100000\n",
      "50/50 [==============================] - 424s 9s/step - loss: 3.7625 - accuracy: 0.3354 - val_loss: 5.5605 - val_accuracy: 0.0500\n",
      "\n",
      " End of Epoch Learning Rate = 0.099998\n",
      "Epoch 32/50\n",
      "\n",
      " Start of Epoch Learning Rate = 0.099998\n",
      "50/50 [==============================] - 427s 9s/step - loss: 3.8208 - accuracy: 0.2945 - val_loss: 5.3832 - val_accuracy: 0.0500\n",
      "\n",
      " End of Epoch Learning Rate = 0.099710\n",
      "Epoch 33/50\n",
      "\n",
      " Start of Epoch Learning Rate = 0.099710\n",
      "50/50 [==============================] - 425s 9s/step - loss: 3.7123 - accuracy: 0.3282 - val_loss: 4.6836 - val_accuracy: 0.0500\n",
      "\n",
      " End of Epoch Learning Rate = 0.098943\n",
      "Epoch 34/50\n",
      "\n",
      " Start of Epoch Learning Rate = 0.098943\n",
      "50/50 [==============================] - 423s 9s/step - loss: 3.7164 - accuracy: 0.2916 - val_loss: 5.0315 - val_accuracy: 0.0500\n",
      "\n",
      " End of Epoch Learning Rate = 0.097705\n",
      "Epoch 35/50\n",
      "\n",
      " Start of Epoch Learning Rate = 0.097705\n",
      "50/50 [==============================] - 422s 9s/step - loss: 3.5221 - accuracy: 0.3390 - val_loss: 4.6287 - val_accuracy: 0.0500\n",
      "\n",
      " End of Epoch Learning Rate = 0.096008\n",
      "Epoch 36/50\n",
      "\n",
      " Start of Epoch Learning Rate = 0.096008\n",
      "50/50 [==============================] - 422s 9s/step - loss: 3.4918 - accuracy: 0.3459 - val_loss: 4.6415 - val_accuracy: 0.0500\n",
      "\n",
      " End of Epoch Learning Rate = 0.093867\n",
      "Epoch 37/50\n",
      "\n",
      " Start of Epoch Learning Rate = 0.093867\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/50 [==============================] - 426s 9s/step - loss: 3.3938 - accuracy: 0.3487 - val_loss: 4.4779 - val_accuracy: 0.0500\n",
      "\n",
      " End of Epoch Learning Rate = 0.091305\n",
      "Epoch 38/50\n",
      "\n",
      " Start of Epoch Learning Rate = 0.091305\n",
      "50/50 [==============================] - 427s 9s/step - loss: 3.3893 - accuracy: 0.3525 - val_loss: 4.5386 - val_accuracy: 0.0500\n",
      "\n",
      " End of Epoch Learning Rate = 0.088344\n",
      "Epoch 39/50\n",
      "\n",
      " Start of Epoch Learning Rate = 0.088344\n",
      "50/50 [==============================] - 426s 9s/step - loss: 3.2920 - accuracy: 0.3501 - val_loss: 4.3863 - val_accuracy: 0.0500\n",
      "\n",
      " End of Epoch Learning Rate = 0.085014\n",
      "Epoch 40/50\n",
      "\n",
      " Start of Epoch Learning Rate = 0.085014\n",
      "50/50 [==============================] - 419s 8s/step - loss: 3.2713 - accuracy: 0.3450 - val_loss: 4.5744 - val_accuracy: 0.0500\n",
      "\n",
      " End of Epoch Learning Rate = 0.081347\n",
      "Epoch 41/50\n",
      "\n",
      " Start of Epoch Learning Rate = 0.081347\n",
      "50/50 [==============================] - 416s 8s/step - loss: 3.1988 - accuracy: 0.3574 - val_loss: 4.7633 - val_accuracy: 0.0500\n",
      "\n",
      " End of Epoch Learning Rate = 0.077379\n",
      "Epoch 42/50\n",
      "\n",
      " Start of Epoch Learning Rate = 0.077379\n",
      "50/50 [==============================] - 424s 9s/step - loss: 3.0736 - accuracy: 0.4059 - val_loss: 4.4954 - val_accuracy: 0.0500\n",
      "\n",
      " End of Epoch Learning Rate = 0.073146\n",
      "Epoch 43/50\n",
      "\n",
      " Start of Epoch Learning Rate = 0.073146\n",
      "50/50 [==============================] - 429s 9s/step - loss: 3.0746 - accuracy: 0.3959 - val_loss: 4.3618 - val_accuracy: 0.0500\n",
      "\n",
      " End of Epoch Learning Rate = 0.068691\n",
      "Epoch 44/50\n",
      "\n",
      " Start of Epoch Learning Rate = 0.068691\n",
      "50/50 [==============================] - 423s 9s/step - loss: 3.0069 - accuracy: 0.3983 - val_loss: 4.8451 - val_accuracy: 0.0500\n",
      "\n",
      " End of Epoch Learning Rate = 0.064056\n",
      "Epoch 45/50\n",
      "\n",
      " Start of Epoch Learning Rate = 0.064056\n",
      "50/50 [==============================] - 413s 8s/step - loss: 2.9226 - accuracy: 0.4207 - val_loss: 4.4998 - val_accuracy: 0.0500\n",
      "\n",
      " End of Epoch Learning Rate = 0.059285\n",
      "Epoch 46/50\n",
      "\n",
      " Start of Epoch Learning Rate = 0.059285\n",
      "50/50 [==============================] - 416s 8s/step - loss: 2.8572 - accuracy: 0.4512 - val_loss: 4.5367 - val_accuracy: 0.0500\n",
      "\n",
      " End of Epoch Learning Rate = 0.054425\n",
      "Epoch 47/50\n",
      "\n",
      " Start of Epoch Learning Rate = 0.054425\n",
      "50/50 [==============================] - 426s 9s/step - loss: 2.8628 - accuracy: 0.4305 - val_loss: 4.3454 - val_accuracy: 0.0500\n",
      "\n",
      " End of Epoch Learning Rate = 0.049523\n",
      "Epoch 48/50\n",
      "\n",
      " Start of Epoch Learning Rate = 0.049523\n",
      "50/50 [==============================] - 425s 9s/step - loss: 2.8374 - accuracy: 0.4296 - val_loss: 4.7402 - val_accuracy: 0.0500\n",
      "\n",
      " End of Epoch Learning Rate = 0.044625\n",
      "Epoch 49/50\n",
      "\n",
      " Start of Epoch Learning Rate = 0.044625\n",
      "50/50 [==============================] - 423s 9s/step - loss: 2.7819 - accuracy: 0.4345 - val_loss: 4.3007 - val_accuracy: 0.0500\n",
      "\n",
      " End of Epoch Learning Rate = 0.039779\n",
      "Epoch 50/50\n",
      "\n",
      " Start of Epoch Learning Rate = 0.039779\n",
      "50/50 [==============================] - 434s 9s/step - loss: 2.8009 - accuracy: 0.4362 - val_loss: 4.4085 - val_accuracy: 0.0500\n",
      "\n",
      " End of Epoch Learning Rate = 0.035032\n"
     ]
    }
   ],
   "source": [
    "ResnetCoarsemodelHistory = ResnetCoarsemodel.fit(dataGenerator.flow(x_train, y_train, batch_size=50),\n",
    "                              validation_data=(x_test, y_test),\n",
    "                              epochs=50,\n",
    "                              verbose=1,\n",
    "                              callbacks=callbacks,\n",
    "                              steps_per_epoch=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "grand-usage",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function ScopedTFGraph.__del__ at 0x000001D47E8BB8B8>\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\lizks\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\framework\\c_api_util.py\", line 58, in __del__\n",
      "    self.deleter(self.graph)\n",
      "AttributeError: deleter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: resNet_coarse_1\\assets\n"
     ]
    }
   ],
   "source": [
    "ResnetCoarsemodel.save('resNet_coarse_1')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "willing-mystery",
   "metadata": {},
   "source": [
    "# ResNet50 Coarse Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "documented-killing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1d4fe894c88>"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(ResnetCoarsemodelHistory.history['accuracy'], label='accuracy')\n",
    "plt.plot(ResnetCoarsemodelHistory.history['val_accuracy'], label = 'val_accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([0.0, 0.6])\n",
    "plt.legend(loc='lower right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "double-funeral",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 - 403s - loss: 4.4085 - accuracy: 0.0500\n",
      "0.05000000074505806\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = ResnetCoarsemodel.evaluate(x_test,  y_test, verbose=2)\n",
    "\n",
    "print(test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "thrown-listing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.01571625 0.22399314 0.02941566 ... 0.0164951  0.01175885 0.0378624 ]\n",
      " [0.01567853 0.22391762 0.02952113 ... 0.0164871  0.01175139 0.03779262]\n",
      " [0.01568515 0.22443788 0.02949302 ... 0.01648965 0.01174634 0.03779897]\n",
      " ...\n",
      " [0.01567763 0.22446308 0.02950623 ... 0.01647531 0.01174237 0.03770077]\n",
      " [0.01566969 0.22348714 0.0295664  ... 0.01647806 0.0117507  0.03774299]\n",
      " [0.01563889 0.22194743 0.02970349 ... 0.01650704 0.01176676 0.03784492]]\n"
     ]
    }
   ],
   "source": [
    "predictionsResnetCoarsemodel=ResnetCoarsemodel.predict(test_images_reshaped)\n",
    "print(predictionsResnetCoarsemodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "portable-gathering",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of multiclass and continuous-multioutput targets",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-110-0946f3c7e298>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_labels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_labels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mdisp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mConfusionMatrixDisplay\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfusion_matrix\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdisplay_labels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_labels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mdisp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\lizks\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\lizks\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36mconfusion_matrix\u001b[1;34m(y_true, y_pred, labels, sample_weight, normalize)\u001b[0m\n\u001b[0;32m    294\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    295\u001b[0m     \"\"\"\n\u001b[1;32m--> 296\u001b[1;33m     \u001b[0my_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    297\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"binary\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"multiclass\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    298\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"%s is not supported\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0my_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\lizks\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     91\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m         raise ValueError(\"Classification metrics can't handle a mix of {0} \"\n\u001b[1;32m---> 93\u001b[1;33m                          \"and {1} targets\".format(type_true, type_pred))\n\u001b[0m\u001b[0;32m     94\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m     \u001b[1;31m# We can't have more than one value on y_type => The set is no more needed\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Classification metrics can't handle a mix of multiclass and continuous-multioutput targets"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(np.array(test_labels), np.array(predictions), labels=np.unique(test_labels))\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=np.unique(test_labels))\n",
    "disp.plot() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "athletic-athletics",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "auburn-memorial",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "analyzed-float",
   "metadata": {},
   "source": [
    "# ResNet fine labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "driven-howard",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32, 32, 3)\n",
      "(50000, 1)\n",
      "(10000, 32, 32, 3)\n",
      "(10000, 1)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "x_train = np.load('trnImage.npy')\n",
    "y_train = np.load('trnLabel_fine.npy')\n",
    "#labels_fine = np.load('trnLabel_fine.npy')\n",
    "\n",
    "x_test = np.load('tstImage.npy')\n",
    "y_test = np.load('tstLabel_fine.npy')\n",
    "#test_labels_fine = np.load('tstLabel_fine.npy')\n",
    "\n",
    "x_train = np.transpose(x_train, (3, 0, 1, 2))\n",
    "x_test = np.transpose(x_test, (3, 0, 1, 2))\n",
    "y_train = y_train.reshape(50000, 1)\n",
    "y_test = y_test.reshape(10000, 1)\n",
    "\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)\n",
    "\n",
    "num_classes = np.unique(y_train).shape[0]\n",
    "K_train = x_train.shape[0]\n",
    "input_shape = x_train.shape[1:]\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "y_train = tf.keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "super-caribbean",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_6 (InputLayer)            [(None, 32, 32, 3)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_84 (BatchNo (None, 32, 32, 3)    12          input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_80 (Conv2D)              (None, 32, 32, 160)  4320        batch_normalization_84[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_85 (BatchNo (None, 32, 32, 160)  320         conv2d_80[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_80 (Activation)      (None, 32, 32, 160)  0           batch_normalization_85[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_81 (Conv2D)              (None, 32, 32, 160)  230400      activation_80[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_86 (BatchNo (None, 32, 32, 160)  320         conv2d_81[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_81 (Activation)      (None, 32, 32, 160)  0           batch_normalization_86[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_82 (Conv2D)              (None, 32, 32, 160)  230400      activation_81[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_36 (Add)                    (None, 32, 32, 160)  0           conv2d_82[0][0]                  \n",
      "                                                                 conv2d_80[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_87 (BatchNo (None, 32, 32, 160)  320         add_36[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_82 (Activation)      (None, 32, 32, 160)  0           batch_normalization_87[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_83 (Conv2D)              (None, 32, 32, 160)  230400      activation_82[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_88 (BatchNo (None, 32, 32, 160)  320         conv2d_83[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_83 (Activation)      (None, 32, 32, 160)  0           batch_normalization_88[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_84 (Conv2D)              (None, 32, 32, 160)  230400      activation_83[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_37 (Add)                    (None, 32, 32, 160)  0           conv2d_84[0][0]                  \n",
      "                                                                 add_36[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_89 (BatchNo (None, 32, 32, 160)  320         add_37[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_84 (Activation)      (None, 32, 32, 160)  0           batch_normalization_89[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_85 (Conv2D)              (None, 32, 32, 160)  230400      activation_84[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_90 (BatchNo (None, 32, 32, 160)  320         conv2d_85[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_85 (Activation)      (None, 32, 32, 160)  0           batch_normalization_90[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_86 (Conv2D)              (None, 32, 32, 160)  230400      activation_85[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_38 (Add)                    (None, 32, 32, 160)  0           conv2d_86[0][0]                  \n",
      "                                                                 add_37[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_91 (BatchNo (None, 32, 32, 160)  320         add_38[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_86 (Activation)      (None, 32, 32, 160)  0           batch_normalization_91[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_87 (Conv2D)              (None, 16, 16, 320)  460800      activation_86[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_92 (BatchNo (None, 16, 16, 320)  640         conv2d_87[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_8 (AveragePoo (None, 16, 16, 160)  0           add_38[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_87 (Activation)      (None, 16, 16, 320)  0           batch_normalization_92[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_8 (Lambda)               (None, 16, 16, 160)  0           average_pooling2d_8[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_88 (Conv2D)              (None, 16, 16, 320)  921600      activation_87[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_8 (Concatenate)     (None, 16, 16, 320)  0           average_pooling2d_8[0][0]        \n",
      "                                                                 lambda_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_39 (Add)                    (None, 16, 16, 320)  0           conv2d_88[0][0]                  \n",
      "                                                                 concatenate_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_93 (BatchNo (None, 16, 16, 320)  640         add_39[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_88 (Activation)      (None, 16, 16, 320)  0           batch_normalization_93[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_89 (Conv2D)              (None, 16, 16, 320)  921600      activation_88[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_94 (BatchNo (None, 16, 16, 320)  640         conv2d_89[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_89 (Activation)      (None, 16, 16, 320)  0           batch_normalization_94[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_90 (Conv2D)              (None, 16, 16, 320)  921600      activation_89[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_40 (Add)                    (None, 16, 16, 320)  0           conv2d_90[0][0]                  \n",
      "                                                                 add_39[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_95 (BatchNo (None, 16, 16, 320)  640         add_40[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_90 (Activation)      (None, 16, 16, 320)  0           batch_normalization_95[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_91 (Conv2D)              (None, 16, 16, 320)  921600      activation_90[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_96 (BatchNo (None, 16, 16, 320)  640         conv2d_91[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_91 (Activation)      (None, 16, 16, 320)  0           batch_normalization_96[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_92 (Conv2D)              (None, 16, 16, 320)  921600      activation_91[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_41 (Add)                    (None, 16, 16, 320)  0           conv2d_92[0][0]                  \n",
      "                                                                 add_40[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_97 (BatchNo (None, 16, 16, 320)  640         add_41[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_92 (Activation)      (None, 16, 16, 320)  0           batch_normalization_97[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_93 (Conv2D)              (None, 8, 8, 640)    1843200     activation_92[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_98 (BatchNo (None, 8, 8, 640)    1280        conv2d_93[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_9 (AveragePoo (None, 8, 8, 320)    0           add_41[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_93 (Activation)      (None, 8, 8, 640)    0           batch_normalization_98[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_9 (Lambda)               (None, 8, 8, 320)    0           average_pooling2d_9[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_94 (Conv2D)              (None, 8, 8, 640)    3686400     activation_93[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_9 (Concatenate)     (None, 8, 8, 640)    0           average_pooling2d_9[0][0]        \n",
      "                                                                 lambda_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_42 (Add)                    (None, 8, 8, 640)    0           conv2d_94[0][0]                  \n",
      "                                                                 concatenate_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_99 (BatchNo (None, 8, 8, 640)    1280        add_42[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_94 (Activation)      (None, 8, 8, 640)    0           batch_normalization_99[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_95 (Conv2D)              (None, 8, 8, 640)    3686400     activation_94[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_100 (BatchN (None, 8, 8, 640)    1280        conv2d_95[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_95 (Activation)      (None, 8, 8, 640)    0           batch_normalization_100[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_96 (Conv2D)              (None, 8, 8, 640)    3686400     activation_95[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_43 (Add)                    (None, 8, 8, 640)    0           conv2d_96[0][0]                  \n",
      "                                                                 add_42[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_101 (BatchN (None, 8, 8, 640)    1280        add_43[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_96 (Activation)      (None, 8, 8, 640)    0           batch_normalization_101[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_97 (Conv2D)              (None, 8, 8, 640)    3686400     activation_96[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_102 (BatchN (None, 8, 8, 640)    1280        conv2d_97[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_97 (Activation)      (None, 8, 8, 640)    0           batch_normalization_102[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_98 (Conv2D)              (None, 8, 8, 640)    3686400     activation_97[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_44 (Add)                    (None, 8, 8, 640)    0           conv2d_98[0][0]                  \n",
      "                                                                 add_43[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_103 (BatchN (None, 8, 8, 640)    1280        add_44[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_98 (Activation)      (None, 8, 8, 640)    0           batch_normalization_103[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_99 (Conv2D)              (None, 8, 8, 100)    64000       activation_98[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_104 (BatchN (None, 8, 8, 100)    200         conv2d_99[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_4 (Glo (None, 100)          0           batch_normalization_104[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_99 (Activation)      (None, 100)          0           global_average_pooling2d_4[0][0] \n",
      "==================================================================================================\n",
      "Total params: 26,808,692\n",
      "Trainable params: 26,794,726\n",
      "Non-trainable params: 13,966\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#fdefine a datagen or generating training samples with flip and pad/crop augmentation, and if set to True, with cutout augmentation\n",
    "dataGenerator = GetDataGen(UseCutout)\n",
    "\n",
    "#define and compile the model\n",
    "ResnetFinemodel = resnet(UseBinary,input_shape=input_shape, depth=resnet_depth, num_classes=num_classes,wd=My_wd,width=resnet_width)\n",
    "ResnetFinemodel.compile(loss=Loss ,optimizer = Optimizer, metrics = Metrics)\n",
    "\n",
    "#print  the model\n",
    "ResnetFinemodel.summary()\n",
    "\n",
    "#define the learnng rate schedule\n",
    "steps_per_epoch = int(np.floor(K_train / batch_size))\n",
    "lr_scheduler = LR_WarmRestart(nbatch=steps_per_epoch,\n",
    "                              initial_lr=init_lr, min_lr=init_lr*1e-4,\n",
    "                              epochs_restart = [1.0,3.0, 7.0, 15.0, 31.0, 63.0,127.0,255.0]) \n",
    "\n",
    "#define callbacks\n",
    "history = History()\n",
    "callbacks = [lr_scheduler,history]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "criminal-feeding",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\n",
      " Start of Epoch Learning Rate = 0.100000\n",
      "50/50 [==============================] - 399s 8s/step - loss: 7.9688 - accuracy: 0.0335 - val_loss: 405.1830 - val_accuracy: 0.0100\n",
      "\n",
      " End of Epoch Learning Rate = 0.099406\n",
      "Epoch 2/50\n",
      "\n",
      " Start of Epoch Learning Rate = 0.099406\n",
      "50/50 [==============================] - 401s 8s/step - loss: 7.6146 - accuracy: 0.0589 - val_loss: 16.7258 - val_accuracy: 0.0100\n",
      "\n",
      " End of Epoch Learning Rate = 0.042324\n",
      "Epoch 3/50\n",
      "\n",
      " Start of Epoch Learning Rate = 0.100000\n",
      "50/50 [==============================] - 404s 8s/step - loss: 7.3831 - accuracy: 0.0755 - val_loss: 12.2159 - val_accuracy: 0.0100\n",
      "\n",
      " End of Epoch Learning Rate = 0.099851\n",
      "Epoch 4/50\n",
      "\n",
      " Start of Epoch Learning Rate = 0.099851\n",
      "50/50 [==============================] - 401s 8s/step - loss: 7.2517 - accuracy: 0.0828 - val_loss: 8.2260 - val_accuracy: 0.0100\n",
      "\n",
      " End of Epoch Learning Rate = 0.082528\n",
      "Epoch 5/50\n",
      "\n",
      " Start of Epoch Learning Rate = 0.082528\n",
      "50/50 [==============================] - 401s 8s/step - loss: 7.0135 - accuracy: 0.0885 - val_loss: 7.9894 - val_accuracy: 0.0100\n",
      "\n",
      " End of Epoch Learning Rate = 0.046153\n",
      "Epoch 6/50\n",
      "\n",
      " Start of Epoch Learning Rate = 0.046153\n",
      "50/50 [==============================] - 408s 8s/step - loss: 6.8771 - accuracy: 0.1089 - val_loss: 8.0820 - val_accuracy: 0.0100\n",
      "\n",
      " End of Epoch Learning Rate = 0.012035\n",
      "Epoch 7/50\n",
      "\n",
      " Start of Epoch Learning Rate = 0.100000\n",
      "50/50 [==============================] - 391s 8s/step - loss: 6.8371 - accuracy: 0.1127 - val_loss: 8.6190 - val_accuracy: 0.0100\n",
      "\n",
      " End of Epoch Learning Rate = 0.099963\n",
      "Epoch 8/50\n",
      "\n",
      " Start of Epoch Learning Rate = 0.099963\n",
      "50/50 [==============================] - 385s 8s/step - loss: 6.7256 - accuracy: 0.1096 - val_loss: 8.5915 - val_accuracy: 0.0100\n",
      "\n",
      " End of Epoch Learning Rate = 0.095422\n",
      "Epoch 9/50\n",
      "\n",
      " Start of Epoch Learning Rate = 0.095422\n",
      "50/50 [==============================] - 385s 8s/step - loss: 6.6261 - accuracy: 0.0883 - val_loss: 7.5959 - val_accuracy: 0.0100\n",
      "\n",
      " End of Epoch Learning Rate = 0.083968\n",
      "Epoch 10/50\n",
      "\n",
      " Start of Epoch Learning Rate = 0.083968\n",
      "50/50 [==============================] - 387s 8s/step - loss: 6.4605 - accuracy: 0.1085 - val_loss: 7.3902 - val_accuracy: 0.0100\n",
      "\n",
      " End of Epoch Learning Rate = 0.067342\n",
      "Epoch 11/50\n",
      "\n",
      " Start of Epoch Learning Rate = 0.067342\n",
      "50/50 [==============================] - 387s 8s/step - loss: 6.3332 - accuracy: 0.1190 - val_loss: 7.5934 - val_accuracy: 0.0100\n",
      "\n",
      " End of Epoch Learning Rate = 0.048078\n",
      "Epoch 12/50\n",
      "\n",
      " Start of Epoch Learning Rate = 0.048078\n",
      "50/50 [==============================] - 388s 8s/step - loss: 6.2164 - accuracy: 0.1435 - val_loss: 7.3691 - val_accuracy: 0.0100\n",
      "\n",
      " End of Epoch Learning Rate = 0.029106\n",
      "Epoch 13/50\n",
      "\n",
      " Start of Epoch Learning Rate = 0.029106\n",
      "50/50 [==============================] - 387s 8s/step - loss: 6.1766 - accuracy: 0.1158 - val_loss: 7.4234 - val_accuracy: 0.0100\n",
      "\n",
      " End of Epoch Learning Rate = 0.013317\n",
      "Epoch 14/50\n",
      "\n",
      " Start of Epoch Learning Rate = 0.013317\n",
      "50/50 [==============================] - 387s 8s/step - loss: 6.0851 - accuracy: 0.1410 - val_loss: 7.4428 - val_accuracy: 0.0100\n",
      "\n",
      " End of Epoch Learning Rate = 0.003112\n",
      "Epoch 15/50\n",
      "\n",
      " Start of Epoch Learning Rate = 0.100000\n",
      "50/50 [==============================] - 388s 8s/step - loss: 6.1597 - accuracy: 0.1352 - val_loss: 8.1124 - val_accuracy: 0.0100\n",
      "\n",
      " End of Epoch Learning Rate = 0.099991\n",
      "Epoch 16/50\n",
      "\n",
      " Start of Epoch Learning Rate = 0.099991\n",
      "50/50 [==============================] - 387s 8s/step - loss: 6.1074 - accuracy: 0.1226 - val_loss: 7.4186 - val_accuracy: 0.0100\n",
      "\n",
      " End of Epoch Learning Rate = 0.098842\n",
      "Epoch 17/50\n",
      "\n",
      " Start of Epoch Learning Rate = 0.098842\n",
      "50/50 [==============================] - 387s 8s/step - loss: 5.9878 - accuracy: 0.1251 - val_loss: 7.0242 - val_accuracy: 0.0100\n",
      "\n",
      " End of Epoch Learning Rate = 0.095817\n",
      "Epoch 18/50\n",
      "\n",
      " Start of Epoch Learning Rate = 0.095817\n",
      "50/50 [==============================] - 386s 8s/step - loss: 5.7863 - accuracy: 0.1589 - val_loss: 7.2944 - val_accuracy: 0.0100\n",
      "\n",
      " End of Epoch Learning Rate = 0.091031\n",
      "Epoch 19/50\n",
      "\n",
      " Start of Epoch Learning Rate = 0.091031\n",
      "50/50 [==============================] - 386s 8s/step - loss: 5.7146 - accuracy: 0.1345 - val_loss: 7.2860 - val_accuracy: 0.0100\n",
      "\n",
      " End of Epoch Learning Rate = 0.084669\n",
      "Epoch 20/50\n",
      "\n",
      " Start of Epoch Learning Rate = 0.084669\n",
      "50/50 [==============================] - 387s 8s/step - loss: 5.6054 - accuracy: 0.1624 - val_loss: 6.7107 - val_accuracy: 0.0100\n",
      "\n",
      " End of Epoch Learning Rate = 0.076974\n",
      "Epoch 21/50\n",
      "\n",
      " Start of Epoch Learning Rate = 0.076974\n",
      "50/50 [==============================] - 387s 8s/step - loss: 5.4810 - accuracy: 0.1576 - val_loss: 6.5723 - val_accuracy: 0.0100\n",
      "\n",
      " End of Epoch Learning Rate = 0.068243\n",
      "Epoch 22/50\n",
      "\n",
      " Start of Epoch Learning Rate = 0.068243\n",
      "50/50 [==============================] - 387s 8s/step - loss: 5.3984 - accuracy: 0.1785 - val_loss: 6.6313 - val_accuracy: 0.0100\n",
      "\n",
      " End of Epoch Learning Rate = 0.058811\n",
      "Epoch 23/50\n",
      "\n",
      " Start of Epoch Learning Rate = 0.058811\n",
      "50/50 [==============================] - 386s 8s/step - loss: 5.2931 - accuracy: 0.1803 - val_loss: 6.5484 - val_accuracy: 0.0100\n",
      "\n",
      " End of Epoch Learning Rate = 0.049041\n",
      "Epoch 24/50\n",
      "\n",
      " Start of Epoch Learning Rate = 0.049041\n",
      "50/50 [==============================] - 388s 8s/step - loss: 5.2242 - accuracy: 0.1932 - val_loss: 6.7288 - val_accuracy: 0.0100\n",
      "\n",
      " End of Epoch Learning Rate = 0.039308\n",
      "Epoch 25/50\n",
      "\n",
      " Start of Epoch Learning Rate = 0.039308\n",
      "50/50 [==============================] - 386s 8s/step - loss: 5.1339 - accuracy: 0.1998 - val_loss: 6.6893 - val_accuracy: 0.0100\n",
      "\n",
      " End of Epoch Learning Rate = 0.029986\n",
      "Epoch 26/50\n",
      "\n",
      " Start of Epoch Learning Rate = 0.029986\n",
      "50/50 [==============================] - 387s 8s/step - loss: 5.0450 - accuracy: 0.2098 - val_loss: 6.5763 - val_accuracy: 0.0112\n",
      "\n",
      " End of Epoch Learning Rate = 0.021433\n",
      "Epoch 27/50\n",
      "\n",
      " Start of Epoch Learning Rate = 0.021433\n",
      "50/50 [==============================] - 388s 8s/step - loss: 5.0252 - accuracy: 0.2220 - val_loss: 6.4797 - val_accuracy: 0.0100\n",
      "\n",
      " End of Epoch Learning Rate = 0.013978\n",
      "Epoch 28/50\n",
      "\n",
      " Start of Epoch Learning Rate = 0.013978\n",
      "50/50 [==============================] - 389s 8s/step - loss: 4.9330 - accuracy: 0.2289 - val_loss: 6.5000 - val_accuracy: 0.0100\n",
      "\n",
      " End of Epoch Learning Rate = 0.007908\n",
      "Epoch 29/50\n",
      "\n",
      " Start of Epoch Learning Rate = 0.007908\n",
      "50/50 [==============================] - 387s 8s/step - loss: 4.9067 - accuracy: 0.2415 - val_loss: 6.8065 - val_accuracy: 0.0100\n",
      "\n",
      " End of Epoch Learning Rate = 0.003455\n",
      "Epoch 30/50\n",
      "\n",
      " Start of Epoch Learning Rate = 0.003455\n",
      "50/50 [==============================] - 387s 8s/step - loss: 4.8587 - accuracy: 0.2385 - val_loss: 6.6840 - val_accuracy: 0.0100\n",
      "\n",
      " End of Epoch Learning Rate = 0.000792\n",
      "Epoch 31/50\n",
      "\n",
      " Start of Epoch Learning Rate = 0.100000\n",
      "50/50 [==============================] - 384s 8s/step - loss: 5.0294 - accuracy: 0.1998 - val_loss: 7.1853 - val_accuracy: 0.0100\n",
      "\n",
      " End of Epoch Learning Rate = 0.099998\n",
      "Epoch 32/50\n",
      "\n",
      " Start of Epoch Learning Rate = 0.099998\n",
      "50/50 [==============================] - 382s 8s/step - loss: 5.2297 - accuracy: 0.1517 - val_loss: 9.0106 - val_accuracy: 0.0100\n",
      "\n",
      " End of Epoch Learning Rate = 0.099710\n",
      "Epoch 33/50\n",
      "\n",
      " Start of Epoch Learning Rate = 0.099710\n",
      "50/50 [==============================] - 389s 8s/step - loss: 5.0652 - accuracy: 0.1652 - val_loss: 7.4417 - val_accuracy: 0.0100\n",
      "\n",
      " End of Epoch Learning Rate = 0.098943\n",
      "Epoch 34/50\n",
      "\n",
      " Start of Epoch Learning Rate = 0.098943\n",
      "50/50 [==============================] - 391s 8s/step - loss: 4.9356 - accuracy: 0.1952 - val_loss: 6.5654 - val_accuracy: 0.0100\n",
      "\n",
      " End of Epoch Learning Rate = 0.097705\n",
      "Epoch 35/50\n",
      "\n",
      " Start of Epoch Learning Rate = 0.097705\n",
      "50/50 [==============================] - 391s 8s/step - loss: 4.9066 - accuracy: 0.1935 - val_loss: 6.7226 - val_accuracy: 0.0100\n",
      "\n",
      " End of Epoch Learning Rate = 0.096008\n",
      "Epoch 36/50\n",
      "\n",
      " Start of Epoch Learning Rate = 0.096008\n",
      "50/50 [==============================] - 391s 8s/step - loss: 4.7438 - accuracy: 0.2089 - val_loss: 6.9529 - val_accuracy: 0.0100\n",
      "\n",
      " End of Epoch Learning Rate = 0.093867\n",
      "Epoch 37/50\n",
      "\n",
      " Start of Epoch Learning Rate = 0.093867\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/50 [==============================] - 390s 8s/step - loss: 4.7237 - accuracy: 0.1991 - val_loss: 6.2369 - val_accuracy: 0.0100\n",
      "\n",
      " End of Epoch Learning Rate = 0.091305\n",
      "Epoch 38/50\n",
      "\n",
      " Start of Epoch Learning Rate = 0.091305\n",
      "50/50 [==============================] - 390s 8s/step - loss: 4.6504 - accuracy: 0.2093 - val_loss: 6.8544 - val_accuracy: 0.0100\n",
      "\n",
      " End of Epoch Learning Rate = 0.088344\n",
      "Epoch 39/50\n",
      "\n",
      " Start of Epoch Learning Rate = 0.088344\n",
      "50/50 [==============================] - 391s 8s/step - loss: 4.5429 - accuracy: 0.2112 - val_loss: 7.0144 - val_accuracy: 0.0100\n",
      "\n",
      " End of Epoch Learning Rate = 0.085014\n",
      "Epoch 40/50\n",
      "\n",
      " Start of Epoch Learning Rate = 0.085014\n",
      "50/50 [==============================] - 393s 8s/step - loss: 4.5233 - accuracy: 0.2230 - val_loss: 6.3175 - val_accuracy: 0.0100\n",
      "\n",
      " End of Epoch Learning Rate = 0.081347\n",
      "Epoch 41/50\n",
      "\n",
      " Start of Epoch Learning Rate = 0.081347\n",
      "50/50 [==============================] - 391s 8s/step - loss: 4.4548 - accuracy: 0.2308 - val_loss: 6.2267 - val_accuracy: 0.0100\n",
      "\n",
      " End of Epoch Learning Rate = 0.077379\n",
      "Epoch 42/50\n",
      "\n",
      " Start of Epoch Learning Rate = 0.077379\n",
      "50/50 [==============================] - 392s 8s/step - loss: 4.4084 - accuracy: 0.2142 - val_loss: 6.8855 - val_accuracy: 0.0100\n",
      "\n",
      " End of Epoch Learning Rate = 0.073146\n",
      "Epoch 43/50\n",
      "\n",
      " Start of Epoch Learning Rate = 0.073146\n",
      "50/50 [==============================] - 394s 8s/step - loss: 4.3669 - accuracy: 0.2217 - val_loss: 6.2328 - val_accuracy: 0.0100\n",
      "\n",
      " End of Epoch Learning Rate = 0.068691\n",
      "Epoch 44/50\n",
      "\n",
      " Start of Epoch Learning Rate = 0.068691\n",
      "50/50 [==============================] - 393s 8s/step - loss: 4.2319 - accuracy: 0.2526 - val_loss: 6.3893 - val_accuracy: 0.0100\n",
      "\n",
      " End of Epoch Learning Rate = 0.064056\n",
      "Epoch 45/50\n",
      "\n",
      " Start of Epoch Learning Rate = 0.064056\n",
      "50/50 [==============================] - 396s 8s/step - loss: 4.0952 - accuracy: 0.2822 - val_loss: 6.3426 - val_accuracy: 0.0100\n",
      "\n",
      " End of Epoch Learning Rate = 0.059285\n",
      "Epoch 46/50\n",
      "\n",
      " Start of Epoch Learning Rate = 0.059285\n",
      "50/50 [==============================] - 393s 8s/step - loss: 4.1361 - accuracy: 0.2610 - val_loss: 6.4842 - val_accuracy: 0.0100\n",
      "\n",
      " End of Epoch Learning Rate = 0.054425\n",
      "Epoch 47/50\n",
      "\n",
      " Start of Epoch Learning Rate = 0.054425\n",
      "50/50 [==============================] - 393s 8s/step - loss: 4.0519 - accuracy: 0.2861 - val_loss: 6.1512 - val_accuracy: 0.0100\n",
      "\n",
      " End of Epoch Learning Rate = 0.049523\n",
      "Epoch 48/50\n",
      "\n",
      " Start of Epoch Learning Rate = 0.049523\n",
      "50/50 [==============================] - 393s 8s/step - loss: 3.9998 - accuracy: 0.2847 - val_loss: 6.1319 - val_accuracy: 0.0100\n",
      "\n",
      " End of Epoch Learning Rate = 0.044625\n",
      "Epoch 49/50\n",
      "\n",
      " Start of Epoch Learning Rate = 0.044625\n",
      "50/50 [==============================] - 393s 8s/step - loss: 3.9815 - accuracy: 0.2812 - val_loss: 6.1156 - val_accuracy: 0.0100\n",
      "\n",
      " End of Epoch Learning Rate = 0.039779\n",
      "Epoch 50/50\n",
      "\n",
      " Start of Epoch Learning Rate = 0.039779\n",
      "50/50 [==============================] - 393s 8s/step - loss: 3.9643 - accuracy: 0.2713 - val_loss: 5.9824 - val_accuracy: 0.0100\n",
      "\n",
      " End of Epoch Learning Rate = 0.035032\n"
     ]
    }
   ],
   "source": [
    "ResnetFineModelHistory = ResnetFinemodel.fit(dataGenerator.flow(x_train, y_train, batch_size=50),\n",
    "                              validation_data=(x_test, y_test),\n",
    "                              epochs=50,\n",
    "                              verbose=1,\n",
    "                              callbacks=callbacks,\n",
    "                              steps_per_epoch =50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "artificial-jewelry",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: resNet_fine_1\\assets\n"
     ]
    }
   ],
   "source": [
    "ResnetFinemodel.save('resNet_fine_1')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "suitable-concept",
   "metadata": {},
   "source": [
    "plot training curves and test accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "latin-velvet",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1d5041e4fc8>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(ResnetFineModelHistory.history['accuracy'], label='accuracy')\n",
    "plt.plot(ResnetFineModelHistory.history['val_accuracy'], label = 'val_accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([0.0, 0.6])\n",
    "plt.legend(loc='lower right')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "known-telling",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 - 167s - loss: 65.3604 - accuracy: 0.0100\n",
      "0.009999999776482582\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(x_test,  y_test, verbose=2)\n",
    "\n",
    "print(test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "useful-kennedy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.01012157 0.01943859 0.0026361  ... 0.00429937 0.00563788 0.08619825]\n",
      " [0.01007977 0.01952694 0.00263482 ... 0.00430329 0.00563988 0.08634824]\n",
      " [0.01009737 0.01950925 0.00263198 ... 0.00430212 0.0056369  0.08633547]\n",
      " ...\n",
      " [0.01003984 0.01956393 0.00263371 ... 0.0043056  0.00563628 0.08633611]\n",
      " [0.01006966 0.01953766 0.00263495 ... 0.00430548 0.00564506 0.08650868]\n",
      " [0.01023299 0.01952851 0.00264168 ... 0.00430985 0.00565613 0.08607346]]\n"
     ]
    }
   ],
   "source": [
    "predictionsResnetFinemodel=ResnetFinemodel.predict(test_images_reshaped)\n",
    "print(predictionsResnetFinemodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tough-decade",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cm = confusion_matrix(np.array(test_labels), np.array(predictions), labels=np.unique(test_labels))\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=np.unique(test_labels))\n",
    "disp.plot() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "behavioral-holmes",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[49 33 72 ... 51 42 70]\n"
     ]
    }
   ],
   "source": [
    "#change y_train from one-hot encoded\n",
    "import numpy as np\n",
    "y_rounded_labels=np.argmax(y_test, axis=1)\n",
    "y_rounded_labels[1]\n",
    "print(y_rounded_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "substantial-harvest",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Singleton array 49 cannot be considered a valid collection.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-89-bee8e9a90331>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_rounded_labels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredictionsResnetFinemodel\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_rounded_labels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m#disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=np.unique(y_rounded_labels))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m#disp.plot()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\lizks\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\lizks\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36mconfusion_matrix\u001b[1;34m(y_true, y_pred, labels, sample_weight, normalize)\u001b[0m\n\u001b[0;32m    294\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    295\u001b[0m     \"\"\"\n\u001b[1;32m--> 296\u001b[1;33m     \u001b[0my_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    297\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"binary\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"multiclass\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    298\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"%s is not supported\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0my_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\lizks\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     81\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0marray\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mindicator\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m     \"\"\"\n\u001b[1;32m---> 83\u001b[1;33m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     84\u001b[0m     \u001b[0mtype_true\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m     \u001b[0mtype_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\lizks\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    257\u001b[0m     \"\"\"\n\u001b[0;32m    258\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 259\u001b[1;33m     \u001b[0mlengths\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0m_num_samples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mX\u001b[0m \u001b[1;32min\u001b[0m \u001b[0marrays\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mX\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    260\u001b[0m     \u001b[0muniques\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\lizks\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    257\u001b[0m     \"\"\"\n\u001b[0;32m    258\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 259\u001b[1;33m     \u001b[0mlengths\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0m_num_samples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mX\u001b[0m \u001b[1;32min\u001b[0m \u001b[0marrays\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mX\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    260\u001b[0m     \u001b[0muniques\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\lizks\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36m_num_samples\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    201\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    202\u001b[0m             raise TypeError(\"Singleton array %r cannot be considered\"\n\u001b[1;32m--> 203\u001b[1;33m                             \" a valid collection.\" % x)\n\u001b[0m\u001b[0;32m    204\u001b[0m         \u001b[1;31m# Check that shape is returning an integer or default to len\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    205\u001b[0m         \u001b[1;31m# Dask dataframes may not return numeric shape[0] value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Singleton array 49 cannot be considered a valid collection."
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "cm = confusion_matrix(y_rounded_labels[0], predictionsResnetFinemodel[0], labels=np.unique(y_rounded_labels[0]))\n",
    "\n",
    "#disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=np.unique(y_rounded_labels))\n",
    "#disp.plot() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "phantom-gather",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[49 33 72 ... 51 42 70]\n",
      "[[0.01012157 0.01943859 0.0026361  ... 0.00429937 0.00563788 0.08619825]\n",
      " [0.01007977 0.01952694 0.00263482 ... 0.00430329 0.00563988 0.08634824]\n",
      " [0.01009737 0.01950925 0.00263198 ... 0.00430212 0.0056369  0.08633547]\n",
      " ...\n",
      " [0.01003984 0.01956393 0.00263371 ... 0.0043056  0.00563628 0.08633611]\n",
      " [0.01006966 0.01953766 0.00263495 ... 0.00430548 0.00564506 0.08650868]\n",
      " [0.01023299 0.01952851 0.00264168 ... 0.00430985 0.00565613 0.08607346]]\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(np.array(y_rounded_labels))\n",
    "print(np.array(predictionsResnetFinemodel))\n",
    "\n",
    "print(type(y_rounded_labels))\n",
    "print(type(predictionsResnetFinemodel))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "considerable-arnold",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of multiclass and continuous-multioutput targets",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-94-6070555e99a4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0my_true\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my_rounded_labels\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpredictionsResnetFinemodel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mconfusion_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m#, predictionsResnetFinemodel[0],\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\lizks\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\lizks\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36mconfusion_matrix\u001b[1;34m(y_true, y_pred, labels, sample_weight, normalize)\u001b[0m\n\u001b[0;32m    294\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    295\u001b[0m     \"\"\"\n\u001b[1;32m--> 296\u001b[1;33m     \u001b[0my_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    297\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"binary\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"multiclass\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    298\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"%s is not supported\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0my_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\lizks\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     91\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m         raise ValueError(\"Classification metrics can't handle a mix of {0} \"\n\u001b[1;32m---> 93\u001b[1;33m                          \"and {1} targets\".format(type_true, type_pred))\n\u001b[0m\u001b[0;32m     94\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m     \u001b[1;31m# We can't have more than one value on y_type => The set is no more needed\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Classification metrics can't handle a mix of multiclass and continuous-multioutput targets"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "y_true = np.array(y_rounded_labels)\n",
    "y_pred = np.array(predictionsResnetFinemodel)\n",
    "confusion_matrix(y_true, y_pred)\n",
    "\n",
    "\n",
    "\n",
    "#, predictionsResnetFinemodel[0],"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "weekly-chicken",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"fini\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fresh-formula",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "registered-disclaimer",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
