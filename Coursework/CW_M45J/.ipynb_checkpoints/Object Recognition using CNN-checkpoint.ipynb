{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ordered-recorder",
   "metadata": {},
   "source": [
    "# CW1 - Object Recognition using CNN\n",
    "To apply machine learning alorithms to clasify the testing images into object categories. Then use a model to perform classification and report quantitative results.\n",
    "\n",
    "Due: Monday 19th April"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "norwegian-karma",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "leading-turning",
   "metadata": {},
   "source": [
    "The aim is to evaluate the use of CNN's in image recognition and the affect of adding multiple layers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alpha-negotiation",
   "metadata": {},
   "source": [
    "# Imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "modified-demographic",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import skimage.feature\n",
    "import tensorflow as tf\n",
    "from sklearn.utils import shuffle\n",
    "from numpy import load\n",
    "from numpy import asarray\n",
    "from numpy import save"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "moving-democracy",
   "metadata": {},
   "source": [
    "# Load Data\n",
    "There are 100 different categories of objects\n",
    "each has 500 images for training and 100 images for testing.\n",
    "Split the data into train and test sections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "recovered-longer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images Shape: (32, 32, 3, 50000)\n",
      "Train Labels Fine Shape: (50000,)\n",
      "Train Labels Coarse Shape: (50000,)\n"
     ]
    }
   ],
   "source": [
    "images = np.load('trnImage.npy')\n",
    "label_fine = np.load('trnLabel_fine.npy')\n",
    "label_coarse = np.load('trnLabel_coarse.npy')\n",
    "\n",
    "#image_index = 1 # pick a specific image\n",
    "#image = images[:, :, :, image_index]\n",
    "\n",
    "test_images = np.load('tstImage.npy')\n",
    "test_label_fine = np.load('tstLabel_fine.npy')\n",
    "test_label_coarse = np.load('tstLabel_coarse.npy')\n",
    "\n",
    "print(f'Images Shape: {images.shape}')\n",
    "print(f'Train Labels Fine Shape: {label_fine.shape}')\n",
    "print(f'Train Labels Coarse Shape: {label_coarse.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "protecting-departure",
   "metadata": {},
   "source": [
    "# Shuffle data to ensure not ordered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "lesbian-procedure",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = shuffle(images, random_state=0)\n",
    "label_fine, label_coarse = shuffle(label_fine, label_coarse, random_state=0) #make sure the samples are not ordered\n",
    "\n",
    "\n",
    "test_images = shuffle(test_images, random_state=0)\n",
    "test_label_fine, test_label_coarse = shuffle(test_label_fine, test_label_coarse, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "looking-chain",
   "metadata": {},
   "source": [
    "# CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "adjacent-cattle",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32, 32, 1)\n"
     ]
    }
   ],
   "source": [
    "images_reshaped = np.transpose(images, (3, 0, 1, 2))[:, :, :, -1]\n",
    "images_reshaped = np.expand_dims(images_reshaped, axis=3)\n",
    "\n",
    "print(images_reshaped.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "coated-angel",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 32, 32, 1)\n"
     ]
    }
   ],
   "source": [
    "test_images_reshaped = np.transpose(test_images, (3, 0, 1, 2))[:, :, :, -1]\n",
    "test_images_reshaped = np.expand_dims(test_images_reshaped, axis=3)\n",
    "\n",
    "print(test_images_reshaped.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rotary-constraint",
   "metadata": {},
   "source": [
    "# Normalise the data, for each image do a hog, add how to array, train images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "banner-psychiatry",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-89bdfd9f7701>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'hog_array_train.npy'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\lizks\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\numpy\\lib\\npyio.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[0;32m    415\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 416\u001b[1;33m             \u001b[0mfid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstack\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menter_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos_fspath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    417\u001b[0m             \u001b[0mown_fid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'hog_array_train.npy'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-89bdfd9f7701>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[1;31m# Extract features from a single image\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhog_image\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mskimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpixels_per_cell\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcells_per_block\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvisualize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\lizks\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\skimage\\feature\\_hog.py\u001b[0m in \u001b[0;36mhog\u001b[1;34m(image, orientations, pixels_per_cell, cells_per_block, block_norm, visualize, transform_sqrt, feature_vector, multichannel)\u001b[0m\n\u001b[0;32m    252\u001b[0m                                        \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcentre\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mdr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    253\u001b[0m                                        \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcentre\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mdc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 254\u001b[1;33m                                        int(centre[1] - dr))\n\u001b[0m\u001b[0;32m    255\u001b[0m                     \u001b[0mhog_image\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mrr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcc\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0morientation_histogram\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    256\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\lizks\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\skimage\\draw\\draw.py\u001b[0m in \u001b[0;36mline\u001b[1;34m(r0, c0, r1, c1)\u001b[0m\n\u001b[0;32m    408\u001b[0m            [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], dtype=uint8)\n\u001b[0;32m    409\u001b[0m     \"\"\"\n\u001b[1;32m--> 410\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_line\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mr0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mc0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mr1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mc1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    411\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    412\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mskimage\\draw\\_draw.pyx\u001b[0m in \u001b[0;36mskimage.draw._draw._line\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mc:\\users\\lizks\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\numpy\\core\\_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[1;34m(a, dtype, order)\u001b[0m\n\u001b[0;32m     12\u001b[0m ]\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[1;33m@\u001b[0m\u001b[0mset_module\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'numpy'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \"\"\"Convert the input to an array.\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "train_images_normalised = []\n",
    "\n",
    "try:\n",
    "    data = load('hog_array_train.npy')\n",
    "    print(data)\n",
    "except: \n",
    "    for image_index in range(0, 100):\n",
    "        image = images_reshaped[:, :, :, image_index]\n",
    "\n",
    "        # Extract features from a single image\n",
    "        _, hog_image = skimage.feature.hog(image, pixels_per_cell=[2,2], cells_per_block=[3,3], visualize=True)\n",
    "\n",
    "        plt.figure()\n",
    "        plt.subplot(121)\n",
    "        plt.imshow(hog_image)\n",
    "        plt.subplot(122)\n",
    "        plt.imshow(image)\n",
    "        plt.suptitle(f'Extracted HOG features from image number: {image_index}\\nFine Class: {label_fine[image_index]}, Coarse Class: {label_coarse[image_index]}')\n",
    "        plt.show(block=False)\n",
    "\n",
    "        print(hog_image)\n",
    "        train_images_normalised.append(hog_image)\n",
    "        #test_images_normalised[image_index] = hog_image\n",
    "\n",
    "        print(train_images_normalised[image_index])\n",
    "\n",
    "        train_images_output = np.array(train_images_normalised)\n",
    "\n",
    "\n",
    "        # save numpy array as npy file\n",
    "\n",
    "\n",
    "    data = asarray(train_images_output)\n",
    "        # save to npy file\n",
    "    save('hog_array_train.npy', data)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "correct-tokyo",
   "metadata": {},
   "source": [
    "normalise test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "absolute-arrival",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_images_normalised = []\n",
    "\n",
    "\n",
    "try:\n",
    "    \n",
    "    data = load('hog_array_test.npy')\n",
    "\n",
    "    print(data)\n",
    "except: \n",
    "    for image_index in range(0, 100):\n",
    "        image = test_images_reshaped[:, :, :, image_index]\n",
    "\n",
    "        # Extract features from a single image\n",
    "        _, hog_image = skimage.feature.hog(image, pixels_per_cell=[2,2], cells_per_block=[3,3], visualize=True)\n",
    "\n",
    "        plt.figure()\n",
    "        plt.subplot(121)\n",
    "        plt.imshow(hog_image)\n",
    "        plt.subplot(122)\n",
    "        plt.imshow(image)\n",
    "        plt.suptitle(f'Extracted HOG features from image number: {image_index}\\nFine Class: {label_fine[image_index]}, Coarse Class: {label_coarse[image_index]}')\n",
    "        plt.show(block=False)\n",
    "\n",
    "        print(hog_image)\n",
    "        test_images_normalised.append(hog_image)\n",
    "        #test_images_normalised[image_index] = hog_image\n",
    "\n",
    "        print(test_images_normalised[image_index])\n",
    "\n",
    "        train_images_output = np.array(test_images_normalised)\n",
    "\n",
    "\n",
    "        # save numpy array as npy file\n",
    "\n",
    "\n",
    "    data = asarray(train_images_output)\n",
    "        # save to npy file\n",
    "    save('hog_array_test.npy', data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "certain-catholic",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_images_normalised)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chubby-study",
   "metadata": {},
   "source": [
    "Normalise the data, for each image do a hog, add how to array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stupid-oxford",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_images_normalised)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unauthorized-opportunity",
   "metadata": {},
   "source": [
    "### Create and train a Tensorflow Convolutional Neural Network on the training set using Conv2D and pooling Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interior-penetration",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, -1)))\n",
    "model.add(tf.keras.layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "excessive-guyana",
   "metadata": {},
   "source": [
    "Check the Data cardinality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "continued-gentleman",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_images_normalised.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spiritual-paris",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_images_normalised.shape)\n",
    "print(test_images_normalised.shape)\n",
    "\n",
    "#train_images_normalised = np.array(train_images_normalised).reshape(50000, -1, 32, 32)\n",
    "#test_images_normalised = np.array(test_images_normalised).reshape(10000, -1, 32, 32)\n",
    "\n",
    "#train_images_normalised = train_images_normalised[:, 0, :, :]\n",
    "test_images_normalised = test_images_normalised[:, 0, :, :]\n",
    "\n",
    "train_images_normalised = np.transpose(train_images_normalised, (1, 2, 0))\n",
    "test_images_normalised = np.transpose(test_images_normalised, (1, 2, 0))\n",
    "\n",
    "print(train_images_normalised.shape)\n",
    "print(test_images_normalised.shape)\n",
    "\n",
    "\n",
    "print(label_fine.shape)\n",
    "print(test_label_fine.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "finite-chile",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check number of unique  labels in coarse dtaaset\n",
    "#number of labels\n",
    "\n",
    "output_num_fine = (np.unique(label_fine).shape[0])\n",
    "print(output_num_fine)\n",
    "\n",
    "output_num_coarse = (np.unique(label_coarse).shape[0])\n",
    "print(output_num_coarse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "worst-religion",
   "metadata": {},
   "outputs": [],
   "source": [
    "xTrn, xTst, yTrn, yTst = train_test_split(train_images_normalised, label_coarse, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "waiting-ivory",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(tf.keras.layers.Flatten()) #dense layers can oinly have 1d so flattern araray to one dimension\n",
    "model.add(tf.keras.layers.Dense(64, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(output_num_coarse, activation='softmax'))\n",
    "\n",
    "model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(xTrn, yTrn, epochs=10, \n",
    "                    validation_data=(xTst, yTst))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aggressive-postage",
   "metadata": {},
   "source": [
    "### Plot models traing curves "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "conditional-senegal",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['accuracy'], label='accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label = 'val_accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([0.5, 1])\n",
    "plt.legend(loc='lower right')\n",
    "\n",
    "test_loss, test_acc = model.evaluate(images_normalised,  label_fine_normalised, verbose=2)\n",
    "\n",
    "print(test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "improving-alias",
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(test_images_normalised, test_label_fine_normalised, verbose=0)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "seven-wiring",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
